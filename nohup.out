I0925 18:54:45.404325  4179 caffe.cpp:217] Using GPUs 0
I0925 18:54:45.410712  4179 caffe.cpp:222] GPU 0: GeForce GTX 970
I0925 18:54:45.562580  4179 solver.cpp:48] Initializing solver from parameters: 
test_iter: 392
test_interval: 1000
base_lr: 1e-05
display: 10
max_iter: 20000000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 200000000
snapshot: 1000
snapshot_prefix: "AESR/model_maxout_deconv_bn/model-1"
solver_mode: GPU
device_id: 0
random_seed: 701
net: "AESR/AESR_net.prototxt"
train_state {
  level: 0
  stage: ""
}
test_initialization: false
I0925 18:54:45.562674  4179 solver.cpp:91] Creating training net from net file: AESR/AESR_net.prototxt
I0925 18:54:45.563684  4179 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer low2
I0925 18:54:45.563693  4179 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer low3
I0925 18:54:45.563695  4179 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer low4
I0925 18:54:45.563697  4179 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer label
I0925 18:54:45.563957  4179 net.cpp:58] Initializing net from parameters: 
name: "AESR"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "low2"
  type: "HDF5Data"
  top: "low2"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "AESR/hdf5/tr_txt/low2_1.txt"
    batch_size: 32
  }
}
layer {
  name: "low3"
  type: "HDF5Data"
  top: "low3"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "AESR/hdf5/tr_txt/low3_1.txt"
    batch_size: 32
  }
}
layer {
  name: "low4"
  type: "HDF5Data"
  top: "low4"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "AESR/hdf5/tr_txt/low4_1.txt"
    batch_size: 32
  }
}
layer {
  name: "label"
  type: "HDF5Data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "AESR/hdf5/tr_txt/label_1.txt"
    batch_size: 32
  }
}
layer {
  name: "conv21"
  type: "Convolution"
  bottom: "low2"
  top: "conv21"
  param {
    name: "conv_W1"
    lr_mult: 0.3
  }
  param {
    name: "conv_b1"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "relu21"
  type: "ReLU"
  bottom: "conv21"
  top: "conv21"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv22"
  type: "Convolution"
  bottom: "conv21"
  top: "conv22"
  param {
    name: "conv_W2"
    lr_mult: 0.3
  }
  param {
    name: "conv_b2"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "bn22"
  type: "BatchNorm"
  bottom: "conv22"
  top: "conv22"
}
layer {
  name: "relu22"
  type: "ReLU"
  bottom: "conv22"
  top: "conv22"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv23"
  type: "Convolution"
  bottom: "conv22"
  top: "conv23"
  param {
    name: "conv_W3"
    lr_mult: 0.3
  }
  param {
    name: "conv_b3"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "bn23"
  type: "BatchNorm"
  bottom: "conv23"
  top: "conv23"
}
layer {
  name: "relu2-13"
  type: "ReLU"
  bottom: "conv23"
  top: "conv23"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "deconv24"
  type: "Deconvolution"
  bottom: "conv23"
  top: "deconv24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 6
    kernel_size: 14
    stride: 2
    weight_filler {
      type: "bilinear"
    }
    engine: CUDNN
  }
}
layer {
  name: "relu24"
  type: "ReLU"
  bottom: "deconv24"
  top: "deconv24"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv25"
  type: "Convolution"
  bottom: "deconv24"
  top: "conv25"
  param {
    name: "conv_W5"
    lr_mult: 0.3
  }
  param {
    name: "conv_b5"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "slice25"
  type: "Slice"
  bottom: "conv25"
  top: "conv25-a"
  top: "conv25-b"
  top: "conv25-c"
  slice_param {
    axis: 1
  }
}
layer {
  name: "maxout25"
  type: "Eltwise"
  bottom: "conv25-a"
  bottom: "conv25-b"
  bottom: "conv25-c"
  top: "maxout25"
  eltwise_param {
    operation: MAX
  }
}
layer {
  name: "bn25"
  type: "BatchNorm"
  bottom: "maxout25"
  top: "maxout25"
}
layer {
  name: "relu25"
  type: "ReLU"
  bottom: "maxout25"
  top: "maxout25"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv26"
  type: "Convolution"
  bottom: "maxout25"
  top: "conv26"
  param {
    name: "conv_W6"
    lr_mult: 0.3
  }
  param {
    name: "conv_b6"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "slice26"
  type: "Slice"
  bottom: "conv26"
  top: "conv26-a"
  top: "conv26-b"
  top: "conv26-c"
  slice_param {
    axis: 1
  }
}
layer {
  name: "maxout26"
  type: "Eltwise"
  bottom: "conv26-a"
  bottom: "conv26-b"
  bottom: "conv26-c"
  top: "maxout26"
  eltwise_param {
    operation: MAX
  }
}
layer {
  name: "bn26"
  type: "BatchNorm"
  bottom: "maxout26"
  top: "maxout26"
}
layer {
  name: "relu26"
  type: "ReLU"
  bottom: "maxout26"
  top: "maxout26"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv27"
  type: "Convolution"
  bottom: "maxout26"
  top: "conv27"
  param {
    name: "conv_W7"
    lr_mult: 0.3
  }
  param {
    name: "conv_b7"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 1
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "conv31"
  type: "Convolution"
  bottom: "low3"
  top: "conv31"
  param {
    name: "conv_W1"
    lr_mult: 0.3
  }
  param {
    name: "conv_b1"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "relu31"
  type: "ReLU"
  bottom: "conv31"
  top: "conv31"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv32"
  type: "Convolution"
  bottom: "conv31"
  top: "conv32"
  param {
    name: "conv_W2"
    lr_mult: 0.3
  }
  param {
    name: "conv_b2"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "bn32"
  type: "BatchNorm"
  bottom: "conv32"
  top: "conv32"
}
layer {
  name: "relu32"
  type: "ReLU"
  bottom: "conv32"
  top: "conv32"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv33"
  type: "Convolution"
  bottom: "conv32"
  top: "conv33"
  param {
    name: "conv_W3"
    lr_mult: 0.3
  }
  param {
    name: "conv_b3"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "bn33"
  type: "BatchNorm"
  bottom: "conv33"
  top: "conv33"
}
layer {
  name: "relu3-13"
  type: "ReLU"
  bottom: "conv33"
  top: "conv33"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "deconv34"
  type: "Deconvolution"
  bottom: "conv33"
  top: "deconv34"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 6
    kernel_size: 15
    stride: 3
    weight_filler {
      type: "bilinear"
    }
    engine: CUDNN
  }
}
layer {
  name: "relu34"
  type: "ReLU"
  bottom: "deconv34"
  top: "deconv34"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv35"
  type: "Convolution"
  bottom: "deconv34"
  top: "conv35"
  param {
    name: "conv_W5"
    lr_mult: 0.3
  }
  param {
    name: "conv_b5"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "slice35"
  type: "Slice"
  bottom: "conv35"
  top: "conv35-a"
  top: "conv35-b"
  top: "conv35-c"
  slice_param {
    axis: 1
  }
}
layer {
  name: "maxout35"
  type: "Eltwise"
  bottom: "conv35-a"
  bottom: "conv35-b"
  bottom: "conv35-c"
  top: "maxout35"
  eltwise_param {
    operation: MAX
  }
}
layer {
  name: "bn35"
  type: "BatchNorm"
  bottom: "maxout35"
  top: "maxout35"
}
layer {
  name: "relu35"
  type: "ReLU"
  bottom: "maxout35"
  top: "maxout35"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv36"
  type: "Convolution"
  bottom: "maxout35"
  top: "conv36"
  param {
    name: "conv_W6"
    lr_mult: 0.3
  }
  param {
    name: "conv_b6"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "slice36"
  type: "Slice"
  bottom: "conv36"
  top: "conv36-a"
  top: "conv36-b"
  top: "conv36-c"
  slice_param {
    axis: 1
  }
}
layer {
  name: "maxout36"
  type: "Eltwise"
  bottom: "conv36-a"
  bottom: "conv36-b"
  bottom: "conv36-c"
  top: "maxout36"
  eltwise_param {
    operation: MAX
  }
}
layer {
  name: "bn36"
  type: "BatchNorm"
  bottom: "maxout36"
  top: "maxout36"
}
layer {
  name: "relu36"
  type: "ReLU"
  bottom: "maxout36"
  top: "maxout36"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv37"
  type: "Convolution"
  bottom: "maxout36"
  top: "conv37"
  param {
    name: "conv_W7"
    lr_mult: 0.3
  }
  param {
    name: "conv_b7"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 1
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "conv41"
  type: "Convolution"
  bottom: "low4"
  top: "conv41"
  param {
    name: "conv_W1"
    lr_mult: 0.3
  }
  param {
    name: "conv_b1"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "relu41"
  type: "ReLU"
  bottom: "conv41"
  top: "conv41"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv42"
  type: "Convolution"
  bottom: "conv41"
  top: "conv42"
  param {
    name: "conv_W2"
    lr_mult: 0.3
  }
  param {
    name: "conv_b2"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "bn42"
  type: "BatchNorm"
  bottom: "conv42"
  top: "conv42"
}
layer {
  name: "relu42"
  type: "ReLU"
  bottom: "conv42"
  top: "conv42"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv43"
  type: "Convolution"
  bottom: "conv42"
  top: "conv43"
  param {
    name: "conv_W3"
    lr_mult: 0.3
  }
  param {
    name: "conv_b3"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "bn43"
  type: "BatchNorm"
  bottom: "conv43"
  top: "conv43"
}
layer {
  name: "relu4-13"
  type: "ReLU"
  bottom: "conv43"
  top: "conv43"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "deconv44"
  type: "Deconvolution"
  bottom: "conv43"
  top: "deconv44"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 6
    kernel_size: 16
    stride: 4
    weight_filler {
      type: "bilinear"
    }
    engine: CUDNN
  }
}
layer {
  name: "relu44"
  type: "ReLU"
  bottom: "deconv44"
  top: "deconv44"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv45"
  type: "Convolution"
  bottom: "deconv44"
  top: "conv45"
  param {
    name: "conv_W5"
    lr_mult: 0.3
  }
  param {
    name: "conv_b5"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "slice45"
  type: "Slice"
  bottom: "conv45"
  top: "conv45-a"
  top: "conv45-b"
  top: "conv45-c"
  slice_param {
    axis: 1
  }
}
layer {
  name: "maxout45"
  type: "Eltwise"
  bottom: "conv45-a"
  bottom: "conv45-b"
  bottom: "conv45-c"
  top: "maxout45"
  eltwise_param {
    operation: MAX
  }
}
layer {
  name: "bn45"
  type: "BatchNorm"
  bottom: "maxout45"
  top: "maxout45"
}
layer {
  name: "relu45"
  type: "ReLU"
  bottom: "maxout45"
  top: "maxout45"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv46"
  type: "Convolution"
  bottom: "maxout45"
  top: "conv46"
  param {
    name: "conv_W6"
    lr_mult: 0.3
  }
  param {
    name: "conv_b6"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "slice46"
  type: "Slice"
  bottom: "conv46"
  top: "conv46-a"
  top: "conv46-b"
  top: "conv46-c"
  slice_param {
    axis: 1
  }
}
layer {
  name: "maxout46"
  type: "Eltwise"
  bottom: "conv46-a"
  bottom: "conv46-b"
  bottom: "conv46-c"
  top: "maxout46"
  eltwise_param {
    operation: MAX
  }
}
layer {
  name: "bn46"
  type: "BatchNorm"
  bottom: "maxout46"
  top: "maxout46"
}
layer {
  name: "relu46"
  type: "ReLU"
  bottom: "maxout46"
  top: "maxout46"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv47"
  type: "Convolution"
  bottom: "maxout46"
  top: "conv47"
  param {
    name: "conv_W7"
    lr_mult: 0.3
  }
  param {
    name: "conv_b7"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 1
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "loss2"
  type: "EuclideanLoss"
  bottom: "conv27"
  bottom: "label"
  top: "loss2"
  loss_weight: 0.5
}
layer {
  name: "loss3"
  type: "EuclideanLoss"
  bottom: "conv37"
  bottom: "label"
  top: "loss3"
  loss_weight: 0.3
}
layer {
  name: "loss4"
  type: "EuclideanLoss"
  bottom: "conv47"
  bottom: "label"
  top: "loss4"
  loss_weight: 0.2
}
I0925 18:54:45.564164  4179 layer_factory.hpp:77] Creating layer low2
I0925 18:54:45.564182  4179 net.cpp:100] Creating Layer low2
I0925 18:54:45.564188  4179 net.cpp:408] low2 -> low2
I0925 18:54:45.564203  4179 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: AESR/hdf5/tr_txt/low2_1.txt
I0925 18:54:45.564220  4179 hdf5_data_layer.cpp:93] Number of HDF5 files: 1
I0925 18:54:45.564726  4179 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0925 18:54:45.570703  4179 net.cpp:150] Setting up low2
I0925 18:54:45.570727  4179 net.cpp:157] Top shape: 32 1 36 36 (41472)
I0925 18:54:45.570731  4179 net.cpp:165] Memory required for data: 165888
I0925 18:54:45.570737  4179 layer_factory.hpp:77] Creating layer low3
I0925 18:54:45.570746  4179 net.cpp:100] Creating Layer low3
I0925 18:54:45.570750  4179 net.cpp:408] low3 -> low3
I0925 18:54:45.570760  4179 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: AESR/hdf5/tr_txt/low3_1.txt
I0925 18:54:45.570777  4179 hdf5_data_layer.cpp:93] Number of HDF5 files: 1
I0925 18:54:45.571297  4179 net.cpp:150] Setting up low3
I0925 18:54:45.571310  4179 net.cpp:157] Top shape: 32 1 24 24 (18432)
I0925 18:54:45.571312  4179 net.cpp:165] Memory required for data: 239616
I0925 18:54:45.571316  4179 layer_factory.hpp:77] Creating layer low4
I0925 18:54:45.571321  4179 net.cpp:100] Creating Layer low4
I0925 18:54:45.571323  4179 net.cpp:408] low4 -> low4
I0925 18:54:45.571328  4179 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: AESR/hdf5/tr_txt/low4_1.txt
I0925 18:54:45.571338  4179 hdf5_data_layer.cpp:93] Number of HDF5 files: 1
I0925 18:54:45.571519  4179 net.cpp:150] Setting up low4
I0925 18:54:45.571528  4179 net.cpp:157] Top shape: 32 1 18 18 (10368)
I0925 18:54:45.571532  4179 net.cpp:165] Memory required for data: 281088
I0925 18:54:45.571533  4179 layer_factory.hpp:77] Creating layer label
I0925 18:54:45.571538  4179 net.cpp:100] Creating Layer label
I0925 18:54:45.571542  4179 net.cpp:408] label -> label
I0925 18:54:45.571547  4179 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: AESR/hdf5/tr_txt/label_1.txt
I0925 18:54:45.571555  4179 hdf5_data_layer.cpp:93] Number of HDF5 files: 1
I0925 18:54:45.572155  4179 net.cpp:150] Setting up label
I0925 18:54:45.572165  4179 net.cpp:157] Top shape: 32 1 72 72 (165888)
I0925 18:54:45.572168  4179 net.cpp:165] Memory required for data: 944640
I0925 18:54:45.572170  4179 layer_factory.hpp:77] Creating layer label_label_0_split
I0925 18:54:45.572180  4179 net.cpp:100] Creating Layer label_label_0_split
I0925 18:54:45.572183  4179 net.cpp:434] label_label_0_split <- label
I0925 18:54:45.572192  4179 net.cpp:408] label_label_0_split -> label_label_0_split_0
I0925 18:54:45.572199  4179 net.cpp:408] label_label_0_split -> label_label_0_split_1
I0925 18:54:45.572204  4179 net.cpp:408] label_label_0_split -> label_label_0_split_2
I0925 18:54:45.572232  4179 net.cpp:150] Setting up label_label_0_split
I0925 18:54:45.572237  4179 net.cpp:157] Top shape: 32 1 72 72 (165888)
I0925 18:54:45.572249  4179 net.cpp:157] Top shape: 32 1 72 72 (165888)
I0925 18:54:45.572255  4179 net.cpp:157] Top shape: 32 1 72 72 (165888)
I0925 18:54:45.572259  4179 net.cpp:165] Memory required for data: 2935296
I0925 18:54:45.572263  4179 layer_factory.hpp:77] Creating layer conv21
I0925 18:54:45.572275  4179 net.cpp:100] Creating Layer conv21
I0925 18:54:45.572278  4179 net.cpp:434] conv21 <- low2
I0925 18:54:45.572283  4179 net.cpp:408] conv21 -> conv21
I0925 18:54:45.665231  4179 net.cpp:150] Setting up conv21
I0925 18:54:45.665256  4179 net.cpp:157] Top shape: 32 16 36 36 (663552)
I0925 18:54:45.665259  4179 net.cpp:165] Memory required for data: 5589504
I0925 18:54:45.665272  4179 layer_factory.hpp:77] Creating layer relu21
I0925 18:54:45.665280  4179 net.cpp:100] Creating Layer relu21
I0925 18:54:45.665283  4179 net.cpp:434] relu21 <- conv21
I0925 18:54:45.665287  4179 net.cpp:395] relu21 -> conv21 (in-place)
I0925 18:54:45.665398  4179 net.cpp:150] Setting up relu21
I0925 18:54:45.665405  4179 net.cpp:157] Top shape: 32 16 36 36 (663552)
I0925 18:54:45.665407  4179 net.cpp:165] Memory required for data: 8243712
I0925 18:54:45.665421  4179 layer_factory.hpp:77] Creating layer conv22
I0925 18:54:45.665431  4179 net.cpp:100] Creating Layer conv22
I0925 18:54:45.665434  4179 net.cpp:434] conv22 <- conv21
I0925 18:54:45.665438  4179 net.cpp:408] conv22 -> conv22
I0925 18:54:45.666046  4179 net.cpp:150] Setting up conv22
I0925 18:54:45.666056  4179 net.cpp:157] Top shape: 32 16 36 36 (663552)
I0925 18:54:45.666059  4179 net.cpp:165] Memory required for data: 10897920
I0925 18:54:45.666064  4179 layer_factory.hpp:77] Creating layer bn22
I0925 18:54:45.666072  4179 net.cpp:100] Creating Layer bn22
I0925 18:54:45.666076  4179 net.cpp:434] bn22 <- conv22
I0925 18:54:45.666080  4179 net.cpp:395] bn22 -> conv22 (in-place)
I0925 18:54:45.666188  4179 net.cpp:150] Setting up bn22
I0925 18:54:45.666193  4179 net.cpp:157] Top shape: 32 16 36 36 (663552)
I0925 18:54:45.666194  4179 net.cpp:165] Memory required for data: 13552128
I0925 18:54:45.666200  4179 layer_factory.hpp:77] Creating layer relu22
I0925 18:54:45.666204  4179 net.cpp:100] Creating Layer relu22
I0925 18:54:45.666208  4179 net.cpp:434] relu22 <- conv22
I0925 18:54:45.666210  4179 net.cpp:395] relu22 -> conv22 (in-place)
I0925 18:54:45.666381  4179 net.cpp:150] Setting up relu22
I0925 18:54:45.666389  4179 net.cpp:157] Top shape: 32 16 36 36 (663552)
I0925 18:54:45.666391  4179 net.cpp:165] Memory required for data: 16206336
I0925 18:54:45.666394  4179 layer_factory.hpp:77] Creating layer conv23
I0925 18:54:45.666400  4179 net.cpp:100] Creating Layer conv23
I0925 18:54:45.666404  4179 net.cpp:434] conv23 <- conv22
I0925 18:54:45.666406  4179 net.cpp:408] conv23 -> conv23
I0925 18:54:45.666934  4179 net.cpp:150] Setting up conv23
I0925 18:54:45.666944  4179 net.cpp:157] Top shape: 32 16 36 36 (663552)
I0925 18:54:45.666946  4179 net.cpp:165] Memory required for data: 18860544
I0925 18:54:45.666951  4179 layer_factory.hpp:77] Creating layer bn23
I0925 18:54:45.666955  4179 net.cpp:100] Creating Layer bn23
I0925 18:54:45.666959  4179 net.cpp:434] bn23 <- conv23
I0925 18:54:45.666961  4179 net.cpp:395] bn23 -> conv23 (in-place)
I0925 18:54:45.667064  4179 net.cpp:150] Setting up bn23
I0925 18:54:45.667069  4179 net.cpp:157] Top shape: 32 16 36 36 (663552)
I0925 18:54:45.667071  4179 net.cpp:165] Memory required for data: 21514752
I0925 18:54:45.667076  4179 layer_factory.hpp:77] Creating layer relu2-13
I0925 18:54:45.667080  4179 net.cpp:100] Creating Layer relu2-13
I0925 18:54:45.667083  4179 net.cpp:434] relu2-13 <- conv23
I0925 18:54:45.667085  4179 net.cpp:395] relu2-13 -> conv23 (in-place)
I0925 18:54:45.667255  4179 net.cpp:150] Setting up relu2-13
I0925 18:54:45.667263  4179 net.cpp:157] Top shape: 32 16 36 36 (663552)
I0925 18:54:45.667265  4179 net.cpp:165] Memory required for data: 24168960
I0925 18:54:45.667268  4179 layer_factory.hpp:77] Creating layer deconv24
I0925 18:54:45.667273  4179 net.cpp:100] Creating Layer deconv24
I0925 18:54:45.667275  4179 net.cpp:434] deconv24 <- conv23
I0925 18:54:45.667279  4179 net.cpp:408] deconv24 -> deconv24
I0925 18:54:45.669088  4179 net.cpp:150] Setting up deconv24
I0925 18:54:45.669097  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.669100  4179 net.cpp:165] Memory required for data: 34785792
I0925 18:54:45.669104  4179 layer_factory.hpp:77] Creating layer relu24
I0925 18:54:45.669107  4179 net.cpp:100] Creating Layer relu24
I0925 18:54:45.669111  4179 net.cpp:434] relu24 <- deconv24
I0925 18:54:45.669113  4179 net.cpp:395] relu24 -> deconv24 (in-place)
I0925 18:54:45.669212  4179 net.cpp:150] Setting up relu24
I0925 18:54:45.669219  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.669221  4179 net.cpp:165] Memory required for data: 45402624
I0925 18:54:45.669224  4179 layer_factory.hpp:77] Creating layer conv25
I0925 18:54:45.669229  4179 net.cpp:100] Creating Layer conv25
I0925 18:54:45.669231  4179 net.cpp:434] conv25 <- deconv24
I0925 18:54:45.669235  4179 net.cpp:408] conv25 -> conv25
I0925 18:54:45.670017  4179 net.cpp:150] Setting up conv25
I0925 18:54:45.670025  4179 net.cpp:157] Top shape: 32 48 72 72 (7962624)
I0925 18:54:45.670034  4179 net.cpp:165] Memory required for data: 77253120
I0925 18:54:45.670039  4179 layer_factory.hpp:77] Creating layer slice25
I0925 18:54:45.670045  4179 net.cpp:100] Creating Layer slice25
I0925 18:54:45.670048  4179 net.cpp:434] slice25 <- conv25
I0925 18:54:45.670052  4179 net.cpp:408] slice25 -> conv25-a
I0925 18:54:45.670058  4179 net.cpp:408] slice25 -> conv25-b
I0925 18:54:45.670063  4179 net.cpp:408] slice25 -> conv25-c
I0925 18:54:45.670091  4179 net.cpp:150] Setting up slice25
I0925 18:54:45.670096  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.670099  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.670101  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.670104  4179 net.cpp:165] Memory required for data: 109103616
I0925 18:54:45.670105  4179 layer_factory.hpp:77] Creating layer maxout25
I0925 18:54:45.670112  4179 net.cpp:100] Creating Layer maxout25
I0925 18:54:45.670116  4179 net.cpp:434] maxout25 <- conv25-a
I0925 18:54:45.670120  4179 net.cpp:434] maxout25 <- conv25-b
I0925 18:54:45.670121  4179 net.cpp:434] maxout25 <- conv25-c
I0925 18:54:45.670125  4179 net.cpp:408] maxout25 -> maxout25
I0925 18:54:45.670148  4179 net.cpp:150] Setting up maxout25
I0925 18:54:45.670153  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.670156  4179 net.cpp:165] Memory required for data: 119720448
I0925 18:54:45.670157  4179 layer_factory.hpp:77] Creating layer bn25
I0925 18:54:45.670161  4179 net.cpp:100] Creating Layer bn25
I0925 18:54:45.670162  4179 net.cpp:434] bn25 <- maxout25
I0925 18:54:45.670166  4179 net.cpp:395] bn25 -> maxout25 (in-place)
I0925 18:54:45.670267  4179 net.cpp:150] Setting up bn25
I0925 18:54:45.670272  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.670274  4179 net.cpp:165] Memory required for data: 130337280
I0925 18:54:45.670281  4179 layer_factory.hpp:77] Creating layer relu25
I0925 18:54:45.670284  4179 net.cpp:100] Creating Layer relu25
I0925 18:54:45.670287  4179 net.cpp:434] relu25 <- maxout25
I0925 18:54:45.670290  4179 net.cpp:395] relu25 -> maxout25 (in-place)
I0925 18:54:45.670467  4179 net.cpp:150] Setting up relu25
I0925 18:54:45.670475  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.670477  4179 net.cpp:165] Memory required for data: 140954112
I0925 18:54:45.670480  4179 layer_factory.hpp:77] Creating layer conv26
I0925 18:54:45.670486  4179 net.cpp:100] Creating Layer conv26
I0925 18:54:45.670488  4179 net.cpp:434] conv26 <- maxout25
I0925 18:54:45.670492  4179 net.cpp:408] conv26 -> conv26
I0925 18:54:45.671213  4179 net.cpp:150] Setting up conv26
I0925 18:54:45.671222  4179 net.cpp:157] Top shape: 32 48 72 72 (7962624)
I0925 18:54:45.671226  4179 net.cpp:165] Memory required for data: 172804608
I0925 18:54:45.671229  4179 layer_factory.hpp:77] Creating layer slice26
I0925 18:54:45.671234  4179 net.cpp:100] Creating Layer slice26
I0925 18:54:45.671236  4179 net.cpp:434] slice26 <- conv26
I0925 18:54:45.671239  4179 net.cpp:408] slice26 -> conv26-a
I0925 18:54:45.671246  4179 net.cpp:408] slice26 -> conv26-b
I0925 18:54:45.671249  4179 net.cpp:408] slice26 -> conv26-c
I0925 18:54:45.671281  4179 net.cpp:150] Setting up slice26
I0925 18:54:45.671285  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.671288  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.671290  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.671293  4179 net.cpp:165] Memory required for data: 204655104
I0925 18:54:45.671294  4179 layer_factory.hpp:77] Creating layer maxout26
I0925 18:54:45.671298  4179 net.cpp:100] Creating Layer maxout26
I0925 18:54:45.671301  4179 net.cpp:434] maxout26 <- conv26-a
I0925 18:54:45.671304  4179 net.cpp:434] maxout26 <- conv26-b
I0925 18:54:45.671306  4179 net.cpp:434] maxout26 <- conv26-c
I0925 18:54:45.671309  4179 net.cpp:408] maxout26 -> maxout26
I0925 18:54:45.671330  4179 net.cpp:150] Setting up maxout26
I0925 18:54:45.671335  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.671344  4179 net.cpp:165] Memory required for data: 215271936
I0925 18:54:45.671346  4179 layer_factory.hpp:77] Creating layer bn26
I0925 18:54:45.671350  4179 net.cpp:100] Creating Layer bn26
I0925 18:54:45.671351  4179 net.cpp:434] bn26 <- maxout26
I0925 18:54:45.671355  4179 net.cpp:395] bn26 -> maxout26 (in-place)
I0925 18:54:45.671463  4179 net.cpp:150] Setting up bn26
I0925 18:54:45.671468  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.671471  4179 net.cpp:165] Memory required for data: 225888768
I0925 18:54:45.671475  4179 layer_factory.hpp:77] Creating layer relu26
I0925 18:54:45.671480  4179 net.cpp:100] Creating Layer relu26
I0925 18:54:45.671483  4179 net.cpp:434] relu26 <- maxout26
I0925 18:54:45.671486  4179 net.cpp:395] relu26 -> maxout26 (in-place)
I0925 18:54:45.671589  4179 net.cpp:150] Setting up relu26
I0925 18:54:45.671596  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.671598  4179 net.cpp:165] Memory required for data: 236505600
I0925 18:54:45.671600  4179 layer_factory.hpp:77] Creating layer conv27
I0925 18:54:45.671607  4179 net.cpp:100] Creating Layer conv27
I0925 18:54:45.671610  4179 net.cpp:434] conv27 <- maxout26
I0925 18:54:45.671614  4179 net.cpp:408] conv27 -> conv27
I0925 18:54:45.672209  4179 net.cpp:150] Setting up conv27
I0925 18:54:45.672217  4179 net.cpp:157] Top shape: 32 1 72 72 (165888)
I0925 18:54:45.672220  4179 net.cpp:165] Memory required for data: 237169152
I0925 18:54:45.672224  4179 layer_factory.hpp:77] Creating layer conv31
I0925 18:54:45.672232  4179 net.cpp:100] Creating Layer conv31
I0925 18:54:45.672235  4179 net.cpp:434] conv31 <- low3
I0925 18:54:45.672242  4179 net.cpp:408] conv31 -> conv31
I0925 18:54:45.673112  4179 net.cpp:150] Setting up conv31
I0925 18:54:45.673122  4179 net.cpp:157] Top shape: 32 16 24 24 (294912)
I0925 18:54:45.673125  4179 net.cpp:165] Memory required for data: 238348800
I0925 18:54:45.673127  4179 net.cpp:493] Sharing parameters 'conv_W1' owned by layer 'conv21', param index 0
I0925 18:54:45.673130  4179 net.cpp:493] Sharing parameters 'conv_b1' owned by layer 'conv21', param index 1
I0925 18:54:45.673133  4179 layer_factory.hpp:77] Creating layer relu31
I0925 18:54:45.673137  4179 net.cpp:100] Creating Layer relu31
I0925 18:54:45.673140  4179 net.cpp:434] relu31 <- conv31
I0925 18:54:45.673143  4179 net.cpp:395] relu31 -> conv31 (in-place)
I0925 18:54:45.673254  4179 net.cpp:150] Setting up relu31
I0925 18:54:45.673259  4179 net.cpp:157] Top shape: 32 16 24 24 (294912)
I0925 18:54:45.673262  4179 net.cpp:165] Memory required for data: 239528448
I0925 18:54:45.673264  4179 layer_factory.hpp:77] Creating layer conv32
I0925 18:54:45.673271  4179 net.cpp:100] Creating Layer conv32
I0925 18:54:45.673274  4179 net.cpp:434] conv32 <- conv31
I0925 18:54:45.673279  4179 net.cpp:408] conv32 -> conv32
I0925 18:54:45.674012  4179 net.cpp:150] Setting up conv32
I0925 18:54:45.674021  4179 net.cpp:157] Top shape: 32 16 24 24 (294912)
I0925 18:54:45.674023  4179 net.cpp:165] Memory required for data: 240708096
I0925 18:54:45.674026  4179 net.cpp:493] Sharing parameters 'conv_W2' owned by layer 'conv22', param index 0
I0925 18:54:45.674029  4179 net.cpp:493] Sharing parameters 'conv_b2' owned by layer 'conv22', param index 1
I0925 18:54:45.674031  4179 layer_factory.hpp:77] Creating layer bn32
I0925 18:54:45.674036  4179 net.cpp:100] Creating Layer bn32
I0925 18:54:45.674038  4179 net.cpp:434] bn32 <- conv32
I0925 18:54:45.674041  4179 net.cpp:395] bn32 -> conv32 (in-place)
I0925 18:54:45.674156  4179 net.cpp:150] Setting up bn32
I0925 18:54:45.674161  4179 net.cpp:157] Top shape: 32 16 24 24 (294912)
I0925 18:54:45.674163  4179 net.cpp:165] Memory required for data: 241887744
I0925 18:54:45.674170  4179 layer_factory.hpp:77] Creating layer relu32
I0925 18:54:45.674175  4179 net.cpp:100] Creating Layer relu32
I0925 18:54:45.674177  4179 net.cpp:434] relu32 <- conv32
I0925 18:54:45.674180  4179 net.cpp:395] relu32 -> conv32 (in-place)
I0925 18:54:45.674357  4179 net.cpp:150] Setting up relu32
I0925 18:54:45.674372  4179 net.cpp:157] Top shape: 32 16 24 24 (294912)
I0925 18:54:45.674376  4179 net.cpp:165] Memory required for data: 243067392
I0925 18:54:45.674377  4179 layer_factory.hpp:77] Creating layer conv33
I0925 18:54:45.674386  4179 net.cpp:100] Creating Layer conv33
I0925 18:54:45.674388  4179 net.cpp:434] conv33 <- conv32
I0925 18:54:45.674394  4179 net.cpp:408] conv33 -> conv33
I0925 18:54:45.674975  4179 net.cpp:150] Setting up conv33
I0925 18:54:45.674984  4179 net.cpp:157] Top shape: 32 16 24 24 (294912)
I0925 18:54:45.674986  4179 net.cpp:165] Memory required for data: 244247040
I0925 18:54:45.674989  4179 net.cpp:493] Sharing parameters 'conv_W3' owned by layer 'conv23', param index 0
I0925 18:54:45.674993  4179 net.cpp:493] Sharing parameters 'conv_b3' owned by layer 'conv23', param index 1
I0925 18:54:45.674994  4179 layer_factory.hpp:77] Creating layer bn33
I0925 18:54:45.675000  4179 net.cpp:100] Creating Layer bn33
I0925 18:54:45.675004  4179 net.cpp:434] bn33 <- conv33
I0925 18:54:45.675007  4179 net.cpp:395] bn33 -> conv33 (in-place)
I0925 18:54:45.675122  4179 net.cpp:150] Setting up bn33
I0925 18:54:45.675127  4179 net.cpp:157] Top shape: 32 16 24 24 (294912)
I0925 18:54:45.675129  4179 net.cpp:165] Memory required for data: 245426688
I0925 18:54:45.675134  4179 layer_factory.hpp:77] Creating layer relu3-13
I0925 18:54:45.675137  4179 net.cpp:100] Creating Layer relu3-13
I0925 18:54:45.675140  4179 net.cpp:434] relu3-13 <- conv33
I0925 18:54:45.675143  4179 net.cpp:395] relu3-13 -> conv33 (in-place)
I0925 18:54:45.675320  4179 net.cpp:150] Setting up relu3-13
I0925 18:54:45.675328  4179 net.cpp:157] Top shape: 32 16 24 24 (294912)
I0925 18:54:45.675331  4179 net.cpp:165] Memory required for data: 246606336
I0925 18:54:45.675333  4179 layer_factory.hpp:77] Creating layer deconv34
I0925 18:54:45.675338  4179 net.cpp:100] Creating Layer deconv34
I0925 18:54:45.675341  4179 net.cpp:434] deconv34 <- conv33
I0925 18:54:45.675345  4179 net.cpp:408] deconv34 -> deconv34
I0925 18:54:45.677108  4179 net.cpp:150] Setting up deconv34
I0925 18:54:45.677114  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.677115  4179 net.cpp:165] Memory required for data: 257223168
I0925 18:54:45.677120  4179 layer_factory.hpp:77] Creating layer relu34
I0925 18:54:45.677124  4179 net.cpp:100] Creating Layer relu34
I0925 18:54:45.677126  4179 net.cpp:434] relu34 <- deconv34
I0925 18:54:45.677130  4179 net.cpp:395] relu34 -> deconv34 (in-place)
I0925 18:54:45.677234  4179 net.cpp:150] Setting up relu34
I0925 18:54:45.677242  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.677243  4179 net.cpp:165] Memory required for data: 267840000
I0925 18:54:45.677245  4179 layer_factory.hpp:77] Creating layer conv35
I0925 18:54:45.677253  4179 net.cpp:100] Creating Layer conv35
I0925 18:54:45.677255  4179 net.cpp:434] conv35 <- deconv34
I0925 18:54:45.677258  4179 net.cpp:408] conv35 -> conv35
I0925 18:54:45.678012  4179 net.cpp:150] Setting up conv35
I0925 18:54:45.678021  4179 net.cpp:157] Top shape: 32 48 72 72 (7962624)
I0925 18:54:45.678025  4179 net.cpp:165] Memory required for data: 299690496
I0925 18:54:45.678027  4179 net.cpp:493] Sharing parameters 'conv_W5' owned by layer 'conv25', param index 0
I0925 18:54:45.678030  4179 net.cpp:493] Sharing parameters 'conv_b5' owned by layer 'conv25', param index 1
I0925 18:54:45.678032  4179 layer_factory.hpp:77] Creating layer slice35
I0925 18:54:45.678036  4179 net.cpp:100] Creating Layer slice35
I0925 18:54:45.678038  4179 net.cpp:434] slice35 <- conv35
I0925 18:54:45.678042  4179 net.cpp:408] slice35 -> conv35-a
I0925 18:54:45.678048  4179 net.cpp:408] slice35 -> conv35-b
I0925 18:54:45.678052  4179 net.cpp:408] slice35 -> conv35-c
I0925 18:54:45.678086  4179 net.cpp:150] Setting up slice35
I0925 18:54:45.678089  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.678092  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.678094  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.678097  4179 net.cpp:165] Memory required for data: 331540992
I0925 18:54:45.678104  4179 layer_factory.hpp:77] Creating layer maxout35
I0925 18:54:45.678110  4179 net.cpp:100] Creating Layer maxout35
I0925 18:54:45.678112  4179 net.cpp:434] maxout35 <- conv35-a
I0925 18:54:45.678115  4179 net.cpp:434] maxout35 <- conv35-b
I0925 18:54:45.678119  4179 net.cpp:434] maxout35 <- conv35-c
I0925 18:54:45.678122  4179 net.cpp:408] maxout35 -> maxout35
I0925 18:54:45.678145  4179 net.cpp:150] Setting up maxout35
I0925 18:54:45.678149  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.678151  4179 net.cpp:165] Memory required for data: 342157824
I0925 18:54:45.678153  4179 layer_factory.hpp:77] Creating layer bn35
I0925 18:54:45.678158  4179 net.cpp:100] Creating Layer bn35
I0925 18:54:45.678159  4179 net.cpp:434] bn35 <- maxout35
I0925 18:54:45.678163  4179 net.cpp:395] bn35 -> maxout35 (in-place)
I0925 18:54:45.678277  4179 net.cpp:150] Setting up bn35
I0925 18:54:45.678282  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.678284  4179 net.cpp:165] Memory required for data: 352774656
I0925 18:54:45.678289  4179 layer_factory.hpp:77] Creating layer relu35
I0925 18:54:45.678292  4179 net.cpp:100] Creating Layer relu35
I0925 18:54:45.678295  4179 net.cpp:434] relu35 <- maxout35
I0925 18:54:45.678298  4179 net.cpp:395] relu35 -> maxout35 (in-place)
I0925 18:54:45.678478  4179 net.cpp:150] Setting up relu35
I0925 18:54:45.678485  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.678488  4179 net.cpp:165] Memory required for data: 363391488
I0925 18:54:45.678490  4179 layer_factory.hpp:77] Creating layer conv36
I0925 18:54:45.678498  4179 net.cpp:100] Creating Layer conv36
I0925 18:54:45.678499  4179 net.cpp:434] conv36 <- maxout35
I0925 18:54:45.678504  4179 net.cpp:408] conv36 -> conv36
I0925 18:54:45.679270  4179 net.cpp:150] Setting up conv36
I0925 18:54:45.679280  4179 net.cpp:157] Top shape: 32 48 72 72 (7962624)
I0925 18:54:45.679281  4179 net.cpp:165] Memory required for data: 395241984
I0925 18:54:45.679285  4179 net.cpp:493] Sharing parameters 'conv_W6' owned by layer 'conv26', param index 0
I0925 18:54:45.679287  4179 net.cpp:493] Sharing parameters 'conv_b6' owned by layer 'conv26', param index 1
I0925 18:54:45.679289  4179 layer_factory.hpp:77] Creating layer slice36
I0925 18:54:45.679294  4179 net.cpp:100] Creating Layer slice36
I0925 18:54:45.679297  4179 net.cpp:434] slice36 <- conv36
I0925 18:54:45.679301  4179 net.cpp:408] slice36 -> conv36-a
I0925 18:54:45.679307  4179 net.cpp:408] slice36 -> conv36-b
I0925 18:54:45.679312  4179 net.cpp:408] slice36 -> conv36-c
I0925 18:54:45.679344  4179 net.cpp:150] Setting up slice36
I0925 18:54:45.679348  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.679352  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.679354  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.679358  4179 net.cpp:165] Memory required for data: 427092480
I0925 18:54:45.679359  4179 layer_factory.hpp:77] Creating layer maxout36
I0925 18:54:45.679364  4179 net.cpp:100] Creating Layer maxout36
I0925 18:54:45.679368  4179 net.cpp:434] maxout36 <- conv36-a
I0925 18:54:45.679370  4179 net.cpp:434] maxout36 <- conv36-b
I0925 18:54:45.679373  4179 net.cpp:434] maxout36 <- conv36-c
I0925 18:54:45.679378  4179 net.cpp:408] maxout36 -> maxout36
I0925 18:54:45.679399  4179 net.cpp:150] Setting up maxout36
I0925 18:54:45.679404  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.679406  4179 net.cpp:165] Memory required for data: 437709312
I0925 18:54:45.679409  4179 layer_factory.hpp:77] Creating layer bn36
I0925 18:54:45.679411  4179 net.cpp:100] Creating Layer bn36
I0925 18:54:45.679414  4179 net.cpp:434] bn36 <- maxout36
I0925 18:54:45.679419  4179 net.cpp:395] bn36 -> maxout36 (in-place)
I0925 18:54:45.679534  4179 net.cpp:150] Setting up bn36
I0925 18:54:45.679539  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.679543  4179 net.cpp:165] Memory required for data: 448326144
I0925 18:54:45.679548  4179 layer_factory.hpp:77] Creating layer relu36
I0925 18:54:45.679556  4179 net.cpp:100] Creating Layer relu36
I0925 18:54:45.679560  4179 net.cpp:434] relu36 <- maxout36
I0925 18:54:45.679564  4179 net.cpp:395] relu36 -> maxout36 (in-place)
I0925 18:54:45.679672  4179 net.cpp:150] Setting up relu36
I0925 18:54:45.679679  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.679682  4179 net.cpp:165] Memory required for data: 458942976
I0925 18:54:45.679684  4179 layer_factory.hpp:77] Creating layer conv37
I0925 18:54:45.679692  4179 net.cpp:100] Creating Layer conv37
I0925 18:54:45.679695  4179 net.cpp:434] conv37 <- maxout36
I0925 18:54:45.679699  4179 net.cpp:408] conv37 -> conv37
I0925 18:54:45.680316  4179 net.cpp:150] Setting up conv37
I0925 18:54:45.680325  4179 net.cpp:157] Top shape: 32 1 72 72 (165888)
I0925 18:54:45.680330  4179 net.cpp:165] Memory required for data: 459606528
I0925 18:54:45.680332  4179 net.cpp:493] Sharing parameters 'conv_W7' owned by layer 'conv27', param index 0
I0925 18:54:45.680336  4179 net.cpp:493] Sharing parameters 'conv_b7' owned by layer 'conv27', param index 1
I0925 18:54:45.680340  4179 layer_factory.hpp:77] Creating layer conv41
I0925 18:54:45.680346  4179 net.cpp:100] Creating Layer conv41
I0925 18:54:45.680351  4179 net.cpp:434] conv41 <- low4
I0925 18:54:45.680354  4179 net.cpp:408] conv41 -> conv41
I0925 18:54:45.680966  4179 net.cpp:150] Setting up conv41
I0925 18:54:45.680975  4179 net.cpp:157] Top shape: 32 16 18 18 (165888)
I0925 18:54:45.680979  4179 net.cpp:165] Memory required for data: 460270080
I0925 18:54:45.680981  4179 net.cpp:493] Sharing parameters 'conv_W1' owned by layer 'conv21', param index 0
I0925 18:54:45.680985  4179 net.cpp:493] Sharing parameters 'conv_b1' owned by layer 'conv21', param index 1
I0925 18:54:45.680989  4179 layer_factory.hpp:77] Creating layer relu41
I0925 18:54:45.680992  4179 net.cpp:100] Creating Layer relu41
I0925 18:54:45.680995  4179 net.cpp:434] relu41 <- conv41
I0925 18:54:45.680999  4179 net.cpp:395] relu41 -> conv41 (in-place)
I0925 18:54:45.681102  4179 net.cpp:150] Setting up relu41
I0925 18:54:45.681109  4179 net.cpp:157] Top shape: 32 16 18 18 (165888)
I0925 18:54:45.681113  4179 net.cpp:165] Memory required for data: 460933632
I0925 18:54:45.681114  4179 layer_factory.hpp:77] Creating layer conv42
I0925 18:54:45.681121  4179 net.cpp:100] Creating Layer conv42
I0925 18:54:45.681124  4179 net.cpp:434] conv42 <- conv41
I0925 18:54:45.681129  4179 net.cpp:408] conv42 -> conv42
I0925 18:54:45.681793  4179 net.cpp:150] Setting up conv42
I0925 18:54:45.681802  4179 net.cpp:157] Top shape: 32 16 18 18 (165888)
I0925 18:54:45.681805  4179 net.cpp:165] Memory required for data: 461597184
I0925 18:54:45.681808  4179 net.cpp:493] Sharing parameters 'conv_W2' owned by layer 'conv22', param index 0
I0925 18:54:45.681812  4179 net.cpp:493] Sharing parameters 'conv_b2' owned by layer 'conv22', param index 1
I0925 18:54:45.681814  4179 layer_factory.hpp:77] Creating layer bn42
I0925 18:54:45.681819  4179 net.cpp:100] Creating Layer bn42
I0925 18:54:45.681823  4179 net.cpp:434] bn42 <- conv42
I0925 18:54:45.681826  4179 net.cpp:395] bn42 -> conv42 (in-place)
I0925 18:54:45.681947  4179 net.cpp:150] Setting up bn42
I0925 18:54:45.681952  4179 net.cpp:157] Top shape: 32 16 18 18 (165888)
I0925 18:54:45.681955  4179 net.cpp:165] Memory required for data: 462260736
I0925 18:54:45.681960  4179 layer_factory.hpp:77] Creating layer relu42
I0925 18:54:45.681965  4179 net.cpp:100] Creating Layer relu42
I0925 18:54:45.681968  4179 net.cpp:434] relu42 <- conv42
I0925 18:54:45.681972  4179 net.cpp:395] relu42 -> conv42 (in-place)
I0925 18:54:45.682150  4179 net.cpp:150] Setting up relu42
I0925 18:54:45.682158  4179 net.cpp:157] Top shape: 32 16 18 18 (165888)
I0925 18:54:45.682162  4179 net.cpp:165] Memory required for data: 462924288
I0925 18:54:45.682164  4179 layer_factory.hpp:77] Creating layer conv43
I0925 18:54:45.682173  4179 net.cpp:100] Creating Layer conv43
I0925 18:54:45.682176  4179 net.cpp:434] conv43 <- conv42
I0925 18:54:45.682180  4179 net.cpp:408] conv43 -> conv43
I0925 18:54:45.682795  4179 net.cpp:150] Setting up conv43
I0925 18:54:45.682803  4179 net.cpp:157] Top shape: 32 16 18 18 (165888)
I0925 18:54:45.682806  4179 net.cpp:165] Memory required for data: 463587840
I0925 18:54:45.682809  4179 net.cpp:493] Sharing parameters 'conv_W3' owned by layer 'conv23', param index 0
I0925 18:54:45.682812  4179 net.cpp:493] Sharing parameters 'conv_b3' owned by layer 'conv23', param index 1
I0925 18:54:45.682816  4179 layer_factory.hpp:77] Creating layer bn43
I0925 18:54:45.682821  4179 net.cpp:100] Creating Layer bn43
I0925 18:54:45.682823  4179 net.cpp:434] bn43 <- conv43
I0925 18:54:45.682826  4179 net.cpp:395] bn43 -> conv43 (in-place)
I0925 18:54:45.682947  4179 net.cpp:150] Setting up bn43
I0925 18:54:45.682952  4179 net.cpp:157] Top shape: 32 16 18 18 (165888)
I0925 18:54:45.682955  4179 net.cpp:165] Memory required for data: 464251392
I0925 18:54:45.682960  4179 layer_factory.hpp:77] Creating layer relu4-13
I0925 18:54:45.682965  4179 net.cpp:100] Creating Layer relu4-13
I0925 18:54:45.682968  4179 net.cpp:434] relu4-13 <- conv43
I0925 18:54:45.682971  4179 net.cpp:395] relu4-13 -> conv43 (in-place)
I0925 18:54:45.683151  4179 net.cpp:150] Setting up relu4-13
I0925 18:54:45.683158  4179 net.cpp:157] Top shape: 32 16 18 18 (165888)
I0925 18:54:45.683161  4179 net.cpp:165] Memory required for data: 464914944
I0925 18:54:45.683164  4179 layer_factory.hpp:77] Creating layer deconv44
I0925 18:54:45.683171  4179 net.cpp:100] Creating Layer deconv44
I0925 18:54:45.683173  4179 net.cpp:434] deconv44 <- conv43
I0925 18:54:45.683177  4179 net.cpp:408] deconv44 -> deconv44
I0925 18:54:45.685183  4179 net.cpp:150] Setting up deconv44
I0925 18:54:45.685190  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.685194  4179 net.cpp:165] Memory required for data: 475531776
I0925 18:54:45.685202  4179 layer_factory.hpp:77] Creating layer relu44
I0925 18:54:45.685207  4179 net.cpp:100] Creating Layer relu44
I0925 18:54:45.685210  4179 net.cpp:434] relu44 <- deconv44
I0925 18:54:45.685214  4179 net.cpp:395] relu44 -> deconv44 (in-place)
I0925 18:54:45.685396  4179 net.cpp:150] Setting up relu44
I0925 18:54:45.685405  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.685407  4179 net.cpp:165] Memory required for data: 486148608
I0925 18:54:45.685410  4179 layer_factory.hpp:77] Creating layer conv45
I0925 18:54:45.685418  4179 net.cpp:100] Creating Layer conv45
I0925 18:54:45.685422  4179 net.cpp:434] conv45 <- deconv44
I0925 18:54:45.685426  4179 net.cpp:408] conv45 -> conv45
I0925 18:54:45.686203  4179 net.cpp:150] Setting up conv45
I0925 18:54:45.686213  4179 net.cpp:157] Top shape: 32 48 72 72 (7962624)
I0925 18:54:45.686215  4179 net.cpp:165] Memory required for data: 517999104
I0925 18:54:45.686218  4179 net.cpp:493] Sharing parameters 'conv_W5' owned by layer 'conv25', param index 0
I0925 18:54:45.686221  4179 net.cpp:493] Sharing parameters 'conv_b5' owned by layer 'conv25', param index 1
I0925 18:54:45.686225  4179 layer_factory.hpp:77] Creating layer slice45
I0925 18:54:45.686229  4179 net.cpp:100] Creating Layer slice45
I0925 18:54:45.686233  4179 net.cpp:434] slice45 <- conv45
I0925 18:54:45.686236  4179 net.cpp:408] slice45 -> conv45-a
I0925 18:54:45.686242  4179 net.cpp:408] slice45 -> conv45-b
I0925 18:54:45.686247  4179 net.cpp:408] slice45 -> conv45-c
I0925 18:54:45.686280  4179 net.cpp:150] Setting up slice45
I0925 18:54:45.686285  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.686288  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.686291  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.686293  4179 net.cpp:165] Memory required for data: 549849600
I0925 18:54:45.686296  4179 layer_factory.hpp:77] Creating layer maxout45
I0925 18:54:45.686300  4179 net.cpp:100] Creating Layer maxout45
I0925 18:54:45.686303  4179 net.cpp:434] maxout45 <- conv45-a
I0925 18:54:45.686306  4179 net.cpp:434] maxout45 <- conv45-b
I0925 18:54:45.686309  4179 net.cpp:434] maxout45 <- conv45-c
I0925 18:54:45.686319  4179 net.cpp:408] maxout45 -> maxout45
I0925 18:54:45.686344  4179 net.cpp:150] Setting up maxout45
I0925 18:54:45.686348  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.686352  4179 net.cpp:165] Memory required for data: 560466432
I0925 18:54:45.686353  4179 layer_factory.hpp:77] Creating layer bn45
I0925 18:54:45.686357  4179 net.cpp:100] Creating Layer bn45
I0925 18:54:45.686359  4179 net.cpp:434] bn45 <- maxout45
I0925 18:54:45.686363  4179 net.cpp:395] bn45 -> maxout45 (in-place)
I0925 18:54:45.686480  4179 net.cpp:150] Setting up bn45
I0925 18:54:45.686486  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.686487  4179 net.cpp:165] Memory required for data: 571083264
I0925 18:54:45.686492  4179 layer_factory.hpp:77] Creating layer relu45
I0925 18:54:45.686497  4179 net.cpp:100] Creating Layer relu45
I0925 18:54:45.686501  4179 net.cpp:434] relu45 <- maxout45
I0925 18:54:45.686506  4179 net.cpp:395] relu45 -> maxout45 (in-place)
I0925 18:54:45.686689  4179 net.cpp:150] Setting up relu45
I0925 18:54:45.686697  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.686700  4179 net.cpp:165] Memory required for data: 581700096
I0925 18:54:45.686702  4179 layer_factory.hpp:77] Creating layer conv46
I0925 18:54:45.686710  4179 net.cpp:100] Creating Layer conv46
I0925 18:54:45.686713  4179 net.cpp:434] conv46 <- maxout45
I0925 18:54:45.686718  4179 net.cpp:408] conv46 -> conv46
I0925 18:54:45.687496  4179 net.cpp:150] Setting up conv46
I0925 18:54:45.687505  4179 net.cpp:157] Top shape: 32 48 72 72 (7962624)
I0925 18:54:45.687508  4179 net.cpp:165] Memory required for data: 613550592
I0925 18:54:45.687511  4179 net.cpp:493] Sharing parameters 'conv_W6' owned by layer 'conv26', param index 0
I0925 18:54:45.687515  4179 net.cpp:493] Sharing parameters 'conv_b6' owned by layer 'conv26', param index 1
I0925 18:54:45.687518  4179 layer_factory.hpp:77] Creating layer slice46
I0925 18:54:45.687522  4179 net.cpp:100] Creating Layer slice46
I0925 18:54:45.687525  4179 net.cpp:434] slice46 <- conv46
I0925 18:54:45.687530  4179 net.cpp:408] slice46 -> conv46-a
I0925 18:54:45.687536  4179 net.cpp:408] slice46 -> conv46-b
I0925 18:54:45.687541  4179 net.cpp:408] slice46 -> conv46-c
I0925 18:54:45.687572  4179 net.cpp:150] Setting up slice46
I0925 18:54:45.687577  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.687580  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.687583  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.687587  4179 net.cpp:165] Memory required for data: 645401088
I0925 18:54:45.687589  4179 layer_factory.hpp:77] Creating layer maxout46
I0925 18:54:45.687597  4179 net.cpp:100] Creating Layer maxout46
I0925 18:54:45.687599  4179 net.cpp:434] maxout46 <- conv46-a
I0925 18:54:45.687602  4179 net.cpp:434] maxout46 <- conv46-b
I0925 18:54:45.687605  4179 net.cpp:434] maxout46 <- conv46-c
I0925 18:54:45.687608  4179 net.cpp:408] maxout46 -> maxout46
I0925 18:54:45.687631  4179 net.cpp:150] Setting up maxout46
I0925 18:54:45.687636  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.687638  4179 net.cpp:165] Memory required for data: 656017920
I0925 18:54:45.687641  4179 layer_factory.hpp:77] Creating layer bn46
I0925 18:54:45.687645  4179 net.cpp:100] Creating Layer bn46
I0925 18:54:45.687649  4179 net.cpp:434] bn46 <- maxout46
I0925 18:54:45.687651  4179 net.cpp:395] bn46 -> maxout46 (in-place)
I0925 18:54:45.687767  4179 net.cpp:150] Setting up bn46
I0925 18:54:45.687772  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.687775  4179 net.cpp:165] Memory required for data: 666634752
I0925 18:54:45.687779  4179 layer_factory.hpp:77] Creating layer relu46
I0925 18:54:45.687784  4179 net.cpp:100] Creating Layer relu46
I0925 18:54:45.687788  4179 net.cpp:434] relu46 <- maxout46
I0925 18:54:45.687791  4179 net.cpp:395] relu46 -> maxout46 (in-place)
I0925 18:54:45.687898  4179 net.cpp:150] Setting up relu46
I0925 18:54:45.687906  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.687913  4179 net.cpp:165] Memory required for data: 677251584
I0925 18:54:45.687916  4179 layer_factory.hpp:77] Creating layer conv47
I0925 18:54:45.687923  4179 net.cpp:100] Creating Layer conv47
I0925 18:54:45.687927  4179 net.cpp:434] conv47 <- maxout46
I0925 18:54:45.687932  4179 net.cpp:408] conv47 -> conv47
I0925 18:54:45.688566  4179 net.cpp:150] Setting up conv47
I0925 18:54:45.688576  4179 net.cpp:157] Top shape: 32 1 72 72 (165888)
I0925 18:54:45.688580  4179 net.cpp:165] Memory required for data: 677915136
I0925 18:54:45.688582  4179 net.cpp:493] Sharing parameters 'conv_W7' owned by layer 'conv27', param index 0
I0925 18:54:45.688585  4179 net.cpp:493] Sharing parameters 'conv_b7' owned by layer 'conv27', param index 1
I0925 18:54:45.688588  4179 layer_factory.hpp:77] Creating layer loss2
I0925 18:54:45.688596  4179 net.cpp:100] Creating Layer loss2
I0925 18:54:45.688598  4179 net.cpp:434] loss2 <- conv27
I0925 18:54:45.688601  4179 net.cpp:434] loss2 <- label_label_0_split_0
I0925 18:54:45.688606  4179 net.cpp:408] loss2 -> loss2
I0925 18:54:45.688635  4179 net.cpp:150] Setting up loss2
I0925 18:54:45.688640  4179 net.cpp:157] Top shape: (1)
I0925 18:54:45.688643  4179 net.cpp:160]     with loss weight 0.5
I0925 18:54:45.688655  4179 net.cpp:165] Memory required for data: 677915140
I0925 18:54:45.688658  4179 layer_factory.hpp:77] Creating layer loss3
I0925 18:54:45.688662  4179 net.cpp:100] Creating Layer loss3
I0925 18:54:45.688664  4179 net.cpp:434] loss3 <- conv37
I0925 18:54:45.688668  4179 net.cpp:434] loss3 <- label_label_0_split_1
I0925 18:54:45.688670  4179 net.cpp:408] loss3 -> loss3
I0925 18:54:45.688695  4179 net.cpp:150] Setting up loss3
I0925 18:54:45.688699  4179 net.cpp:157] Top shape: (1)
I0925 18:54:45.688702  4179 net.cpp:160]     with loss weight 0.3
I0925 18:54:45.688706  4179 net.cpp:165] Memory required for data: 677915144
I0925 18:54:45.688709  4179 layer_factory.hpp:77] Creating layer loss4
I0925 18:54:45.688711  4179 net.cpp:100] Creating Layer loss4
I0925 18:54:45.688714  4179 net.cpp:434] loss4 <- conv47
I0925 18:54:45.688717  4179 net.cpp:434] loss4 <- label_label_0_split_2
I0925 18:54:45.688722  4179 net.cpp:408] loss4 -> loss4
I0925 18:54:45.688745  4179 net.cpp:150] Setting up loss4
I0925 18:54:45.688750  4179 net.cpp:157] Top shape: (1)
I0925 18:54:45.688753  4179 net.cpp:160]     with loss weight 0.2
I0925 18:54:45.688756  4179 net.cpp:165] Memory required for data: 677915148
I0925 18:54:45.688758  4179 net.cpp:226] loss4 needs backward computation.
I0925 18:54:45.688761  4179 net.cpp:226] loss3 needs backward computation.
I0925 18:54:45.688763  4179 net.cpp:226] loss2 needs backward computation.
I0925 18:54:45.688766  4179 net.cpp:226] conv47 needs backward computation.
I0925 18:54:45.688769  4179 net.cpp:226] relu46 needs backward computation.
I0925 18:54:45.688771  4179 net.cpp:226] bn46 needs backward computation.
I0925 18:54:45.688773  4179 net.cpp:226] maxout46 needs backward computation.
I0925 18:54:45.688776  4179 net.cpp:226] slice46 needs backward computation.
I0925 18:54:45.688779  4179 net.cpp:226] conv46 needs backward computation.
I0925 18:54:45.688781  4179 net.cpp:226] relu45 needs backward computation.
I0925 18:54:45.688783  4179 net.cpp:226] bn45 needs backward computation.
I0925 18:54:45.688786  4179 net.cpp:226] maxout45 needs backward computation.
I0925 18:54:45.688788  4179 net.cpp:226] slice45 needs backward computation.
I0925 18:54:45.688791  4179 net.cpp:226] conv45 needs backward computation.
I0925 18:54:45.688793  4179 net.cpp:226] relu44 needs backward computation.
I0925 18:54:45.688796  4179 net.cpp:226] deconv44 needs backward computation.
I0925 18:54:45.688798  4179 net.cpp:226] relu4-13 needs backward computation.
I0925 18:54:45.688801  4179 net.cpp:226] bn43 needs backward computation.
I0925 18:54:45.688803  4179 net.cpp:226] conv43 needs backward computation.
I0925 18:54:45.688805  4179 net.cpp:226] relu42 needs backward computation.
I0925 18:54:45.688807  4179 net.cpp:226] bn42 needs backward computation.
I0925 18:54:45.688809  4179 net.cpp:226] conv42 needs backward computation.
I0925 18:54:45.688818  4179 net.cpp:226] relu41 needs backward computation.
I0925 18:54:45.688820  4179 net.cpp:226] conv41 needs backward computation.
I0925 18:54:45.688823  4179 net.cpp:226] conv37 needs backward computation.
I0925 18:54:45.688827  4179 net.cpp:226] relu36 needs backward computation.
I0925 18:54:45.688828  4179 net.cpp:226] bn36 needs backward computation.
I0925 18:54:45.688830  4179 net.cpp:226] maxout36 needs backward computation.
I0925 18:54:45.688833  4179 net.cpp:226] slice36 needs backward computation.
I0925 18:54:45.688837  4179 net.cpp:226] conv36 needs backward computation.
I0925 18:54:45.688838  4179 net.cpp:226] relu35 needs backward computation.
I0925 18:54:45.688841  4179 net.cpp:226] bn35 needs backward computation.
I0925 18:54:45.688843  4179 net.cpp:226] maxout35 needs backward computation.
I0925 18:54:45.688845  4179 net.cpp:226] slice35 needs backward computation.
I0925 18:54:45.688848  4179 net.cpp:226] conv35 needs backward computation.
I0925 18:54:45.688850  4179 net.cpp:226] relu34 needs backward computation.
I0925 18:54:45.688853  4179 net.cpp:226] deconv34 needs backward computation.
I0925 18:54:45.688856  4179 net.cpp:226] relu3-13 needs backward computation.
I0925 18:54:45.688858  4179 net.cpp:226] bn33 needs backward computation.
I0925 18:54:45.688860  4179 net.cpp:226] conv33 needs backward computation.
I0925 18:54:45.688863  4179 net.cpp:226] relu32 needs backward computation.
I0925 18:54:45.688864  4179 net.cpp:226] bn32 needs backward computation.
I0925 18:54:45.688868  4179 net.cpp:226] conv32 needs backward computation.
I0925 18:54:45.688869  4179 net.cpp:226] relu31 needs backward computation.
I0925 18:54:45.688872  4179 net.cpp:226] conv31 needs backward computation.
I0925 18:54:45.688874  4179 net.cpp:226] conv27 needs backward computation.
I0925 18:54:45.688876  4179 net.cpp:226] relu26 needs backward computation.
I0925 18:54:45.688879  4179 net.cpp:226] bn26 needs backward computation.
I0925 18:54:45.688881  4179 net.cpp:226] maxout26 needs backward computation.
I0925 18:54:45.688884  4179 net.cpp:226] slice26 needs backward computation.
I0925 18:54:45.688887  4179 net.cpp:226] conv26 needs backward computation.
I0925 18:54:45.688889  4179 net.cpp:226] relu25 needs backward computation.
I0925 18:54:45.688892  4179 net.cpp:226] bn25 needs backward computation.
I0925 18:54:45.688894  4179 net.cpp:226] maxout25 needs backward computation.
I0925 18:54:45.688897  4179 net.cpp:226] slice25 needs backward computation.
I0925 18:54:45.688900  4179 net.cpp:226] conv25 needs backward computation.
I0925 18:54:45.688902  4179 net.cpp:226] relu24 needs backward computation.
I0925 18:54:45.688905  4179 net.cpp:226] deconv24 needs backward computation.
I0925 18:54:45.688907  4179 net.cpp:226] relu2-13 needs backward computation.
I0925 18:54:45.688910  4179 net.cpp:226] bn23 needs backward computation.
I0925 18:54:45.688912  4179 net.cpp:226] conv23 needs backward computation.
I0925 18:54:45.688915  4179 net.cpp:226] relu22 needs backward computation.
I0925 18:54:45.688917  4179 net.cpp:226] bn22 needs backward computation.
I0925 18:54:45.688920  4179 net.cpp:226] conv22 needs backward computation.
I0925 18:54:45.688921  4179 net.cpp:226] relu21 needs backward computation.
I0925 18:54:45.688925  4179 net.cpp:226] conv21 needs backward computation.
I0925 18:54:45.688927  4179 net.cpp:228] label_label_0_split does not need backward computation.
I0925 18:54:45.688930  4179 net.cpp:228] label does not need backward computation.
I0925 18:54:45.688932  4179 net.cpp:228] low4 does not need backward computation.
I0925 18:54:45.688935  4179 net.cpp:228] low3 does not need backward computation.
I0925 18:54:45.688937  4179 net.cpp:228] low2 does not need backward computation.
I0925 18:54:45.688940  4179 net.cpp:270] This network produces output loss2
I0925 18:54:45.688941  4179 net.cpp:270] This network produces output loss3
I0925 18:54:45.688944  4179 net.cpp:270] This network produces output loss4
I0925 18:54:45.689131  4179 net.cpp:283] Network initialization done.
I0925 18:54:45.690073  4179 solver.cpp:181] Creating test net (#0) specified by net file: AESR/AESR_net.prototxt
I0925 18:54:45.690127  4179 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer low2
I0925 18:54:45.690132  4179 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer low3
I0925 18:54:45.690135  4179 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer low4
I0925 18:54:45.690136  4179 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer label
I0925 18:54:45.690367  4179 net.cpp:58] Initializing net from parameters: 
name: "AESR"
state {
  phase: TEST
}
layer {
  name: "low2"
  type: "HDF5Data"
  top: "low2"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "AESR/hdf5/ts_txt/low2.txt"
    batch_size: 32
  }
}
layer {
  name: "low3"
  type: "HDF5Data"
  top: "low3"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "AESR/hdf5/ts_txt/low3.txt"
    batch_size: 32
  }
}
layer {
  name: "low4"
  type: "HDF5Data"
  top: "low4"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "AESR/hdf5/ts_txt/low4.txt"
    batch_size: 32
  }
}
layer {
  name: "label"
  type: "HDF5Data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "AESR/hdf5/ts_txt/label.txt"
    batch_size: 32
  }
}
layer {
  name: "conv21"
  type: "Convolution"
  bottom: "low2"
  top: "conv21"
  param {
    name: "conv_W1"
    lr_mult: 0.3
  }
  param {
    name: "conv_b1"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "relu21"
  type: "ReLU"
  bottom: "conv21"
  top: "conv21"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv22"
  type: "Convolution"
  bottom: "conv21"
  top: "conv22"
  param {
    name: "conv_W2"
    lr_mult: 0.3
  }
  param {
    name: "conv_b2"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "bn22"
  type: "BatchNorm"
  bottom: "conv22"
  top: "conv22"
}
layer {
  name: "relu22"
  type: "ReLU"
  bottom: "conv22"
  top: "conv22"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv23"
  type: "Convolution"
  bottom: "conv22"
  top: "conv23"
  param {
    name: "conv_W3"
    lr_mult: 0.3
  }
  param {
    name: "conv_b3"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "bn23"
  type: "BatchNorm"
  bottom: "conv23"
  top: "conv23"
}
layer {
  name: "relu2-13"
  type: "ReLU"
  bottom: "conv23"
  top: "conv23"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "deconv24"
  type: "Deconvolution"
  bottom: "conv23"
  top: "deconv24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 6
    kernel_size: 14
    stride: 2
    weight_filler {
      type: "bilinear"
    }
    engine: CUDNN
  }
}
layer {
  name: "relu24"
  type: "ReLU"
  bottom: "deconv24"
  top: "deconv24"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv25"
  type: "Convolution"
  bottom: "deconv24"
  top: "conv25"
  param {
    name: "conv_W5"
    lr_mult: 0.3
  }
  param {
    name: "conv_b5"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "slice25"
  type: "Slice"
  bottom: "conv25"
  top: "conv25-a"
  top: "conv25-b"
  top: "conv25-c"
  slice_param {
    axis: 1
  }
}
layer {
  name: "maxout25"
  type: "Eltwise"
  bottom: "conv25-a"
  bottom: "conv25-b"
  bottom: "conv25-c"
  top: "maxout25"
  eltwise_param {
    operation: MAX
  }
}
layer {
  name: "bn25"
  type: "BatchNorm"
  bottom: "maxout25"
  top: "maxout25"
}
layer {
  name: "relu25"
  type: "ReLU"
  bottom: "maxout25"
  top: "maxout25"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv26"
  type: "Convolution"
  bottom: "maxout25"
  top: "conv26"
  param {
    name: "conv_W6"
    lr_mult: 0.3
  }
  param {
    name: "conv_b6"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "slice26"
  type: "Slice"
  bottom: "conv26"
  top: "conv26-a"
  top: "conv26-b"
  top: "conv26-c"
  slice_param {
    axis: 1
  }
}
layer {
  name: "maxout26"
  type: "Eltwise"
  bottom: "conv26-a"
  bottom: "conv26-b"
  bottom: "conv26-c"
  top: "maxout26"
  eltwise_param {
    operation: MAX
  }
}
layer {
  name: "bn26"
  type: "BatchNorm"
  bottom: "maxout26"
  top: "maxout26"
}
layer {
  name: "relu26"
  type: "ReLU"
  bottom: "maxout26"
  top: "maxout26"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv27"
  type: "Convolution"
  bottom: "maxout26"
  top: "conv27"
  param {
    name: "conv_W7"
    lr_mult: 0.3
  }
  param {
    name: "conv_b7"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 1
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "conv31"
  type: "Convolution"
  bottom: "low3"
  top: "conv31"
  param {
    name: "conv_W1"
    lr_mult: 0.3
  }
  param {
    name: "conv_b1"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "relu31"
  type: "ReLU"
  bottom: "conv31"
  top: "conv31"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv32"
  type: "Convolution"
  bottom: "conv31"
  top: "conv32"
  param {
    name: "conv_W2"
    lr_mult: 0.3
  }
  param {
    name: "conv_b2"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "bn32"
  type: "BatchNorm"
  bottom: "conv32"
  top: "conv32"
}
layer {
  name: "relu32"
  type: "ReLU"
  bottom: "conv32"
  top: "conv32"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv33"
  type: "Convolution"
  bottom: "conv32"
  top: "conv33"
  param {
    name: "conv_W3"
    lr_mult: 0.3
  }
  param {
    name: "conv_b3"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "bn33"
  type: "BatchNorm"
  bottom: "conv33"
  top: "conv33"
}
layer {
  name: "relu3-13"
  type: "ReLU"
  bottom: "conv33"
  top: "conv33"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "deconv34"
  type: "Deconvolution"
  bottom: "conv33"
  top: "deconv34"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 6
    kernel_size: 15
    stride: 3
    weight_filler {
      type: "bilinear"
    }
    engine: CUDNN
  }
}
layer {
  name: "relu34"
  type: "ReLU"
  bottom: "deconv34"
  top: "deconv34"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv35"
  type: "Convolution"
  bottom: "deconv34"
  top: "conv35"
  param {
    name: "conv_W5"
    lr_mult: 0.3
  }
  param {
    name: "conv_b5"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "slice35"
  type: "Slice"
  bottom: "conv35"
  top: "conv35-a"
  top: "conv35-b"
  top: "conv35-c"
  slice_param {
    axis: 1
  }
}
layer {
  name: "maxout35"
  type: "Eltwise"
  bottom: "conv35-a"
  bottom: "conv35-b"
  bottom: "conv35-c"
  top: "maxout35"
  eltwise_param {
    operation: MAX
  }
}
layer {
  name: "bn35"
  type: "BatchNorm"
  bottom: "maxout35"
  top: "maxout35"
}
layer {
  name: "relu35"
  type: "ReLU"
  bottom: "maxout35"
  top: "maxout35"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv36"
  type: "Convolution"
  bottom: "maxout35"
  top: "conv36"
  param {
    name: "conv_W6"
    lr_mult: 0.3
  }
  param {
    name: "conv_b6"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "slice36"
  type: "Slice"
  bottom: "conv36"
  top: "conv36-a"
  top: "conv36-b"
  top: "conv36-c"
  slice_param {
    axis: 1
  }
}
layer {
  name: "maxout36"
  type: "Eltwise"
  bottom: "conv36-a"
  bottom: "conv36-b"
  bottom: "conv36-c"
  top: "maxout36"
  eltwise_param {
    operation: MAX
  }
}
layer {
  name: "bn36"
  type: "BatchNorm"
  bottom: "maxout36"
  top: "maxout36"
}
layer {
  name: "relu36"
  type: "ReLU"
  bottom: "maxout36"
  top: "maxout36"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv37"
  type: "Convolution"
  bottom: "maxout36"
  top: "conv37"
  param {
    name: "conv_W7"
    lr_mult: 0.3
  }
  param {
    name: "conv_b7"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 1
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "conv41"
  type: "Convolution"
  bottom: "low4"
  top: "conv41"
  param {
    name: "conv_W1"
    lr_mult: 0.3
  }
  param {
    name: "conv_b1"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "relu41"
  type: "ReLU"
  bottom: "conv41"
  top: "conv41"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv42"
  type: "Convolution"
  bottom: "conv41"
  top: "conv42"
  param {
    name: "conv_W2"
    lr_mult: 0.3
  }
  param {
    name: "conv_b2"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "bn42"
  type: "BatchNorm"
  bottom: "conv42"
  top: "conv42"
}
layer {
  name: "relu42"
  type: "ReLU"
  bottom: "conv42"
  top: "conv42"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv43"
  type: "Convolution"
  bottom: "conv42"
  top: "conv43"
  param {
    name: "conv_W3"
    lr_mult: 0.3
  }
  param {
    name: "conv_b3"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "bn43"
  type: "BatchNorm"
  bottom: "conv43"
  top: "conv43"
}
layer {
  name: "relu4-13"
  type: "ReLU"
  bottom: "conv43"
  top: "conv43"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "deconv44"
  type: "Deconvolution"
  bottom: "conv43"
  top: "deconv44"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 6
    kernel_size: 16
    stride: 4
    weight_filler {
      type: "bilinear"
    }
    engine: CUDNN
  }
}
layer {
  name: "relu44"
  type: "ReLU"
  bottom: "deconv44"
  top: "deconv44"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv45"
  type: "Convolution"
  bottom: "deconv44"
  top: "conv45"
  param {
    name: "conv_W5"
    lr_mult: 0.3
  }
  param {
    name: "conv_b5"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "slice45"
  type: "Slice"
  bottom: "conv45"
  top: "conv45-a"
  top: "conv45-b"
  top: "conv45-c"
  slice_param {
    axis: 1
  }
}
layer {
  name: "maxout45"
  type: "Eltwise"
  bottom: "conv45-a"
  bottom: "conv45-b"
  bottom: "conv45-c"
  top: "maxout45"
  eltwise_param {
    operation: MAX
  }
}
layer {
  name: "bn45"
  type: "BatchNorm"
  bottom: "maxout45"
  top: "maxout45"
}
layer {
  name: "relu45"
  type: "ReLU"
  bottom: "maxout45"
  top: "maxout45"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv46"
  type: "Convolution"
  bottom: "maxout45"
  top: "conv46"
  param {
    name: "conv_W6"
    lr_mult: 0.3
  }
  param {
    name: "conv_b6"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "slice46"
  type: "Slice"
  bottom: "conv46"
  top: "conv46-a"
  top: "conv46-b"
  top: "conv46-c"
  slice_param {
    axis: 1
  }
}
layer {
  name: "maxout46"
  type: "Eltwise"
  bottom: "conv46-a"
  bottom: "conv46-b"
  bottom: "conv46-c"
  top: "maxout46"
  eltwise_param {
    operation: MAX
  }
}
layer {
  name: "bn46"
  type: "BatchNorm"
  bottom: "maxout46"
  top: "maxout46"
}
layer {
  name: "relu46"
  type: "ReLU"
  bottom: "maxout46"
  top: "maxout46"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv47"
  type: "Convolution"
  bottom: "maxout46"
  top: "conv47"
  param {
    name: "conv_W7"
    lr_mult: 0.3
  }
  param {
    name: "conv_b7"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 1
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "loss2"
  type: "EuclideanLoss"
  bottom: "conv27"
  bottom: "label"
  top: "loss2"
  loss_weight: 0.5
}
layer {
  name: "loss3"
  type: "EuclideanLoss"
  bottom: "conv37"
  bottom: "label"
  top: "loss3"
  loss_weight: 0.3
}
layer {
  name: "loss4"
  type: "EuclideanLoss"
  bottom: "conv47"
  bottom: "label"
  top: "loss4"
  loss_weight: 0.2
}
I0925 18:54:45.690516  4179 layer_factory.hpp:77] Creating layer low2
I0925 18:54:45.690523  4179 net.cpp:100] Creating Layer low2
I0925 18:54:45.690526  4179 net.cpp:408] low2 -> low2
I0925 18:54:45.690531  4179 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: AESR/hdf5/ts_txt/low2.txt
I0925 18:54:45.690578  4179 hdf5_data_layer.cpp:93] Number of HDF5 files: 196
I0925 18:54:45.690960  4179 net.cpp:150] Setting up low2
I0925 18:54:45.690969  4179 net.cpp:157] Top shape: 32 1 36 36 (41472)
I0925 18:54:45.690971  4179 net.cpp:165] Memory required for data: 165888
I0925 18:54:45.690979  4179 layer_factory.hpp:77] Creating layer low3
I0925 18:54:45.690984  4179 net.cpp:100] Creating Layer low3
I0925 18:54:45.690989  4179 net.cpp:408] low3 -> low3
I0925 18:54:45.690994  4179 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: AESR/hdf5/ts_txt/low3.txt
I0925 18:54:45.691036  4179 hdf5_data_layer.cpp:93] Number of HDF5 files: 196
I0925 18:54:45.691480  4179 net.cpp:150] Setting up low3
I0925 18:54:45.691489  4179 net.cpp:157] Top shape: 32 1 24 24 (18432)
I0925 18:54:45.691493  4179 net.cpp:165] Memory required for data: 239616
I0925 18:54:45.691494  4179 layer_factory.hpp:77] Creating layer low4
I0925 18:54:45.691499  4179 net.cpp:100] Creating Layer low4
I0925 18:54:45.691503  4179 net.cpp:408] low4 -> low4
I0925 18:54:45.691509  4179 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: AESR/hdf5/ts_txt/low4.txt
I0925 18:54:45.691550  4179 hdf5_data_layer.cpp:93] Number of HDF5 files: 196
I0925 18:54:45.691738  4179 net.cpp:150] Setting up low4
I0925 18:54:45.691746  4179 net.cpp:157] Top shape: 32 1 18 18 (10368)
I0925 18:54:45.691750  4179 net.cpp:165] Memory required for data: 281088
I0925 18:54:45.691751  4179 layer_factory.hpp:77] Creating layer label
I0925 18:54:45.691756  4179 net.cpp:100] Creating Layer label
I0925 18:54:45.691757  4179 net.cpp:408] label -> label
I0925 18:54:45.691763  4179 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: AESR/hdf5/ts_txt/label.txt
I0925 18:54:45.691805  4179 hdf5_data_layer.cpp:93] Number of HDF5 files: 196
I0925 18:54:45.692401  4179 net.cpp:150] Setting up label
I0925 18:54:45.692410  4179 net.cpp:157] Top shape: 32 1 72 72 (165888)
I0925 18:54:45.692414  4179 net.cpp:165] Memory required for data: 944640
I0925 18:54:45.692416  4179 layer_factory.hpp:77] Creating layer label_label_0_split
I0925 18:54:45.692422  4179 net.cpp:100] Creating Layer label_label_0_split
I0925 18:54:45.692425  4179 net.cpp:434] label_label_0_split <- label
I0925 18:54:45.692430  4179 net.cpp:408] label_label_0_split -> label_label_0_split_0
I0925 18:54:45.692435  4179 net.cpp:408] label_label_0_split -> label_label_0_split_1
I0925 18:54:45.692440  4179 net.cpp:408] label_label_0_split -> label_label_0_split_2
I0925 18:54:45.692483  4179 net.cpp:150] Setting up label_label_0_split
I0925 18:54:45.692488  4179 net.cpp:157] Top shape: 32 1 72 72 (165888)
I0925 18:54:45.692492  4179 net.cpp:157] Top shape: 32 1 72 72 (165888)
I0925 18:54:45.692494  4179 net.cpp:157] Top shape: 32 1 72 72 (165888)
I0925 18:54:45.692497  4179 net.cpp:165] Memory required for data: 2935296
I0925 18:54:45.692499  4179 layer_factory.hpp:77] Creating layer conv21
I0925 18:54:45.692505  4179 net.cpp:100] Creating Layer conv21
I0925 18:54:45.692508  4179 net.cpp:434] conv21 <- low2
I0925 18:54:45.692512  4179 net.cpp:408] conv21 -> conv21
I0925 18:54:45.693184  4179 net.cpp:150] Setting up conv21
I0925 18:54:45.693193  4179 net.cpp:157] Top shape: 32 16 36 36 (663552)
I0925 18:54:45.693197  4179 net.cpp:165] Memory required for data: 5589504
I0925 18:54:45.693202  4179 layer_factory.hpp:77] Creating layer relu21
I0925 18:54:45.693208  4179 net.cpp:100] Creating Layer relu21
I0925 18:54:45.693212  4179 net.cpp:434] relu21 <- conv21
I0925 18:54:45.693214  4179 net.cpp:395] relu21 -> conv21 (in-place)
I0925 18:54:45.693320  4179 net.cpp:150] Setting up relu21
I0925 18:54:45.693327  4179 net.cpp:157] Top shape: 32 16 36 36 (663552)
I0925 18:54:45.693330  4179 net.cpp:165] Memory required for data: 8243712
I0925 18:54:45.693332  4179 layer_factory.hpp:77] Creating layer conv22
I0925 18:54:45.693337  4179 net.cpp:100] Creating Layer conv22
I0925 18:54:45.693341  4179 net.cpp:434] conv22 <- conv21
I0925 18:54:45.693344  4179 net.cpp:408] conv22 -> conv22
I0925 18:54:45.693980  4179 net.cpp:150] Setting up conv22
I0925 18:54:45.693990  4179 net.cpp:157] Top shape: 32 16 36 36 (663552)
I0925 18:54:45.693994  4179 net.cpp:165] Memory required for data: 10897920
I0925 18:54:45.693999  4179 layer_factory.hpp:77] Creating layer bn22
I0925 18:54:45.694005  4179 net.cpp:100] Creating Layer bn22
I0925 18:54:45.694015  4179 net.cpp:434] bn22 <- conv22
I0925 18:54:45.694018  4179 net.cpp:395] bn22 -> conv22 (in-place)
I0925 18:54:45.694140  4179 net.cpp:150] Setting up bn22
I0925 18:54:45.694146  4179 net.cpp:157] Top shape: 32 16 36 36 (663552)
I0925 18:54:45.694149  4179 net.cpp:165] Memory required for data: 13552128
I0925 18:54:45.694154  4179 layer_factory.hpp:77] Creating layer relu22
I0925 18:54:45.694159  4179 net.cpp:100] Creating Layer relu22
I0925 18:54:45.694162  4179 net.cpp:434] relu22 <- conv22
I0925 18:54:45.694165  4179 net.cpp:395] relu22 -> conv22 (in-place)
I0925 18:54:45.694345  4179 net.cpp:150] Setting up relu22
I0925 18:54:45.694353  4179 net.cpp:157] Top shape: 32 16 36 36 (663552)
I0925 18:54:45.694356  4179 net.cpp:165] Memory required for data: 16206336
I0925 18:54:45.694358  4179 layer_factory.hpp:77] Creating layer conv23
I0925 18:54:45.694365  4179 net.cpp:100] Creating Layer conv23
I0925 18:54:45.694367  4179 net.cpp:434] conv23 <- conv22
I0925 18:54:45.694371  4179 net.cpp:408] conv23 -> conv23
I0925 18:54:45.694949  4179 net.cpp:150] Setting up conv23
I0925 18:54:45.694958  4179 net.cpp:157] Top shape: 32 16 36 36 (663552)
I0925 18:54:45.694962  4179 net.cpp:165] Memory required for data: 18860544
I0925 18:54:45.694967  4179 layer_factory.hpp:77] Creating layer bn23
I0925 18:54:45.694972  4179 net.cpp:100] Creating Layer bn23
I0925 18:54:45.694975  4179 net.cpp:434] bn23 <- conv23
I0925 18:54:45.694978  4179 net.cpp:395] bn23 -> conv23 (in-place)
I0925 18:54:45.695106  4179 net.cpp:150] Setting up bn23
I0925 18:54:45.695111  4179 net.cpp:157] Top shape: 32 16 36 36 (663552)
I0925 18:54:45.695113  4179 net.cpp:165] Memory required for data: 21514752
I0925 18:54:45.695118  4179 layer_factory.hpp:77] Creating layer relu2-13
I0925 18:54:45.695122  4179 net.cpp:100] Creating Layer relu2-13
I0925 18:54:45.695125  4179 net.cpp:434] relu2-13 <- conv23
I0925 18:54:45.695128  4179 net.cpp:395] relu2-13 -> conv23 (in-place)
I0925 18:54:45.695317  4179 net.cpp:150] Setting up relu2-13
I0925 18:54:45.695325  4179 net.cpp:157] Top shape: 32 16 36 36 (663552)
I0925 18:54:45.695327  4179 net.cpp:165] Memory required for data: 24168960
I0925 18:54:45.695330  4179 layer_factory.hpp:77] Creating layer deconv24
I0925 18:54:45.695335  4179 net.cpp:100] Creating Layer deconv24
I0925 18:54:45.695338  4179 net.cpp:434] deconv24 <- conv23
I0925 18:54:45.695343  4179 net.cpp:408] deconv24 -> deconv24
I0925 18:54:45.696956  4179 net.cpp:150] Setting up deconv24
I0925 18:54:45.696964  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.696966  4179 net.cpp:165] Memory required for data: 34785792
I0925 18:54:45.696970  4179 layer_factory.hpp:77] Creating layer relu24
I0925 18:54:45.696975  4179 net.cpp:100] Creating Layer relu24
I0925 18:54:45.696979  4179 net.cpp:434] relu24 <- deconv24
I0925 18:54:45.696981  4179 net.cpp:395] relu24 -> deconv24 (in-place)
I0925 18:54:45.697095  4179 net.cpp:150] Setting up relu24
I0925 18:54:45.697101  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.697103  4179 net.cpp:165] Memory required for data: 45402624
I0925 18:54:45.697105  4179 layer_factory.hpp:77] Creating layer conv25
I0925 18:54:45.697113  4179 net.cpp:100] Creating Layer conv25
I0925 18:54:45.697115  4179 net.cpp:434] conv25 <- deconv24
I0925 18:54:45.697120  4179 net.cpp:408] conv25 -> conv25
I0925 18:54:45.697902  4179 net.cpp:150] Setting up conv25
I0925 18:54:45.697911  4179 net.cpp:157] Top shape: 32 48 72 72 (7962624)
I0925 18:54:45.697914  4179 net.cpp:165] Memory required for data: 77253120
I0925 18:54:45.697918  4179 layer_factory.hpp:77] Creating layer slice25
I0925 18:54:45.697924  4179 net.cpp:100] Creating Layer slice25
I0925 18:54:45.697928  4179 net.cpp:434] slice25 <- conv25
I0925 18:54:45.697932  4179 net.cpp:408] slice25 -> conv25-a
I0925 18:54:45.697935  4179 net.cpp:408] slice25 -> conv25-b
I0925 18:54:45.697939  4179 net.cpp:408] slice25 -> conv25-c
I0925 18:54:45.697975  4179 net.cpp:150] Setting up slice25
I0925 18:54:45.697981  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.697990  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.697993  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.697995  4179 net.cpp:165] Memory required for data: 109103616
I0925 18:54:45.697998  4179 layer_factory.hpp:77] Creating layer maxout25
I0925 18:54:45.698002  4179 net.cpp:100] Creating Layer maxout25
I0925 18:54:45.698005  4179 net.cpp:434] maxout25 <- conv25-a
I0925 18:54:45.698009  4179 net.cpp:434] maxout25 <- conv25-b
I0925 18:54:45.698011  4179 net.cpp:434] maxout25 <- conv25-c
I0925 18:54:45.698015  4179 net.cpp:408] maxout25 -> maxout25
I0925 18:54:45.698040  4179 net.cpp:150] Setting up maxout25
I0925 18:54:45.698045  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.698047  4179 net.cpp:165] Memory required for data: 119720448
I0925 18:54:45.698050  4179 layer_factory.hpp:77] Creating layer bn25
I0925 18:54:45.698052  4179 net.cpp:100] Creating Layer bn25
I0925 18:54:45.698055  4179 net.cpp:434] bn25 <- maxout25
I0925 18:54:45.698058  4179 net.cpp:395] bn25 -> maxout25 (in-place)
I0925 18:54:45.698182  4179 net.cpp:150] Setting up bn25
I0925 18:54:45.698186  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.698189  4179 net.cpp:165] Memory required for data: 130337280
I0925 18:54:45.698196  4179 layer_factory.hpp:77] Creating layer relu25
I0925 18:54:45.698201  4179 net.cpp:100] Creating Layer relu25
I0925 18:54:45.698204  4179 net.cpp:434] relu25 <- maxout25
I0925 18:54:45.698207  4179 net.cpp:395] relu25 -> maxout25 (in-place)
I0925 18:54:45.698396  4179 net.cpp:150] Setting up relu25
I0925 18:54:45.698405  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.698407  4179 net.cpp:165] Memory required for data: 140954112
I0925 18:54:45.698410  4179 layer_factory.hpp:77] Creating layer conv26
I0925 18:54:45.698416  4179 net.cpp:100] Creating Layer conv26
I0925 18:54:45.698420  4179 net.cpp:434] conv26 <- maxout25
I0925 18:54:45.698423  4179 net.cpp:408] conv26 -> conv26
I0925 18:54:45.699265  4179 net.cpp:150] Setting up conv26
I0925 18:54:45.699275  4179 net.cpp:157] Top shape: 32 48 72 72 (7962624)
I0925 18:54:45.699278  4179 net.cpp:165] Memory required for data: 172804608
I0925 18:54:45.699282  4179 layer_factory.hpp:77] Creating layer slice26
I0925 18:54:45.699287  4179 net.cpp:100] Creating Layer slice26
I0925 18:54:45.699290  4179 net.cpp:434] slice26 <- conv26
I0925 18:54:45.699295  4179 net.cpp:408] slice26 -> conv26-a
I0925 18:54:45.699300  4179 net.cpp:408] slice26 -> conv26-b
I0925 18:54:45.699304  4179 net.cpp:408] slice26 -> conv26-c
I0925 18:54:45.699340  4179 net.cpp:150] Setting up slice26
I0925 18:54:45.699345  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.699348  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.699352  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.699353  4179 net.cpp:165] Memory required for data: 204655104
I0925 18:54:45.699357  4179 layer_factory.hpp:77] Creating layer maxout26
I0925 18:54:45.699360  4179 net.cpp:100] Creating Layer maxout26
I0925 18:54:45.699363  4179 net.cpp:434] maxout26 <- conv26-a
I0925 18:54:45.699367  4179 net.cpp:434] maxout26 <- conv26-b
I0925 18:54:45.699369  4179 net.cpp:434] maxout26 <- conv26-c
I0925 18:54:45.699373  4179 net.cpp:408] maxout26 -> maxout26
I0925 18:54:45.699395  4179 net.cpp:150] Setting up maxout26
I0925 18:54:45.699400  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.699403  4179 net.cpp:165] Memory required for data: 215271936
I0925 18:54:45.699405  4179 layer_factory.hpp:77] Creating layer bn26
I0925 18:54:45.699409  4179 net.cpp:100] Creating Layer bn26
I0925 18:54:45.699411  4179 net.cpp:434] bn26 <- maxout26
I0925 18:54:45.699415  4179 net.cpp:395] bn26 -> maxout26 (in-place)
I0925 18:54:45.699538  4179 net.cpp:150] Setting up bn26
I0925 18:54:45.699543  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.699547  4179 net.cpp:165] Memory required for data: 225888768
I0925 18:54:45.699553  4179 layer_factory.hpp:77] Creating layer relu26
I0925 18:54:45.699563  4179 net.cpp:100] Creating Layer relu26
I0925 18:54:45.699565  4179 net.cpp:434] relu26 <- maxout26
I0925 18:54:45.699568  4179 net.cpp:395] relu26 -> maxout26 (in-place)
I0925 18:54:45.699679  4179 net.cpp:150] Setting up relu26
I0925 18:54:45.699686  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.699688  4179 net.cpp:165] Memory required for data: 236505600
I0925 18:54:45.699690  4179 layer_factory.hpp:77] Creating layer conv27
I0925 18:54:45.699697  4179 net.cpp:100] Creating Layer conv27
I0925 18:54:45.699700  4179 net.cpp:434] conv27 <- maxout26
I0925 18:54:45.699704  4179 net.cpp:408] conv27 -> conv27
I0925 18:54:45.700423  4179 net.cpp:150] Setting up conv27
I0925 18:54:45.700433  4179 net.cpp:157] Top shape: 32 1 72 72 (165888)
I0925 18:54:45.700435  4179 net.cpp:165] Memory required for data: 237169152
I0925 18:54:45.700440  4179 layer_factory.hpp:77] Creating layer conv31
I0925 18:54:45.700448  4179 net.cpp:100] Creating Layer conv31
I0925 18:54:45.700450  4179 net.cpp:434] conv31 <- low3
I0925 18:54:45.700455  4179 net.cpp:408] conv31 -> conv31
I0925 18:54:45.701138  4179 net.cpp:150] Setting up conv31
I0925 18:54:45.701146  4179 net.cpp:157] Top shape: 32 16 24 24 (294912)
I0925 18:54:45.701149  4179 net.cpp:165] Memory required for data: 238348800
I0925 18:54:45.701153  4179 net.cpp:493] Sharing parameters 'conv_W1' owned by layer 'conv21', param index 0
I0925 18:54:45.701156  4179 net.cpp:493] Sharing parameters 'conv_b1' owned by layer 'conv21', param index 1
I0925 18:54:45.701159  4179 layer_factory.hpp:77] Creating layer relu31
I0925 18:54:45.701162  4179 net.cpp:100] Creating Layer relu31
I0925 18:54:45.701166  4179 net.cpp:434] relu31 <- conv31
I0925 18:54:45.701170  4179 net.cpp:395] relu31 -> conv31 (in-place)
I0925 18:54:45.701280  4179 net.cpp:150] Setting up relu31
I0925 18:54:45.701287  4179 net.cpp:157] Top shape: 32 16 24 24 (294912)
I0925 18:54:45.701289  4179 net.cpp:165] Memory required for data: 239528448
I0925 18:54:45.701292  4179 layer_factory.hpp:77] Creating layer conv32
I0925 18:54:45.701299  4179 net.cpp:100] Creating Layer conv32
I0925 18:54:45.701303  4179 net.cpp:434] conv32 <- conv31
I0925 18:54:45.701306  4179 net.cpp:408] conv32 -> conv32
I0925 18:54:45.701994  4179 net.cpp:150] Setting up conv32
I0925 18:54:45.702003  4179 net.cpp:157] Top shape: 32 16 24 24 (294912)
I0925 18:54:45.702006  4179 net.cpp:165] Memory required for data: 240708096
I0925 18:54:45.702009  4179 net.cpp:493] Sharing parameters 'conv_W2' owned by layer 'conv22', param index 0
I0925 18:54:45.702013  4179 net.cpp:493] Sharing parameters 'conv_b2' owned by layer 'conv22', param index 1
I0925 18:54:45.702016  4179 layer_factory.hpp:77] Creating layer bn32
I0925 18:54:45.702020  4179 net.cpp:100] Creating Layer bn32
I0925 18:54:45.702023  4179 net.cpp:434] bn32 <- conv32
I0925 18:54:45.702028  4179 net.cpp:395] bn32 -> conv32 (in-place)
I0925 18:54:45.702159  4179 net.cpp:150] Setting up bn32
I0925 18:54:45.702165  4179 net.cpp:157] Top shape: 32 16 24 24 (294912)
I0925 18:54:45.702167  4179 net.cpp:165] Memory required for data: 241887744
I0925 18:54:45.702175  4179 layer_factory.hpp:77] Creating layer relu32
I0925 18:54:45.702179  4179 net.cpp:100] Creating Layer relu32
I0925 18:54:45.702183  4179 net.cpp:434] relu32 <- conv32
I0925 18:54:45.702186  4179 net.cpp:395] relu32 -> conv32 (in-place)
I0925 18:54:45.702373  4179 net.cpp:150] Setting up relu32
I0925 18:54:45.702379  4179 net.cpp:157] Top shape: 32 16 24 24 (294912)
I0925 18:54:45.702383  4179 net.cpp:165] Memory required for data: 243067392
I0925 18:54:45.702385  4179 layer_factory.hpp:77] Creating layer conv33
I0925 18:54:45.702394  4179 net.cpp:100] Creating Layer conv33
I0925 18:54:45.702397  4179 net.cpp:434] conv33 <- conv32
I0925 18:54:45.702402  4179 net.cpp:408] conv33 -> conv33
I0925 18:54:45.703012  4179 net.cpp:150] Setting up conv33
I0925 18:54:45.703022  4179 net.cpp:157] Top shape: 32 16 24 24 (294912)
I0925 18:54:45.703025  4179 net.cpp:165] Memory required for data: 244247040
I0925 18:54:45.703034  4179 net.cpp:493] Sharing parameters 'conv_W3' owned by layer 'conv23', param index 0
I0925 18:54:45.703037  4179 net.cpp:493] Sharing parameters 'conv_b3' owned by layer 'conv23', param index 1
I0925 18:54:45.703040  4179 layer_factory.hpp:77] Creating layer bn33
I0925 18:54:45.703045  4179 net.cpp:100] Creating Layer bn33
I0925 18:54:45.703049  4179 net.cpp:434] bn33 <- conv33
I0925 18:54:45.703052  4179 net.cpp:395] bn33 -> conv33 (in-place)
I0925 18:54:45.703184  4179 net.cpp:150] Setting up bn33
I0925 18:54:45.703189  4179 net.cpp:157] Top shape: 32 16 24 24 (294912)
I0925 18:54:45.703192  4179 net.cpp:165] Memory required for data: 245426688
I0925 18:54:45.703197  4179 layer_factory.hpp:77] Creating layer relu3-13
I0925 18:54:45.703202  4179 net.cpp:100] Creating Layer relu3-13
I0925 18:54:45.703204  4179 net.cpp:434] relu3-13 <- conv33
I0925 18:54:45.703207  4179 net.cpp:395] relu3-13 -> conv33 (in-place)
I0925 18:54:45.703394  4179 net.cpp:150] Setting up relu3-13
I0925 18:54:45.703402  4179 net.cpp:157] Top shape: 32 16 24 24 (294912)
I0925 18:54:45.703405  4179 net.cpp:165] Memory required for data: 246606336
I0925 18:54:45.703408  4179 layer_factory.hpp:77] Creating layer deconv34
I0925 18:54:45.703413  4179 net.cpp:100] Creating Layer deconv34
I0925 18:54:45.703418  4179 net.cpp:434] deconv34 <- conv33
I0925 18:54:45.703420  4179 net.cpp:408] deconv34 -> deconv34
I0925 18:54:45.705194  4179 net.cpp:150] Setting up deconv34
I0925 18:54:45.705201  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.705204  4179 net.cpp:165] Memory required for data: 257223168
I0925 18:54:45.705210  4179 layer_factory.hpp:77] Creating layer relu34
I0925 18:54:45.705215  4179 net.cpp:100] Creating Layer relu34
I0925 18:54:45.705217  4179 net.cpp:434] relu34 <- deconv34
I0925 18:54:45.705220  4179 net.cpp:395] relu34 -> deconv34 (in-place)
I0925 18:54:45.705332  4179 net.cpp:150] Setting up relu34
I0925 18:54:45.705338  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.705340  4179 net.cpp:165] Memory required for data: 267840000
I0925 18:54:45.705343  4179 layer_factory.hpp:77] Creating layer conv35
I0925 18:54:45.705348  4179 net.cpp:100] Creating Layer conv35
I0925 18:54:45.705353  4179 net.cpp:434] conv35 <- deconv34
I0925 18:54:45.705356  4179 net.cpp:408] conv35 -> conv35
I0925 18:54:45.706140  4179 net.cpp:150] Setting up conv35
I0925 18:54:45.706149  4179 net.cpp:157] Top shape: 32 48 72 72 (7962624)
I0925 18:54:45.706152  4179 net.cpp:165] Memory required for data: 299690496
I0925 18:54:45.706156  4179 net.cpp:493] Sharing parameters 'conv_W5' owned by layer 'conv25', param index 0
I0925 18:54:45.706158  4179 net.cpp:493] Sharing parameters 'conv_b5' owned by layer 'conv25', param index 1
I0925 18:54:45.706161  4179 layer_factory.hpp:77] Creating layer slice35
I0925 18:54:45.706166  4179 net.cpp:100] Creating Layer slice35
I0925 18:54:45.706168  4179 net.cpp:434] slice35 <- conv35
I0925 18:54:45.706172  4179 net.cpp:408] slice35 -> conv35-a
I0925 18:54:45.706177  4179 net.cpp:408] slice35 -> conv35-b
I0925 18:54:45.706182  4179 net.cpp:408] slice35 -> conv35-c
I0925 18:54:45.706220  4179 net.cpp:150] Setting up slice35
I0925 18:54:45.706224  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.706228  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.706230  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.706233  4179 net.cpp:165] Memory required for data: 331540992
I0925 18:54:45.706235  4179 layer_factory.hpp:77] Creating layer maxout35
I0925 18:54:45.706239  4179 net.cpp:100] Creating Layer maxout35
I0925 18:54:45.706243  4179 net.cpp:434] maxout35 <- conv35-a
I0925 18:54:45.706245  4179 net.cpp:434] maxout35 <- conv35-b
I0925 18:54:45.706248  4179 net.cpp:434] maxout35 <- conv35-c
I0925 18:54:45.706251  4179 net.cpp:408] maxout35 -> maxout35
I0925 18:54:45.706277  4179 net.cpp:150] Setting up maxout35
I0925 18:54:45.706281  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.706290  4179 net.cpp:165] Memory required for data: 342157824
I0925 18:54:45.706292  4179 layer_factory.hpp:77] Creating layer bn35
I0925 18:54:45.706296  4179 net.cpp:100] Creating Layer bn35
I0925 18:54:45.706300  4179 net.cpp:434] bn35 <- maxout35
I0925 18:54:45.706302  4179 net.cpp:395] bn35 -> maxout35 (in-place)
I0925 18:54:45.706432  4179 net.cpp:150] Setting up bn35
I0925 18:54:45.706437  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.706439  4179 net.cpp:165] Memory required for data: 352774656
I0925 18:54:45.706444  4179 layer_factory.hpp:77] Creating layer relu35
I0925 18:54:45.706449  4179 net.cpp:100] Creating Layer relu35
I0925 18:54:45.706451  4179 net.cpp:434] relu35 <- maxout35
I0925 18:54:45.706454  4179 net.cpp:395] relu35 -> maxout35 (in-place)
I0925 18:54:45.706645  4179 net.cpp:150] Setting up relu35
I0925 18:54:45.706653  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.706656  4179 net.cpp:165] Memory required for data: 363391488
I0925 18:54:45.706660  4179 layer_factory.hpp:77] Creating layer conv36
I0925 18:54:45.706666  4179 net.cpp:100] Creating Layer conv36
I0925 18:54:45.706670  4179 net.cpp:434] conv36 <- maxout35
I0925 18:54:45.706674  4179 net.cpp:408] conv36 -> conv36
I0925 18:54:45.707460  4179 net.cpp:150] Setting up conv36
I0925 18:54:45.707469  4179 net.cpp:157] Top shape: 32 48 72 72 (7962624)
I0925 18:54:45.707473  4179 net.cpp:165] Memory required for data: 395241984
I0925 18:54:45.707475  4179 net.cpp:493] Sharing parameters 'conv_W6' owned by layer 'conv26', param index 0
I0925 18:54:45.707479  4179 net.cpp:493] Sharing parameters 'conv_b6' owned by layer 'conv26', param index 1
I0925 18:54:45.707482  4179 layer_factory.hpp:77] Creating layer slice36
I0925 18:54:45.707487  4179 net.cpp:100] Creating Layer slice36
I0925 18:54:45.707490  4179 net.cpp:434] slice36 <- conv36
I0925 18:54:45.707494  4179 net.cpp:408] slice36 -> conv36-a
I0925 18:54:45.707501  4179 net.cpp:408] slice36 -> conv36-b
I0925 18:54:45.707506  4179 net.cpp:408] slice36 -> conv36-c
I0925 18:54:45.707543  4179 net.cpp:150] Setting up slice36
I0925 18:54:45.707548  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.707551  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.707554  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.707557  4179 net.cpp:165] Memory required for data: 427092480
I0925 18:54:45.707559  4179 layer_factory.hpp:77] Creating layer maxout36
I0925 18:54:45.707563  4179 net.cpp:100] Creating Layer maxout36
I0925 18:54:45.707566  4179 net.cpp:434] maxout36 <- conv36-a
I0925 18:54:45.707569  4179 net.cpp:434] maxout36 <- conv36-b
I0925 18:54:45.707572  4179 net.cpp:434] maxout36 <- conv36-c
I0925 18:54:45.707576  4179 net.cpp:408] maxout36 -> maxout36
I0925 18:54:45.707602  4179 net.cpp:150] Setting up maxout36
I0925 18:54:45.707605  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.707608  4179 net.cpp:165] Memory required for data: 437709312
I0925 18:54:45.707610  4179 layer_factory.hpp:77] Creating layer bn36
I0925 18:54:45.707614  4179 net.cpp:100] Creating Layer bn36
I0925 18:54:45.707617  4179 net.cpp:434] bn36 <- maxout36
I0925 18:54:45.707619  4179 net.cpp:395] bn36 -> maxout36 (in-place)
I0925 18:54:45.707749  4179 net.cpp:150] Setting up bn36
I0925 18:54:45.707754  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.707757  4179 net.cpp:165] Memory required for data: 448326144
I0925 18:54:45.707762  4179 layer_factory.hpp:77] Creating layer relu36
I0925 18:54:45.707767  4179 net.cpp:100] Creating Layer relu36
I0925 18:54:45.707769  4179 net.cpp:434] relu36 <- maxout36
I0925 18:54:45.707772  4179 net.cpp:395] relu36 -> maxout36 (in-place)
I0925 18:54:45.707901  4179 net.cpp:150] Setting up relu36
I0925 18:54:45.707907  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.707911  4179 net.cpp:165] Memory required for data: 458942976
I0925 18:54:45.707913  4179 layer_factory.hpp:77] Creating layer conv37
I0925 18:54:45.707921  4179 net.cpp:100] Creating Layer conv37
I0925 18:54:45.707928  4179 net.cpp:434] conv37 <- maxout36
I0925 18:54:45.707934  4179 net.cpp:408] conv37 -> conv37
I0925 18:54:45.708602  4179 net.cpp:150] Setting up conv37
I0925 18:54:45.708611  4179 net.cpp:157] Top shape: 32 1 72 72 (165888)
I0925 18:54:45.708614  4179 net.cpp:165] Memory required for data: 459606528
I0925 18:54:45.708617  4179 net.cpp:493] Sharing parameters 'conv_W7' owned by layer 'conv27', param index 0
I0925 18:54:45.708621  4179 net.cpp:493] Sharing parameters 'conv_b7' owned by layer 'conv27', param index 1
I0925 18:54:45.708624  4179 layer_factory.hpp:77] Creating layer conv41
I0925 18:54:45.708631  4179 net.cpp:100] Creating Layer conv41
I0925 18:54:45.708634  4179 net.cpp:434] conv41 <- low4
I0925 18:54:45.708639  4179 net.cpp:408] conv41 -> conv41
I0925 18:54:45.709368  4179 net.cpp:150] Setting up conv41
I0925 18:54:45.709378  4179 net.cpp:157] Top shape: 32 16 18 18 (165888)
I0925 18:54:45.709381  4179 net.cpp:165] Memory required for data: 460270080
I0925 18:54:45.709384  4179 net.cpp:493] Sharing parameters 'conv_W1' owned by layer 'conv21', param index 0
I0925 18:54:45.709388  4179 net.cpp:493] Sharing parameters 'conv_b1' owned by layer 'conv21', param index 1
I0925 18:54:45.709390  4179 layer_factory.hpp:77] Creating layer relu41
I0925 18:54:45.709395  4179 net.cpp:100] Creating Layer relu41
I0925 18:54:45.709398  4179 net.cpp:434] relu41 <- conv41
I0925 18:54:45.709401  4179 net.cpp:395] relu41 -> conv41 (in-place)
I0925 18:54:45.709509  4179 net.cpp:150] Setting up relu41
I0925 18:54:45.709517  4179 net.cpp:157] Top shape: 32 16 18 18 (165888)
I0925 18:54:45.709519  4179 net.cpp:165] Memory required for data: 460933632
I0925 18:54:45.709522  4179 layer_factory.hpp:77] Creating layer conv42
I0925 18:54:45.709527  4179 net.cpp:100] Creating Layer conv42
I0925 18:54:45.709532  4179 net.cpp:434] conv42 <- conv41
I0925 18:54:45.709537  4179 net.cpp:408] conv42 -> conv42
I0925 18:54:45.710234  4179 net.cpp:150] Setting up conv42
I0925 18:54:45.710243  4179 net.cpp:157] Top shape: 32 16 18 18 (165888)
I0925 18:54:45.710247  4179 net.cpp:165] Memory required for data: 461597184
I0925 18:54:45.710249  4179 net.cpp:493] Sharing parameters 'conv_W2' owned by layer 'conv22', param index 0
I0925 18:54:45.710253  4179 net.cpp:493] Sharing parameters 'conv_b2' owned by layer 'conv22', param index 1
I0925 18:54:45.710256  4179 layer_factory.hpp:77] Creating layer bn42
I0925 18:54:45.710260  4179 net.cpp:100] Creating Layer bn42
I0925 18:54:45.710263  4179 net.cpp:434] bn42 <- conv42
I0925 18:54:45.710268  4179 net.cpp:395] bn42 -> conv42 (in-place)
I0925 18:54:45.710405  4179 net.cpp:150] Setting up bn42
I0925 18:54:45.710410  4179 net.cpp:157] Top shape: 32 16 18 18 (165888)
I0925 18:54:45.710413  4179 net.cpp:165] Memory required for data: 462260736
I0925 18:54:45.710418  4179 layer_factory.hpp:77] Creating layer relu42
I0925 18:54:45.710423  4179 net.cpp:100] Creating Layer relu42
I0925 18:54:45.710427  4179 net.cpp:434] relu42 <- conv42
I0925 18:54:45.710429  4179 net.cpp:395] relu42 -> conv42 (in-place)
I0925 18:54:45.710614  4179 net.cpp:150] Setting up relu42
I0925 18:54:45.710623  4179 net.cpp:157] Top shape: 32 16 18 18 (165888)
I0925 18:54:45.710625  4179 net.cpp:165] Memory required for data: 462924288
I0925 18:54:45.710628  4179 layer_factory.hpp:77] Creating layer conv43
I0925 18:54:45.710636  4179 net.cpp:100] Creating Layer conv43
I0925 18:54:45.710639  4179 net.cpp:434] conv43 <- conv42
I0925 18:54:45.710644  4179 net.cpp:408] conv43 -> conv43
I0925 18:54:45.711271  4179 net.cpp:150] Setting up conv43
I0925 18:54:45.711279  4179 net.cpp:157] Top shape: 32 16 18 18 (165888)
I0925 18:54:45.711282  4179 net.cpp:165] Memory required for data: 463587840
I0925 18:54:45.711285  4179 net.cpp:493] Sharing parameters 'conv_W3' owned by layer 'conv23', param index 0
I0925 18:54:45.711288  4179 net.cpp:493] Sharing parameters 'conv_b3' owned by layer 'conv23', param index 1
I0925 18:54:45.711292  4179 layer_factory.hpp:77] Creating layer bn43
I0925 18:54:45.711297  4179 net.cpp:100] Creating Layer bn43
I0925 18:54:45.711308  4179 net.cpp:434] bn43 <- conv43
I0925 18:54:45.711311  4179 net.cpp:395] bn43 -> conv43 (in-place)
I0925 18:54:45.711448  4179 net.cpp:150] Setting up bn43
I0925 18:54:45.711453  4179 net.cpp:157] Top shape: 32 16 18 18 (165888)
I0925 18:54:45.711457  4179 net.cpp:165] Memory required for data: 464251392
I0925 18:54:45.711462  4179 layer_factory.hpp:77] Creating layer relu4-13
I0925 18:54:45.711467  4179 net.cpp:100] Creating Layer relu4-13
I0925 18:54:45.711470  4179 net.cpp:434] relu4-13 <- conv43
I0925 18:54:45.711473  4179 net.cpp:395] relu4-13 -> conv43 (in-place)
I0925 18:54:45.711660  4179 net.cpp:150] Setting up relu4-13
I0925 18:54:45.711668  4179 net.cpp:157] Top shape: 32 16 18 18 (165888)
I0925 18:54:45.711671  4179 net.cpp:165] Memory required for data: 464914944
I0925 18:54:45.711673  4179 layer_factory.hpp:77] Creating layer deconv44
I0925 18:54:45.711680  4179 net.cpp:100] Creating Layer deconv44
I0925 18:54:45.711683  4179 net.cpp:434] deconv44 <- conv43
I0925 18:54:45.711688  4179 net.cpp:408] deconv44 -> deconv44
I0925 18:54:45.713685  4179 net.cpp:150] Setting up deconv44
I0925 18:54:45.713691  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.713695  4179 net.cpp:165] Memory required for data: 475531776
I0925 18:54:45.713702  4179 layer_factory.hpp:77] Creating layer relu44
I0925 18:54:45.713707  4179 net.cpp:100] Creating Layer relu44
I0925 18:54:45.713711  4179 net.cpp:434] relu44 <- deconv44
I0925 18:54:45.713714  4179 net.cpp:395] relu44 -> deconv44 (in-place)
I0925 18:54:45.713826  4179 net.cpp:150] Setting up relu44
I0925 18:54:45.713832  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.713835  4179 net.cpp:165] Memory required for data: 486148608
I0925 18:54:45.713838  4179 layer_factory.hpp:77] Creating layer conv45
I0925 18:54:45.713845  4179 net.cpp:100] Creating Layer conv45
I0925 18:54:45.713848  4179 net.cpp:434] conv45 <- deconv44
I0925 18:54:45.713853  4179 net.cpp:408] conv45 -> conv45
I0925 18:54:45.714646  4179 net.cpp:150] Setting up conv45
I0925 18:54:45.714655  4179 net.cpp:157] Top shape: 32 48 72 72 (7962624)
I0925 18:54:45.714658  4179 net.cpp:165] Memory required for data: 517999104
I0925 18:54:45.714663  4179 net.cpp:493] Sharing parameters 'conv_W5' owned by layer 'conv25', param index 0
I0925 18:54:45.714665  4179 net.cpp:493] Sharing parameters 'conv_b5' owned by layer 'conv25', param index 1
I0925 18:54:45.714668  4179 layer_factory.hpp:77] Creating layer slice45
I0925 18:54:45.714673  4179 net.cpp:100] Creating Layer slice45
I0925 18:54:45.714675  4179 net.cpp:434] slice45 <- conv45
I0925 18:54:45.714680  4179 net.cpp:408] slice45 -> conv45-a
I0925 18:54:45.714685  4179 net.cpp:408] slice45 -> conv45-b
I0925 18:54:45.714690  4179 net.cpp:408] slice45 -> conv45-c
I0925 18:54:45.714728  4179 net.cpp:150] Setting up slice45
I0925 18:54:45.714733  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.714736  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.714740  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.714742  4179 net.cpp:165] Memory required for data: 549849600
I0925 18:54:45.714745  4179 layer_factory.hpp:77] Creating layer maxout45
I0925 18:54:45.714750  4179 net.cpp:100] Creating Layer maxout45
I0925 18:54:45.714752  4179 net.cpp:434] maxout45 <- conv45-a
I0925 18:54:45.714756  4179 net.cpp:434] maxout45 <- conv45-b
I0925 18:54:45.714758  4179 net.cpp:434] maxout45 <- conv45-c
I0925 18:54:45.714762  4179 net.cpp:408] maxout45 -> maxout45
I0925 18:54:45.714787  4179 net.cpp:150] Setting up maxout45
I0925 18:54:45.714792  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.714794  4179 net.cpp:165] Memory required for data: 560466432
I0925 18:54:45.714797  4179 layer_factory.hpp:77] Creating layer bn45
I0925 18:54:45.714800  4179 net.cpp:100] Creating Layer bn45
I0925 18:54:45.714803  4179 net.cpp:434] bn45 <- maxout45
I0925 18:54:45.714807  4179 net.cpp:395] bn45 -> maxout45 (in-place)
I0925 18:54:45.714941  4179 net.cpp:150] Setting up bn45
I0925 18:54:45.714951  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.714954  4179 net.cpp:165] Memory required for data: 571083264
I0925 18:54:45.714959  4179 layer_factory.hpp:77] Creating layer relu45
I0925 18:54:45.714964  4179 net.cpp:100] Creating Layer relu45
I0925 18:54:45.714967  4179 net.cpp:434] relu45 <- maxout45
I0925 18:54:45.714970  4179 net.cpp:395] relu45 -> maxout45 (in-place)
I0925 18:54:45.715162  4179 net.cpp:150] Setting up relu45
I0925 18:54:45.715169  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.715173  4179 net.cpp:165] Memory required for data: 581700096
I0925 18:54:45.715174  4179 layer_factory.hpp:77] Creating layer conv46
I0925 18:54:45.715183  4179 net.cpp:100] Creating Layer conv46
I0925 18:54:45.715185  4179 net.cpp:434] conv46 <- maxout45
I0925 18:54:45.715190  4179 net.cpp:408] conv46 -> conv46
I0925 18:54:45.715986  4179 net.cpp:150] Setting up conv46
I0925 18:54:45.715996  4179 net.cpp:157] Top shape: 32 48 72 72 (7962624)
I0925 18:54:45.715998  4179 net.cpp:165] Memory required for data: 613550592
I0925 18:54:45.716001  4179 net.cpp:493] Sharing parameters 'conv_W6' owned by layer 'conv26', param index 0
I0925 18:54:45.716006  4179 net.cpp:493] Sharing parameters 'conv_b6' owned by layer 'conv26', param index 1
I0925 18:54:45.716008  4179 layer_factory.hpp:77] Creating layer slice46
I0925 18:54:45.716013  4179 net.cpp:100] Creating Layer slice46
I0925 18:54:45.716017  4179 net.cpp:434] slice46 <- conv46
I0925 18:54:45.716020  4179 net.cpp:408] slice46 -> conv46-a
I0925 18:54:45.716025  4179 net.cpp:408] slice46 -> conv46-b
I0925 18:54:45.716030  4179 net.cpp:408] slice46 -> conv46-c
I0925 18:54:45.716069  4179 net.cpp:150] Setting up slice46
I0925 18:54:45.716074  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.716078  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.716080  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.716083  4179 net.cpp:165] Memory required for data: 645401088
I0925 18:54:45.716085  4179 layer_factory.hpp:77] Creating layer maxout46
I0925 18:54:45.716094  4179 net.cpp:100] Creating Layer maxout46
I0925 18:54:45.716096  4179 net.cpp:434] maxout46 <- conv46-a
I0925 18:54:45.716099  4179 net.cpp:434] maxout46 <- conv46-b
I0925 18:54:45.716102  4179 net.cpp:434] maxout46 <- conv46-c
I0925 18:54:45.716106  4179 net.cpp:408] maxout46 -> maxout46
I0925 18:54:45.716133  4179 net.cpp:150] Setting up maxout46
I0925 18:54:45.716137  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.716140  4179 net.cpp:165] Memory required for data: 656017920
I0925 18:54:45.716142  4179 layer_factory.hpp:77] Creating layer bn46
I0925 18:54:45.716146  4179 net.cpp:100] Creating Layer bn46
I0925 18:54:45.716150  4179 net.cpp:434] bn46 <- maxout46
I0925 18:54:45.716153  4179 net.cpp:395] bn46 -> maxout46 (in-place)
I0925 18:54:45.716294  4179 net.cpp:150] Setting up bn46
I0925 18:54:45.716298  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.716301  4179 net.cpp:165] Memory required for data: 666634752
I0925 18:54:45.716306  4179 layer_factory.hpp:77] Creating layer relu46
I0925 18:54:45.716311  4179 net.cpp:100] Creating Layer relu46
I0925 18:54:45.716315  4179 net.cpp:434] relu46 <- maxout46
I0925 18:54:45.716317  4179 net.cpp:395] relu46 -> maxout46 (in-place)
I0925 18:54:45.716429  4179 net.cpp:150] Setting up relu46
I0925 18:54:45.716436  4179 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:54:45.716439  4179 net.cpp:165] Memory required for data: 677251584
I0925 18:54:45.716441  4179 layer_factory.hpp:77] Creating layer conv47
I0925 18:54:45.716449  4179 net.cpp:100] Creating Layer conv47
I0925 18:54:45.716451  4179 net.cpp:434] conv47 <- maxout46
I0925 18:54:45.716455  4179 net.cpp:408] conv47 -> conv47
I0925 18:54:45.717121  4179 net.cpp:150] Setting up conv47
I0925 18:54:45.717130  4179 net.cpp:157] Top shape: 32 1 72 72 (165888)
I0925 18:54:45.717133  4179 net.cpp:165] Memory required for data: 677915136
I0925 18:54:45.717136  4179 net.cpp:493] Sharing parameters 'conv_W7' owned by layer 'conv27', param index 0
I0925 18:54:45.717145  4179 net.cpp:493] Sharing parameters 'conv_b7' owned by layer 'conv27', param index 1
I0925 18:54:45.717149  4179 layer_factory.hpp:77] Creating layer loss2
I0925 18:54:45.717155  4179 net.cpp:100] Creating Layer loss2
I0925 18:54:45.717159  4179 net.cpp:434] loss2 <- conv27
I0925 18:54:45.717161  4179 net.cpp:434] loss2 <- label_label_0_split_0
I0925 18:54:45.717165  4179 net.cpp:408] loss2 -> loss2
I0925 18:54:45.717196  4179 net.cpp:150] Setting up loss2
I0925 18:54:45.717202  4179 net.cpp:157] Top shape: (1)
I0925 18:54:45.717206  4179 net.cpp:160]     with loss weight 0.5
I0925 18:54:45.717212  4179 net.cpp:165] Memory required for data: 677915140
I0925 18:54:45.717216  4179 layer_factory.hpp:77] Creating layer loss3
I0925 18:54:45.717218  4179 net.cpp:100] Creating Layer loss3
I0925 18:54:45.717221  4179 net.cpp:434] loss3 <- conv37
I0925 18:54:45.717224  4179 net.cpp:434] loss3 <- label_label_0_split_1
I0925 18:54:45.717228  4179 net.cpp:408] loss3 -> loss3
I0925 18:54:45.717255  4179 net.cpp:150] Setting up loss3
I0925 18:54:45.717259  4179 net.cpp:157] Top shape: (1)
I0925 18:54:45.717262  4179 net.cpp:160]     with loss weight 0.3
I0925 18:54:45.717267  4179 net.cpp:165] Memory required for data: 677915144
I0925 18:54:45.717268  4179 layer_factory.hpp:77] Creating layer loss4
I0925 18:54:45.717272  4179 net.cpp:100] Creating Layer loss4
I0925 18:54:45.717275  4179 net.cpp:434] loss4 <- conv47
I0925 18:54:45.717278  4179 net.cpp:434] loss4 <- label_label_0_split_2
I0925 18:54:45.717283  4179 net.cpp:408] loss4 -> loss4
I0925 18:54:45.717309  4179 net.cpp:150] Setting up loss4
I0925 18:54:45.717314  4179 net.cpp:157] Top shape: (1)
I0925 18:54:45.717316  4179 net.cpp:160]     with loss weight 0.2
I0925 18:54:45.717320  4179 net.cpp:165] Memory required for data: 677915148
I0925 18:54:45.717322  4179 net.cpp:226] loss4 needs backward computation.
I0925 18:54:45.717324  4179 net.cpp:226] loss3 needs backward computation.
I0925 18:54:45.717327  4179 net.cpp:226] loss2 needs backward computation.
I0925 18:54:45.717330  4179 net.cpp:226] conv47 needs backward computation.
I0925 18:54:45.717334  4179 net.cpp:226] relu46 needs backward computation.
I0925 18:54:45.717335  4179 net.cpp:226] bn46 needs backward computation.
I0925 18:54:45.717337  4179 net.cpp:226] maxout46 needs backward computation.
I0925 18:54:45.717339  4179 net.cpp:226] slice46 needs backward computation.
I0925 18:54:45.717342  4179 net.cpp:226] conv46 needs backward computation.
I0925 18:54:45.717345  4179 net.cpp:226] relu45 needs backward computation.
I0925 18:54:45.717347  4179 net.cpp:226] bn45 needs backward computation.
I0925 18:54:45.717350  4179 net.cpp:226] maxout45 needs backward computation.
I0925 18:54:45.717352  4179 net.cpp:226] slice45 needs backward computation.
I0925 18:54:45.717355  4179 net.cpp:226] conv45 needs backward computation.
I0925 18:54:45.717357  4179 net.cpp:226] relu44 needs backward computation.
I0925 18:54:45.717360  4179 net.cpp:226] deconv44 needs backward computation.
I0925 18:54:45.717362  4179 net.cpp:226] relu4-13 needs backward computation.
I0925 18:54:45.717365  4179 net.cpp:226] bn43 needs backward computation.
I0925 18:54:45.717367  4179 net.cpp:226] conv43 needs backward computation.
I0925 18:54:45.717370  4179 net.cpp:226] relu42 needs backward computation.
I0925 18:54:45.717371  4179 net.cpp:226] bn42 needs backward computation.
I0925 18:54:45.717373  4179 net.cpp:226] conv42 needs backward computation.
I0925 18:54:45.717376  4179 net.cpp:226] relu41 needs backward computation.
I0925 18:54:45.717378  4179 net.cpp:226] conv41 needs backward computation.
I0925 18:54:45.717381  4179 net.cpp:226] conv37 needs backward computation.
I0925 18:54:45.717383  4179 net.cpp:226] relu36 needs backward computation.
I0925 18:54:45.717386  4179 net.cpp:226] bn36 needs backward computation.
I0925 18:54:45.717387  4179 net.cpp:226] maxout36 needs backward computation.
I0925 18:54:45.717391  4179 net.cpp:226] slice36 needs backward computation.
I0925 18:54:45.717398  4179 net.cpp:226] conv36 needs backward computation.
I0925 18:54:45.717401  4179 net.cpp:226] relu35 needs backward computation.
I0925 18:54:45.717403  4179 net.cpp:226] bn35 needs backward computation.
I0925 18:54:45.717406  4179 net.cpp:226] maxout35 needs backward computation.
I0925 18:54:45.717408  4179 net.cpp:226] slice35 needs backward computation.
I0925 18:54:45.717411  4179 net.cpp:226] conv35 needs backward computation.
I0925 18:54:45.717413  4179 net.cpp:226] relu34 needs backward computation.
I0925 18:54:45.717416  4179 net.cpp:226] deconv34 needs backward computation.
I0925 18:54:45.717418  4179 net.cpp:226] relu3-13 needs backward computation.
I0925 18:54:45.717420  4179 net.cpp:226] bn33 needs backward computation.
I0925 18:54:45.717422  4179 net.cpp:226] conv33 needs backward computation.
I0925 18:54:45.717425  4179 net.cpp:226] relu32 needs backward computation.
I0925 18:54:45.717427  4179 net.cpp:226] bn32 needs backward computation.
I0925 18:54:45.717429  4179 net.cpp:226] conv32 needs backward computation.
I0925 18:54:45.717432  4179 net.cpp:226] relu31 needs backward computation.
I0925 18:54:45.717434  4179 net.cpp:226] conv31 needs backward computation.
I0925 18:54:45.717437  4179 net.cpp:226] conv27 needs backward computation.
I0925 18:54:45.717440  4179 net.cpp:226] relu26 needs backward computation.
I0925 18:54:45.717442  4179 net.cpp:226] bn26 needs backward computation.
I0925 18:54:45.717444  4179 net.cpp:226] maxout26 needs backward computation.
I0925 18:54:45.717447  4179 net.cpp:226] slice26 needs backward computation.
I0925 18:54:45.717452  4179 net.cpp:226] conv26 needs backward computation.
I0925 18:54:45.717453  4179 net.cpp:226] relu25 needs backward computation.
I0925 18:54:45.717455  4179 net.cpp:226] bn25 needs backward computation.
I0925 18:54:45.717458  4179 net.cpp:226] maxout25 needs backward computation.
I0925 18:54:45.717460  4179 net.cpp:226] slice25 needs backward computation.
I0925 18:54:45.717463  4179 net.cpp:226] conv25 needs backward computation.
I0925 18:54:45.717465  4179 net.cpp:226] relu24 needs backward computation.
I0925 18:54:45.717468  4179 net.cpp:226] deconv24 needs backward computation.
I0925 18:54:45.717470  4179 net.cpp:226] relu2-13 needs backward computation.
I0925 18:54:45.717473  4179 net.cpp:226] bn23 needs backward computation.
I0925 18:54:45.717474  4179 net.cpp:226] conv23 needs backward computation.
I0925 18:54:45.717478  4179 net.cpp:226] relu22 needs backward computation.
I0925 18:54:45.717479  4179 net.cpp:226] bn22 needs backward computation.
I0925 18:54:45.717483  4179 net.cpp:226] conv22 needs backward computation.
I0925 18:54:45.717484  4179 net.cpp:226] relu21 needs backward computation.
I0925 18:54:45.717486  4179 net.cpp:226] conv21 needs backward computation.
I0925 18:54:45.717489  4179 net.cpp:228] label_label_0_split does not need backward computation.
I0925 18:54:45.717492  4179 net.cpp:228] label does not need backward computation.
I0925 18:54:45.717495  4179 net.cpp:228] low4 does not need backward computation.
I0925 18:54:45.717497  4179 net.cpp:228] low3 does not need backward computation.
I0925 18:54:45.717500  4179 net.cpp:228] low2 does not need backward computation.
I0925 18:54:45.717501  4179 net.cpp:270] This network produces output loss2
I0925 18:54:45.717504  4179 net.cpp:270] This network produces output loss3
I0925 18:54:45.717506  4179 net.cpp:270] This network produces output loss4
I0925 18:54:45.717694  4179 net.cpp:283] Network initialization done.
I0925 18:54:45.717869  4179 solver.cpp:60] Solver scaffolding done.
I0925 18:54:45.719179  4179 caffe.cpp:251] Starting Optimization
I0925 18:54:45.719184  4179 solver.cpp:279] Solving AESR
I0925 18:54:45.719187  4179 solver.cpp:280] Learning Rate Policy: step
I0925 18:54:45.800858  4179 solver.cpp:228] Iteration 0, loss = 1674.93
I0925 18:54:45.800875  4179 solver.cpp:244]     Train net output #0: loss2 = 1677.72 (* 0.5 = 838.862 loss)
I0925 18:54:45.800880  4179 solver.cpp:244]     Train net output #1: loss3 = 1745.6 (* 0.3 = 523.68 loss)
I0925 18:54:45.800892  4179 solver.cpp:244]     Train net output #2: loss4 = 1561.92 (* 0.2 = 312.384 loss)
I0925 18:54:45.800900  4179 sgd_solver.cpp:106] Iteration 0, lr = 1e-05
I0925 18:54:47.605665  4179 solver.cpp:228] Iteration 10, loss = 321.159
I0925 18:54:47.605690  4179 solver.cpp:244]     Train net output #0: loss2 = 275.645 (* 0.5 = 137.822 loss)
I0925 18:54:47.605695  4179 solver.cpp:244]     Train net output #1: loss3 = 351.596 (* 0.3 = 105.479 loss)
I0925 18:54:47.605700  4179 solver.cpp:244]     Train net output #2: loss4 = 389.287 (* 0.2 = 77.8575 loss)
I0925 18:54:47.605702  4179 sgd_solver.cpp:106] Iteration 10, lr = 1e-05
I0925 18:54:49.401880  4179 solver.cpp:228] Iteration 20, loss = 86.6733
I0925 18:54:49.401908  4179 solver.cpp:244]     Train net output #0: loss2 = 79.5106 (* 0.5 = 39.7553 loss)
I0925 18:54:49.401914  4179 solver.cpp:244]     Train net output #1: loss3 = 92.81 (* 0.3 = 27.843 loss)
I0925 18:54:49.401918  4179 solver.cpp:244]     Train net output #2: loss4 = 95.375 (* 0.2 = 19.075 loss)
I0925 18:54:49.401922  4179 sgd_solver.cpp:106] Iteration 20, lr = 1e-05
I0925 18:54:51.195807  4179 solver.cpp:228] Iteration 30, loss = 62.8332
I0925 18:54:51.195825  4179 solver.cpp:244]     Train net output #0: loss2 = 53.7934 (* 0.5 = 26.8967 loss)
I0925 18:54:51.195830  4179 solver.cpp:244]     Train net output #1: loss3 = 68.0993 (* 0.3 = 20.4298 loss)
I0925 18:54:51.195834  4179 solver.cpp:244]     Train net output #2: loss4 = 77.5335 (* 0.2 = 15.5067 loss)
I0925 18:54:51.195838  4179 sgd_solver.cpp:106] Iteration 30, lr = 1e-05
I0925 18:54:52.990672  4179 solver.cpp:228] Iteration 40, loss = 43.5961
I0925 18:54:52.990692  4179 solver.cpp:244]     Train net output #0: loss2 = 37.133 (* 0.5 = 18.5665 loss)
I0925 18:54:52.990697  4179 solver.cpp:244]     Train net output #1: loss3 = 46.8598 (* 0.3 = 14.0579 loss)
I0925 18:54:52.990701  4179 solver.cpp:244]     Train net output #2: loss4 = 54.8586 (* 0.2 = 10.9717 loss)
I0925 18:54:52.990705  4179 sgd_solver.cpp:106] Iteration 40, lr = 1e-05
I0925 18:54:54.788550  4179 solver.cpp:228] Iteration 50, loss = 38.4714
I0925 18:54:54.788575  4179 solver.cpp:244]     Train net output #0: loss2 = 33.712 (* 0.5 = 16.856 loss)
I0925 18:54:54.788580  4179 solver.cpp:244]     Train net output #1: loss3 = 40.7992 (* 0.3 = 12.2398 loss)
I0925 18:54:54.788585  4179 solver.cpp:244]     Train net output #2: loss4 = 46.8782 (* 0.2 = 9.37565 loss)
I0925 18:54:54.788589  4179 sgd_solver.cpp:106] Iteration 50, lr = 1e-05
I0925 18:54:56.584020  4179 solver.cpp:228] Iteration 60, loss = 37.0186
I0925 18:54:56.584040  4179 solver.cpp:244]     Train net output #0: loss2 = 32.6299 (* 0.5 = 16.315 loss)
I0925 18:54:56.584045  4179 solver.cpp:244]     Train net output #1: loss3 = 39.0358 (* 0.3 = 11.7107 loss)
I0925 18:54:56.584049  4179 solver.cpp:244]     Train net output #2: loss4 = 44.9643 (* 0.2 = 8.99286 loss)
I0925 18:54:56.584053  4179 sgd_solver.cpp:106] Iteration 60, lr = 1e-05
I0925 18:54:58.382227  4179 solver.cpp:228] Iteration 70, loss = 34.0312
I0925 18:54:58.382249  4179 solver.cpp:244]     Train net output #0: loss2 = 30.0182 (* 0.5 = 15.0091 loss)
I0925 18:54:58.382254  4179 solver.cpp:244]     Train net output #1: loss3 = 35.8711 (* 0.3 = 10.7613 loss)
I0925 18:54:58.382258  4179 solver.cpp:244]     Train net output #2: loss4 = 41.304 (* 0.2 = 8.26081 loss)
I0925 18:54:58.382262  4179 sgd_solver.cpp:106] Iteration 70, lr = 1e-05
I0925 18:55:00.184667  4179 solver.cpp:228] Iteration 80, loss = 32.1148
I0925 18:55:00.184710  4179 solver.cpp:244]     Train net output #0: loss2 = 28.1481 (* 0.5 = 14.074 loss)
I0925 18:55:00.184720  4179 solver.cpp:244]     Train net output #1: loss3 = 33.847 (* 0.3 = 10.1541 loss)
I0925 18:55:00.184732  4179 solver.cpp:244]     Train net output #2: loss4 = 39.4331 (* 0.2 = 7.88662 loss)
I0925 18:55:00.184743  4179 sgd_solver.cpp:106] Iteration 80, lr = 1e-05
I0925 18:55:01.980211  4179 solver.cpp:228] Iteration 90, loss = 31.101
I0925 18:55:01.980238  4179 solver.cpp:244]     Train net output #0: loss2 = 27.1396 (* 0.5 = 13.5698 loss)
I0925 18:55:01.980262  4179 solver.cpp:244]     Train net output #1: loss3 = 32.7973 (* 0.3 = 9.83919 loss)
I0925 18:55:01.980265  4179 solver.cpp:244]     Train net output #2: loss4 = 38.4599 (* 0.2 = 7.69197 loss)
I0925 18:55:01.980269  4179 sgd_solver.cpp:106] Iteration 90, lr = 1e-05
I0925 18:55:03.777158  4179 solver.cpp:228] Iteration 100, loss = 30.0918
I0925 18:55:03.777178  4179 solver.cpp:244]     Train net output #0: loss2 = 26.2188 (* 0.5 = 13.1094 loss)
I0925 18:55:03.777184  4179 solver.cpp:244]     Train net output #1: loss3 = 31.7631 (* 0.3 = 9.52893 loss)
I0925 18:55:03.777187  4179 solver.cpp:244]     Train net output #2: loss4 = 37.2676 (* 0.2 = 7.45352 loss)
I0925 18:55:03.777190  4179 sgd_solver.cpp:106] Iteration 100, lr = 1e-05
I0925 18:55:05.573753  4179 solver.cpp:228] Iteration 110, loss = 29.3872
I0925 18:55:05.573771  4179 solver.cpp:244]     Train net output #0: loss2 = 25.5676 (* 0.5 = 12.7838 loss)
I0925 18:55:05.573776  4179 solver.cpp:244]     Train net output #1: loss3 = 31.0199 (* 0.3 = 9.30597 loss)
I0925 18:55:05.573781  4179 solver.cpp:244]     Train net output #2: loss4 = 36.4871 (* 0.2 = 7.29743 loss)
I0925 18:55:05.573783  4179 sgd_solver.cpp:106] Iteration 110, lr = 1e-05
I0925 18:55:06.410990  4179 solver.cpp:454] Snapshotting to binary proto file AESR/model_maxout_deconv_bn/model-1_iter_115.caffemodel
I0925 18:55:06.414366  4179 sgd_solver.cpp:273] Snapshotting solver state to binary proto file AESR/model_maxout_deconv_bn/model-1_iter_115.solverstate
I0925 18:55:07.377879  4179 solver.cpp:228] Iteration 120, loss = 28.6873
I0925 18:55:07.377902  4179 solver.cpp:244]     Train net output #0: loss2 = 24.9352 (* 0.5 = 12.4676 loss)
I0925 18:55:07.377907  4179 solver.cpp:244]     Train net output #1: loss3 = 30.278 (* 0.3 = 9.08341 loss)
I0925 18:55:07.377912  4179 solver.cpp:244]     Train net output #2: loss4 = 35.6816 (* 0.2 = 7.13632 loss)
I0925 18:55:07.377914  4179 sgd_solver.cpp:106] Iteration 120, lr = 1e-05
I0925 18:55:09.174847  4179 solver.cpp:228] Iteration 130, loss = 28.0601
I0925 18:55:09.174875  4179 solver.cpp:244]     Train net output #0: loss2 = 24.3773 (* 0.5 = 12.1886 loss)
I0925 18:55:09.174881  4179 solver.cpp:244]     Train net output #1: loss3 = 29.6199 (* 0.3 = 8.88596 loss)
I0925 18:55:09.174885  4179 solver.cpp:244]     Train net output #2: loss4 = 34.9274 (* 0.2 = 6.98548 loss)
I0925 18:55:09.174890  4179 sgd_solver.cpp:106] Iteration 130, lr = 1e-05
I0925 18:55:10.975595  4179 solver.cpp:228] Iteration 140, loss = 27.5329
I0925 18:55:10.975623  4179 solver.cpp:244]     Train net output #0: loss2 = 23.9059 (* 0.5 = 11.953 loss)
I0925 18:55:10.975628  4179 solver.cpp:244]     Train net output #1: loss3 = 29.0701 (* 0.3 = 8.72102 loss)
I0925 18:55:10.975633  4179 solver.cpp:244]     Train net output #2: loss4 = 34.2947 (* 0.2 = 6.85894 loss)
I0925 18:55:10.975636  4179 sgd_solver.cpp:106] Iteration 140, lr = 1e-05
I0925 18:55:12.789002  4179 solver.cpp:228] Iteration 150, loss = 26.9971
I0925 18:55:12.789033  4179 solver.cpp:244]     Train net output #0: loss2 = 23.4242 (* 0.5 = 11.7121 loss)
I0925 18:55:12.789038  4179 solver.cpp:244]     Train net output #1: loss3 = 28.5157 (* 0.3 = 8.5547 loss)
I0925 18:55:12.789042  4179 solver.cpp:244]     Train net output #2: loss4 = 33.6512 (* 0.2 = 6.73024 loss)
I0925 18:55:12.789047  4179 sgd_solver.cpp:106] Iteration 150, lr = 1e-05
I0925 18:55:14.599310  4179 solver.cpp:228] Iteration 160, loss = 26.4971
I0925 18:55:14.599339  4179 solver.cpp:244]     Train net output #0: loss2 = 22.9754 (* 0.5 = 11.4877 loss)
I0925 18:55:14.599344  4179 solver.cpp:244]     Train net output #1: loss3 = 27.998 (* 0.3 = 8.39939 loss)
I0925 18:55:14.599349  4179 solver.cpp:244]     Train net output #2: loss4 = 33.0501 (* 0.2 = 6.61001 loss)
I0925 18:55:14.599352  4179 sgd_solver.cpp:106] Iteration 160, lr = 1e-05
I0925 18:55:16.405994  4179 solver.cpp:228] Iteration 170, loss = 26.0352
I0925 18:55:16.406122  4179 solver.cpp:244]     Train net output #0: loss2 = 22.5619 (* 0.5 = 11.2809 loss)
I0925 18:55:16.406133  4179 solver.cpp:244]     Train net output #1: loss3 = 27.5192 (* 0.3 = 8.25577 loss)
I0925 18:55:16.406138  4179 solver.cpp:244]     Train net output #2: loss4 = 32.4924 (* 0.2 = 6.49848 loss)
I0925 18:55:16.406144  4179 sgd_solver.cpp:106] Iteration 170, lr = 1e-05
I0925 18:55:18.222036  4179 solver.cpp:228] Iteration 180, loss = 25.5919
I0925 18:55:18.222066  4179 solver.cpp:244]     Train net output #0: loss2 = 22.1665 (* 0.5 = 11.0833 loss)
I0925 18:55:18.222072  4179 solver.cpp:244]     Train net output #1: loss3 = 27.06 (* 0.3 = 8.118 loss)
I0925 18:55:18.222079  4179 solver.cpp:244]     Train net output #2: loss4 = 31.9533 (* 0.2 = 6.39065 loss)
I0925 18:55:18.222085  4179 sgd_solver.cpp:106] Iteration 180, lr = 1e-05
I0925 18:55:20.032557  4179 solver.cpp:228] Iteration 190, loss = 25.1728
I0925 18:55:20.032588  4179 solver.cpp:244]     Train net output #0: loss2 = 21.7935 (* 0.5 = 10.8968 loss)
I0925 18:55:20.032593  4179 solver.cpp:244]     Train net output #1: loss3 = 26.6258 (* 0.3 = 7.98775 loss)
I0925 18:55:20.032598  4179 solver.cpp:244]     Train net output #2: loss4 = 31.4417 (* 0.2 = 6.28835 loss)
I0925 18:55:20.032603  4179 sgd_solver.cpp:106] Iteration 190, lr = 1e-05
I0925 18:55:21.840553  4179 solver.cpp:228] Iteration 200, loss = 24.7745
I0925 18:55:21.840598  4179 solver.cpp:244]     Train net output #0: loss2 = 21.4404 (* 0.5 = 10.7202 loss)
I0925 18:55:21.840607  4179 solver.cpp:244]     Train net output #1: loss3 = 26.2131 (* 0.3 = 7.86393 loss)
I0925 18:55:21.840615  4179 solver.cpp:244]     Train net output #2: loss4 = 30.9517 (* 0.2 = 6.19034 loss)
I0925 18:55:21.840622  4179 sgd_solver.cpp:106] Iteration 200, lr = 1e-05
I0925 18:55:23.644021  4179 solver.cpp:228] Iteration 210, loss = 24.395
I0925 18:55:23.644052  4179 solver.cpp:244]     Train net output #0: loss2 = 21.1056 (* 0.5 = 10.5528 loss)
I0925 18:55:23.644057  4179 solver.cpp:244]     Train net output #1: loss3 = 25.8195 (* 0.3 = 7.74586 loss)
I0925 18:55:23.644062  4179 solver.cpp:244]     Train net output #2: loss4 = 30.4817 (* 0.2 = 6.09634 loss)
I0925 18:55:23.644067  4179 sgd_solver.cpp:106] Iteration 210, lr = 1e-05
I0925 18:55:25.451838  4179 solver.cpp:228] Iteration 220, loss = 24.0334
I0925 18:55:25.451869  4179 solver.cpp:244]     Train net output #0: loss2 = 20.7874 (* 0.5 = 10.3937 loss)
I0925 18:55:25.451874  4179 solver.cpp:244]     Train net output #1: loss3 = 25.4447 (* 0.3 = 7.63341 loss)
I0925 18:55:25.451879  4179 solver.cpp:244]     Train net output #2: loss4 = 30.0315 (* 0.2 = 6.00631 loss)
I0925 18:55:25.451882  4179 sgd_solver.cpp:106] Iteration 220, lr = 1e-05
I0925 18:55:27.257638  4179 solver.cpp:228] Iteration 230, loss = 23.6862
I0925 18:55:27.257668  4179 solver.cpp:244]     Train net output #0: loss2 = 20.482 (* 0.5 = 10.241 loss)
I0925 18:55:27.257674  4179 solver.cpp:244]     Train net output #1: loss3 = 25.0863 (* 0.3 = 7.5259 loss)
I0925 18:55:27.257678  4179 solver.cpp:244]     Train net output #2: loss4 = 29.5967 (* 0.2 = 5.91933 loss)
I0925 18:55:27.257683  4179 sgd_solver.cpp:106] Iteration 230, lr = 1e-05
I0925 18:55:29.059576  4179 solver.cpp:228] Iteration 240, loss = 23.3528
I0925 18:55:29.059607  4179 solver.cpp:244]     Train net output #0: loss2 = 20.1879 (* 0.5 = 10.0939 loss)
I0925 18:55:29.059612  4179 solver.cpp:244]     Train net output #1: loss3 = 24.7432 (* 0.3 = 7.42297 loss)
I0925 18:55:29.059617  4179 solver.cpp:244]     Train net output #2: loss4 = 29.1795 (* 0.2 = 5.8359 loss)
I0925 18:55:29.059620  4179 sgd_solver.cpp:106] Iteration 240, lr = 1e-05
I0925 18:55:30.857084  4179 solver.cpp:228] Iteration 250, loss = 23.0315
I0925 18:55:30.857110  4179 solver.cpp:244]     Train net output #0: loss2 = 19.9038 (* 0.5 = 9.95192 loss)
I0925 18:55:30.857115  4179 solver.cpp:244]     Train net output #1: loss3 = 24.4126 (* 0.3 = 7.32379 loss)
I0925 18:55:30.857120  4179 solver.cpp:244]     Train net output #2: loss4 = 28.7787 (* 0.2 = 5.75575 loss)
I0925 18:55:30.857125  4179 sgd_solver.cpp:106] Iteration 250, lr = 1e-05
I0925 18:55:32.656893  4179 solver.cpp:228] Iteration 260, loss = 22.7203
I0925 18:55:32.656920  4179 solver.cpp:244]     Train net output #0: loss2 = 19.6283 (* 0.5 = 9.81416 loss)
I0925 18:55:32.656925  4179 solver.cpp:244]     Train net output #1: loss3 = 24.0929 (* 0.3 = 7.22788 loss)
I0925 18:55:32.656929  4179 solver.cpp:244]     Train net output #2: loss4 = 28.3911 (* 0.2 = 5.67823 loss)
I0925 18:55:32.656932  4179 sgd_solver.cpp:106] Iteration 260, lr = 1e-05
I0925 18:55:34.453806  4179 solver.cpp:228] Iteration 270, loss = 22.4176
I0925 18:55:34.453826  4179 solver.cpp:244]     Train net output #0: loss2 = 19.3602 (* 0.5 = 9.68011 loss)
I0925 18:55:34.453832  4179 solver.cpp:244]     Train net output #1: loss3 = 23.7828 (* 0.3 = 7.13483 loss)
I0925 18:55:34.453836  4179 solver.cpp:244]     Train net output #2: loss4 = 28.0131 (* 0.2 = 5.60261 loss)
I0925 18:55:34.453840  4179 sgd_solver.cpp:106] Iteration 270, lr = 1e-05
I0925 18:55:36.247812  4179 solver.cpp:228] Iteration 280, loss = 22.1217
I0925 18:55:36.247831  4179 solver.cpp:244]     Train net output #0: loss2 = 19.0979 (* 0.5 = 9.54896 loss)
I0925 18:55:36.247838  4179 solver.cpp:244]     Train net output #1: loss3 = 23.4798 (* 0.3 = 7.04393 loss)
I0925 18:55:36.247841  4179 solver.cpp:244]     Train net output #2: loss4 = 27.6439 (* 0.2 = 5.52878 loss)
I0925 18:55:36.247844  4179 sgd_solver.cpp:106] Iteration 280, lr = 1e-05
I0925 18:55:38.049196  4179 solver.cpp:228] Iteration 290, loss = 21.833
I0925 18:55:38.049217  4179 solver.cpp:244]     Train net output #0: loss2 = 18.8417 (* 0.5 = 9.42086 loss)
I0925 18:55:38.049222  4179 solver.cpp:244]     Train net output #1: loss3 = 23.185 (* 0.3 = 6.95549 loss)
I0925 18:55:38.049226  4179 solver.cpp:244]     Train net output #2: loss4 = 27.2831 (* 0.2 = 5.45662 loss)
I0925 18:55:38.049231  4179 sgd_solver.cpp:106] Iteration 290, lr = 1e-05
I0925 18:55:39.848215  4179 solver.cpp:228] Iteration 300, loss = 21.5509
I0925 18:55:39.848237  4179 solver.cpp:244]     Train net output #0: loss2 = 18.5918 (* 0.5 = 9.29588 loss)
I0925 18:55:39.848245  4179 solver.cpp:244]     Train net output #1: loss3 = 22.8978 (* 0.3 = 6.86935 loss)
I0925 18:55:39.848249  4179 solver.cpp:244]     Train net output #2: loss4 = 26.9286 (* 0.2 = 5.38572 loss)
I0925 18:55:39.848253  4179 sgd_solver.cpp:106] Iteration 300, lr = 1e-05
I0925 18:55:41.644489  4179 solver.cpp:228] Iteration 310, loss = 21.2752
I0925 18:55:41.644512  4179 solver.cpp:244]     Train net output #0: loss2 = 18.348 (* 0.5 = 9.17401 loss)
I0925 18:55:41.644517  4179 solver.cpp:244]     Train net output #1: loss3 = 22.6175 (* 0.3 = 6.78525 loss)
I0925 18:55:41.644521  4179 solver.cpp:244]     Train net output #2: loss4 = 26.5797 (* 0.2 = 5.31594 loss)
I0925 18:55:41.644526  4179 sgd_solver.cpp:106] Iteration 310, lr = 1e-05
I0925 18:55:43.441994  4179 solver.cpp:228] Iteration 320, loss = 21.0061
I0925 18:55:43.442015  4179 solver.cpp:244]     Train net output #0: loss2 = 18.1111 (* 0.5 = 9.05553 loss)
I0925 18:55:43.442021  4179 solver.cpp:244]     Train net output #1: loss3 = 22.3446 (* 0.3 = 6.70339 loss)
I0925 18:55:43.442025  4179 solver.cpp:244]     Train net output #2: loss4 = 26.2359 (* 0.2 = 5.24718 loss)
I0925 18:55:43.442028  4179 sgd_solver.cpp:106] Iteration 320, lr = 1e-05
I0925 18:55:45.240787  4179 solver.cpp:228] Iteration 330, loss = 20.7434
I0925 18:55:45.240808  4179 solver.cpp:244]     Train net output #0: loss2 = 17.8805 (* 0.5 = 8.94023 loss)
I0925 18:55:45.240813  4179 solver.cpp:244]     Train net output #1: loss3 = 22.0794 (* 0.3 = 6.62381 loss)
I0925 18:55:45.240816  4179 solver.cpp:244]     Train net output #2: loss4 = 25.8966 (* 0.2 = 5.17933 loss)
I0925 18:55:45.240819  4179 sgd_solver.cpp:106] Iteration 330, lr = 1e-05
I0925 18:55:47.039041  4179 solver.cpp:228] Iteration 340, loss = 20.4878
I0925 18:55:47.039084  4179 solver.cpp:244]     Train net output #0: loss2 = 17.6569 (* 0.5 = 8.82843 loss)
I0925 18:55:47.039090  4179 solver.cpp:244]     Train net output #1: loss3 = 21.8222 (* 0.3 = 6.54667 loss)
I0925 18:55:47.039094  4179 solver.cpp:244]     Train net output #2: loss4 = 25.5637 (* 0.2 = 5.11274 loss)
I0925 18:55:47.039098  4179 sgd_solver.cpp:106] Iteration 340, lr = 1e-05
I0925 18:55:48.833631  4179 solver.cpp:228] Iteration 350, loss = 20.2403
I0925 18:55:48.833649  4179 solver.cpp:244]     Train net output #0: loss2 = 17.4405 (* 0.5 = 8.72027 loss)
I0925 18:55:48.833654  4179 solver.cpp:244]     Train net output #1: loss3 = 21.5734 (* 0.3 = 6.47201 loss)
I0925 18:55:48.833658  4179 solver.cpp:244]     Train net output #2: loss4 = 25.2399 (* 0.2 = 5.04798 loss)
I0925 18:55:48.833662  4179 sgd_solver.cpp:106] Iteration 350, lr = 1e-05
I0925 18:55:50.631597  4179 solver.cpp:228] Iteration 360, loss = 19.9996
I0925 18:55:50.631624  4179 solver.cpp:244]     Train net output #0: loss2 = 17.2305 (* 0.5 = 8.61524 loss)
I0925 18:55:50.631629  4179 solver.cpp:244]     Train net output #1: loss3 = 21.3329 (* 0.3 = 6.39988 loss)
I0925 18:55:50.631633  4179 solver.cpp:244]     Train net output #2: loss4 = 24.9223 (* 0.2 = 4.98446 loss)
I0925 18:55:50.631639  4179 sgd_solver.cpp:106] Iteration 360, lr = 1e-05
I0925 18:55:50.642592  4257 caffe.cpp:217] Using GPUs 0
I0925 18:55:50.644841  4257 caffe.cpp:222] GPU 0: GeForce GTX 970
I0925 18:55:50.880108  4257 solver.cpp:48] Initializing solver from parameters: 
test_iter: 392
test_interval: 1000
base_lr: 1e-05
display: 10
max_iter: 20000000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 200000000
snapshot: 1000
snapshot_prefix: "AESR/model_maxout_deconv_bn/model-1"
solver_mode: GPU
device_id: 0
random_seed: 701
net: "AESR/AESR_net.prototxt"
train_state {
  level: 0
  stage: ""
}
test_initialization: false
I0925 18:55:50.880199  4257 solver.cpp:91] Creating training net from net file: AESR/AESR_net.prototxt
I0925 18:55:50.881096  4257 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer low2
I0925 18:55:50.881104  4257 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer low3
I0925 18:55:50.881106  4257 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer low4
I0925 18:55:50.881108  4257 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer label
I0925 18:55:50.881338  4257 net.cpp:58] Initializing net from parameters: 
name: "AESR"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "low2"
  type: "HDF5Data"
  top: "low2"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "AESR/hdf5/tr_txt/low2_1.txt"
    batch_size: 32
  }
}
layer {
  name: "low3"
  type: "HDF5Data"
  top: "low3"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "AESR/hdf5/tr_txt/low3_1.txt"
    batch_size: 32
  }
}
layer {
  name: "low4"
  type: "HDF5Data"
  top: "low4"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "AESR/hdf5/tr_txt/low4_1.txt"
    batch_size: 32
  }
}
layer {
  name: "label"
  type: "HDF5Data"
  top: "label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "AESR/hdf5/tr_txt/label_1.txt"
    batch_size: 32
  }
}
layer {
  name: "conv21"
  type: "Convolution"
  bottom: "low2"
  top: "conv21"
  param {
    name: "conv_W1"
    lr_mult: 0.3
  }
  param {
    name: "conv_b1"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "relu21"
  type: "ReLU"
  bottom: "conv21"
  top: "conv21"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv22"
  type: "Convolution"
  bottom: "conv21"
  top: "conv22"
  param {
    name: "conv_W2"
    lr_mult: 0.3
  }
  param {
    name: "conv_b2"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "bn22"
  type: "BatchNorm"
  bottom: "conv22"
  top: "conv22"
}
layer {
  name: "relu22"
  type: "ReLU"
  bottom: "conv22"
  top: "conv22"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv23"
  type: "Convolution"
  bottom: "conv22"
  top: "conv23"
  param {
    name: "conv_W3"
    lr_mult: 0.3
  }
  param {
    name: "conv_b3"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "bn23"
  type: "BatchNorm"
  bottom: "conv23"
  top: "conv23"
}
layer {
  name: "relu2-13"
  type: "ReLU"
  bottom: "conv23"
  top: "conv23"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "deconv24"
  type: "Deconvolution"
  bottom: "conv23"
  top: "deconv24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 6
    kernel_size: 14
    stride: 2
    weight_filler {
      type: "bilinear"
    }
    engine: CUDNN
  }
}
layer {
  name: "relu24"
  type: "ReLU"
  bottom: "deconv24"
  top: "deconv24"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv25"
  type: "Convolution"
  bottom: "deconv24"
  top: "conv25"
  param {
    name: "conv_W5"
    lr_mult: 0.3
  }
  param {
    name: "conv_b5"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "slice25"
  type: "Slice"
  bottom: "conv25"
  top: "conv25-a"
  top: "conv25-b"
  top: "conv25-c"
  slice_param {
    axis: 1
  }
}
layer {
  name: "maxout25"
  type: "Eltwise"
  bottom: "conv25-a"
  bottom: "conv25-b"
  bottom: "conv25-c"
  top: "maxout25"
  eltwise_param {
    operation: MAX
  }
}
layer {
  name: "bn25"
  type: "BatchNorm"
  bottom: "maxout25"
  top: "maxout25"
}
layer {
  name: "relu25"
  type: "ReLU"
  bottom: "maxout25"
  top: "maxout25"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv26"
  type: "Convolution"
  bottom: "maxout25"
  top: "conv26"
  param {
    name: "conv_W6"
    lr_mult: 0.3
  }
  param {
    name: "conv_b6"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "slice26"
  type: "Slice"
  bottom: "conv26"
  top: "conv26-a"
  top: "conv26-b"
  top: "conv26-c"
  slice_param {
    axis: 1
  }
}
layer {
  name: "maxout26"
  type: "Eltwise"
  bottom: "conv26-a"
  bottom: "conv26-b"
  bottom: "conv26-c"
  top: "maxout26"
  eltwise_param {
    operation: MAX
  }
}
layer {
  name: "bn26"
  type: "BatchNorm"
  bottom: "maxout26"
  top: "maxout26"
}
layer {
  name: "relu26"
  type: "ReLU"
  bottom: "maxout26"
  top: "maxout26"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv27"
  type: "Convolution"
  bottom: "maxout26"
  top: "conv27"
  param {
    name: "conv_W7"
    lr_mult: 0.3
  }
  param {
    name: "conv_b7"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 1
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "conv31"
  type: "Convolution"
  bottom: "low3"
  top: "conv31"
  param {
    name: "conv_W1"
    lr_mult: 0.3
  }
  param {
    name: "conv_b1"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "relu31"
  type: "ReLU"
  bottom: "conv31"
  top: "conv31"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv32"
  type: "Convolution"
  bottom: "conv31"
  top: "conv32"
  param {
    name: "conv_W2"
    lr_mult: 0.3
  }
  param {
    name: "conv_b2"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "bn32"
  type: "BatchNorm"
  bottom: "conv32"
  top: "conv32"
}
layer {
  name: "relu32"
  type: "ReLU"
  bottom: "conv32"
  top: "conv32"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv33"
  type: "Convolution"
  bottom: "conv32"
  top: "conv33"
  param {
    name: "conv_W3"
    lr_mult: 0.3
  }
  param {
    name: "conv_b3"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "bn33"
  type: "BatchNorm"
  bottom: "conv33"
  top: "conv33"
}
layer {
  name: "relu3-13"
  type: "ReLU"
  bottom: "conv33"
  top: "conv33"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "deconv34"
  type: "Deconvolution"
  bottom: "conv33"
  top: "deconv34"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 6
    kernel_size: 15
    stride: 3
    weight_filler {
      type: "bilinear"
    }
    engine: CUDNN
  }
}
layer {
  name: "relu34"
  type: "ReLU"
  bottom: "deconv34"
  top: "deconv34"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv35"
  type: "Convolution"
  bottom: "deconv34"
  top: "conv35"
  param {
    name: "conv_W5"
    lr_mult: 0.3
  }
  param {
    name: "conv_b5"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "slice35"
  type: "Slice"
  bottom: "conv35"
  top: "conv35-a"
  top: "conv35-b"
  top: "conv35-c"
  slice_param {
    axis: 1
  }
}
layer {
  name: "maxout35"
  type: "Eltwise"
  bottom: "conv35-a"
  bottom: "conv35-b"
  bottom: "conv35-c"
  top: "maxout35"
  eltwise_param {
    operation: MAX
  }
}
layer {
  name: "bn35"
  type: "BatchNorm"
  bottom: "maxout35"
  top: "maxout35"
}
layer {
  name: "relu35"
  type: "ReLU"
  bottom: "maxout35"
  top: "maxout35"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv36"
  type: "Convolution"
  bottom: "maxout35"
  top: "conv36"
  param {
    name: "conv_W6"
    lr_mult: 0.3
  }
  param {
    name: "conv_b6"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "slice36"
  type: "Slice"
  bottom: "conv36"
  top: "conv36-a"
  top: "conv36-b"
  top: "conv36-c"
  slice_param {
    axis: 1
  }
}
layer {
  name: "maxout36"
  type: "Eltwise"
  bottom: "conv36-a"
  bottom: "conv36-b"
  bottom: "conv36-c"
  top: "maxout36"
  eltwise_param {
    operation: MAX
  }
}
layer {
  name: "bn36"
  type: "BatchNorm"
  bottom: "maxout36"
  top: "maxout36"
}
layer {
  name: "relu36"
  type: "ReLU"
  bottom: "maxout36"
  top: "maxout36"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv37"
  type: "Convolution"
  bottom: "maxout36"
  top: "conv37"
  param {
    name: "conv_W7"
    lr_mult: 0.3
  }
  param {
    name: "conv_b7"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 1
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "conv41"
  type: "Convolution"
  bottom: "low4"
  top: "conv41"
  param {
    name: "conv_W1"
    lr_mult: 0.3
  }
  param {
    name: "conv_b1"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "relu41"
  type: "ReLU"
  bottom: "conv41"
  top: "conv41"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv42"
  type: "Convolution"
  bottom: "conv41"
  top: "conv42"
  param {
    name: "conv_W2"
    lr_mult: 0.3
  }
  param {
    name: "conv_b2"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "bn42"
  type: "BatchNorm"
  bottom: "conv42"
  top: "conv42"
}
layer {
  name: "relu42"
  type: "ReLU"
  bottom: "conv42"
  top: "conv42"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv43"
  type: "Convolution"
  bottom: "conv42"
  top: "conv43"
  param {
    name: "conv_W3"
    lr_mult: 0.3
  }
  param {
    name: "conv_b3"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "bn43"
  type: "BatchNorm"
  bottom: "conv43"
  top: "conv43"
}
layer {
  name: "relu4-13"
  type: "ReLU"
  bottom: "conv43"
  top: "conv43"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "deconv44"
  type: "Deconvolution"
  bottom: "conv43"
  top: "deconv44"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 6
    kernel_size: 16
    stride: 4
    weight_filler {
      type: "bilinear"
    }
    engine: CUDNN
  }
}
layer {
  name: "relu44"
  type: "ReLU"
  bottom: "deconv44"
  top: "deconv44"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv45"
  type: "Convolution"
  bottom: "deconv44"
  top: "conv45"
  param {
    name: "conv_W5"
    lr_mult: 0.3
  }
  param {
    name: "conv_b5"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "slice45"
  type: "Slice"
  bottom: "conv45"
  top: "conv45-a"
  top: "conv45-b"
  top: "conv45-c"
  slice_param {
    axis: 1
  }
}
layer {
  name: "maxout45"
  type: "Eltwise"
  bottom: "conv45-a"
  bottom: "conv45-b"
  bottom: "conv45-c"
  top: "maxout45"
  eltwise_param {
    operation: MAX
  }
}
layer {
  name: "bn45"
  type: "BatchNorm"
  bottom: "maxout45"
  top: "maxout45"
}
layer {
  name: "relu45"
  type: "ReLU"
  bottom: "maxout45"
  top: "maxout45"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv46"
  type: "Convolution"
  bottom: "maxout45"
  top: "conv46"
  param {
    name: "conv_W6"
    lr_mult: 0.3
  }
  param {
    name: "conv_b6"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "slice46"
  type: "Slice"
  bottom: "conv46"
  top: "conv46-a"
  top: "conv46-b"
  top: "conv46-c"
  slice_param {
    axis: 1
  }
}
layer {
  name: "maxout46"
  type: "Eltwise"
  bottom: "conv46-a"
  bottom: "conv46-b"
  bottom: "conv46-c"
  top: "maxout46"
  eltwise_param {
    operation: MAX
  }
}
layer {
  name: "bn46"
  type: "BatchNorm"
  bottom: "maxout46"
  top: "maxout46"
}
layer {
  name: "relu46"
  type: "ReLU"
  bottom: "maxout46"
  top: "maxout46"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv47"
  type: "Convolution"
  bottom: "maxout46"
  top: "conv47"
  param {
    name: "conv_W7"
    lr_mult: 0.3
  }
  param {
    name: "conv_b7"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 1
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "loss2"
  type: "EuclideanLoss"
  bottom: "conv27"
  bottom: "label"
  top: "loss2"
  loss_weight: 0.5
}
layer {
  name: "loss3"
  type: "EuclideanLoss"
  bottom: "conv37"
  bottom: "label"
  top: "loss3"
  loss_weight: 0.3
}
layer {
  name: "loss4"
  type: "EuclideanLoss"
  bottom: "conv47"
  bottom: "label"
  top: "loss4"
  loss_weight: 0.2
}
I0925 18:55:50.881520  4257 layer_factory.hpp:77] Creating layer low2
I0925 18:55:50.881536  4257 net.cpp:100] Creating Layer low2
I0925 18:55:50.881541  4257 net.cpp:408] low2 -> low2
I0925 18:55:50.881553  4257 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: AESR/hdf5/tr_txt/low2_1.txt
I0925 18:55:50.881570  4257 hdf5_data_layer.cpp:93] Number of HDF5 files: 1
I0925 18:55:50.882030  4257 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0925 18:55:50.933534  4257 net.cpp:150] Setting up low2
I0925 18:55:50.933557  4257 net.cpp:157] Top shape: 32 1 36 36 (41472)
I0925 18:55:50.933560  4257 net.cpp:165] Memory required for data: 165888
I0925 18:55:50.933567  4257 layer_factory.hpp:77] Creating layer low3
I0925 18:55:50.933576  4257 net.cpp:100] Creating Layer low3
I0925 18:55:50.933579  4257 net.cpp:408] low3 -> low3
I0925 18:55:50.933588  4257 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: AESR/hdf5/tr_txt/low3_1.txt
I0925 18:55:50.933605  4257 hdf5_data_layer.cpp:93] Number of HDF5 files: 1
I0925 18:55:50.934092  4257 net.cpp:150] Setting up low3
I0925 18:55:50.934103  4257 net.cpp:157] Top shape: 32 1 24 24 (18432)
I0925 18:55:50.934105  4257 net.cpp:165] Memory required for data: 239616
I0925 18:55:50.934108  4257 layer_factory.hpp:77] Creating layer low4
I0925 18:55:50.934113  4257 net.cpp:100] Creating Layer low4
I0925 18:55:50.934114  4257 net.cpp:408] low4 -> low4
I0925 18:55:50.934119  4257 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: AESR/hdf5/tr_txt/low4_1.txt
I0925 18:55:50.934128  4257 hdf5_data_layer.cpp:93] Number of HDF5 files: 1
I0925 18:55:50.934295  4257 net.cpp:150] Setting up low4
I0925 18:55:50.934303  4257 net.cpp:157] Top shape: 32 1 18 18 (10368)
I0925 18:55:50.934305  4257 net.cpp:165] Memory required for data: 281088
I0925 18:55:50.934308  4257 layer_factory.hpp:77] Creating layer label
I0925 18:55:50.934311  4257 net.cpp:100] Creating Layer label
I0925 18:55:50.934314  4257 net.cpp:408] label -> label
I0925 18:55:50.934319  4257 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: AESR/hdf5/tr_txt/label_1.txt
I0925 18:55:50.934326  4257 hdf5_data_layer.cpp:93] Number of HDF5 files: 1
I0925 18:55:50.934893  4257 net.cpp:150] Setting up label
I0925 18:55:50.934902  4257 net.cpp:157] Top shape: 32 1 72 72 (165888)
I0925 18:55:50.934906  4257 net.cpp:165] Memory required for data: 944640
I0925 18:55:50.934908  4257 layer_factory.hpp:77] Creating layer label_label_0_split
I0925 18:55:50.934917  4257 net.cpp:100] Creating Layer label_label_0_split
I0925 18:55:50.934921  4257 net.cpp:434] label_label_0_split <- label
I0925 18:55:50.934929  4257 net.cpp:408] label_label_0_split -> label_label_0_split_0
I0925 18:55:50.934936  4257 net.cpp:408] label_label_0_split -> label_label_0_split_1
I0925 18:55:50.934940  4257 net.cpp:408] label_label_0_split -> label_label_0_split_2
I0925 18:55:50.934965  4257 net.cpp:150] Setting up label_label_0_split
I0925 18:55:50.934970  4257 net.cpp:157] Top shape: 32 1 72 72 (165888)
I0925 18:55:50.934973  4257 net.cpp:157] Top shape: 32 1 72 72 (165888)
I0925 18:55:50.934975  4257 net.cpp:157] Top shape: 32 1 72 72 (165888)
I0925 18:55:50.934978  4257 net.cpp:165] Memory required for data: 2935296
I0925 18:55:50.934980  4257 layer_factory.hpp:77] Creating layer conv21
I0925 18:55:50.934991  4257 net.cpp:100] Creating Layer conv21
I0925 18:55:50.934994  4257 net.cpp:434] conv21 <- low2
I0925 18:55:50.934998  4257 net.cpp:408] conv21 -> conv21
I0925 18:55:51.088454  4257 net.cpp:150] Setting up conv21
I0925 18:55:51.088476  4257 net.cpp:157] Top shape: 32 16 36 36 (663552)
I0925 18:55:51.088479  4257 net.cpp:165] Memory required for data: 5589504
I0925 18:55:51.088491  4257 layer_factory.hpp:77] Creating layer relu21
I0925 18:55:51.088500  4257 net.cpp:100] Creating Layer relu21
I0925 18:55:51.088503  4257 net.cpp:434] relu21 <- conv21
I0925 18:55:51.088507  4257 net.cpp:395] relu21 -> conv21 (in-place)
I0925 18:55:51.089316  4257 net.cpp:150] Setting up relu21
I0925 18:55:51.089323  4257 net.cpp:157] Top shape: 32 16 36 36 (663552)
I0925 18:55:51.089325  4257 net.cpp:165] Memory required for data: 8243712
I0925 18:55:51.089337  4257 layer_factory.hpp:77] Creating layer conv22
I0925 18:55:51.089346  4257 net.cpp:100] Creating Layer conv22
I0925 18:55:51.089350  4257 net.cpp:434] conv22 <- conv21
I0925 18:55:51.089354  4257 net.cpp:408] conv22 -> conv22
I0925 18:55:51.092986  4257 net.cpp:150] Setting up conv22
I0925 18:55:51.092996  4257 net.cpp:157] Top shape: 32 16 36 36 (663552)
I0925 18:55:51.092998  4257 net.cpp:165] Memory required for data: 10897920
I0925 18:55:51.093004  4257 layer_factory.hpp:77] Creating layer bn22
I0925 18:55:51.093013  4257 net.cpp:100] Creating Layer bn22
I0925 18:55:51.093016  4257 net.cpp:434] bn22 <- conv22
I0925 18:55:51.093019  4257 net.cpp:395] bn22 -> conv22 (in-place)
I0925 18:55:51.093125  4257 net.cpp:150] Setting up bn22
I0925 18:55:51.093130  4257 net.cpp:157] Top shape: 32 16 36 36 (663552)
I0925 18:55:51.093132  4257 net.cpp:165] Memory required for data: 13552128
I0925 18:55:51.093138  4257 layer_factory.hpp:77] Creating layer relu22
I0925 18:55:51.093142  4257 net.cpp:100] Creating Layer relu22
I0925 18:55:51.093144  4257 net.cpp:434] relu22 <- conv22
I0925 18:55:51.093147  4257 net.cpp:395] relu22 -> conv22 (in-place)
I0925 18:55:51.094193  4257 net.cpp:150] Setting up relu22
I0925 18:55:51.094202  4257 net.cpp:157] Top shape: 32 16 36 36 (663552)
I0925 18:55:51.094204  4257 net.cpp:165] Memory required for data: 16206336
I0925 18:55:51.094207  4257 layer_factory.hpp:77] Creating layer conv23
I0925 18:55:51.094213  4257 net.cpp:100] Creating Layer conv23
I0925 18:55:51.094215  4257 net.cpp:434] conv23 <- conv22
I0925 18:55:51.094219  4257 net.cpp:408] conv23 -> conv23
I0925 18:55:51.097713  4257 net.cpp:150] Setting up conv23
I0925 18:55:51.097723  4257 net.cpp:157] Top shape: 32 16 36 36 (663552)
I0925 18:55:51.097725  4257 net.cpp:165] Memory required for data: 18860544
I0925 18:55:51.097730  4257 layer_factory.hpp:77] Creating layer bn23
I0925 18:55:51.097734  4257 net.cpp:100] Creating Layer bn23
I0925 18:55:51.097736  4257 net.cpp:434] bn23 <- conv23
I0925 18:55:51.097739  4257 net.cpp:395] bn23 -> conv23 (in-place)
I0925 18:55:51.097841  4257 net.cpp:150] Setting up bn23
I0925 18:55:51.097846  4257 net.cpp:157] Top shape: 32 16 36 36 (663552)
I0925 18:55:51.097848  4257 net.cpp:165] Memory required for data: 21514752
I0925 18:55:51.097852  4257 layer_factory.hpp:77] Creating layer relu2-13
I0925 18:55:51.097856  4257 net.cpp:100] Creating Layer relu2-13
I0925 18:55:51.097859  4257 net.cpp:434] relu2-13 <- conv23
I0925 18:55:51.097862  4257 net.cpp:395] relu2-13 -> conv23 (in-place)
I0925 18:55:51.098909  4257 net.cpp:150] Setting up relu2-13
I0925 18:55:51.098917  4257 net.cpp:157] Top shape: 32 16 36 36 (663552)
I0925 18:55:51.098920  4257 net.cpp:165] Memory required for data: 24168960
I0925 18:55:51.098922  4257 layer_factory.hpp:77] Creating layer deconv24
I0925 18:55:51.098927  4257 net.cpp:100] Creating Layer deconv24
I0925 18:55:51.098929  4257 net.cpp:434] deconv24 <- conv23
I0925 18:55:51.098933  4257 net.cpp:408] deconv24 -> deconv24
I0925 18:55:51.100741  4257 net.cpp:150] Setting up deconv24
I0925 18:55:51.100750  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.100752  4257 net.cpp:165] Memory required for data: 34785792
I0925 18:55:51.100756  4257 layer_factory.hpp:77] Creating layer relu24
I0925 18:55:51.100760  4257 net.cpp:100] Creating Layer relu24
I0925 18:55:51.100764  4257 net.cpp:434] relu24 <- deconv24
I0925 18:55:51.100766  4257 net.cpp:395] relu24 -> deconv24 (in-place)
I0925 18:55:51.100863  4257 net.cpp:150] Setting up relu24
I0925 18:55:51.100868  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.100870  4257 net.cpp:165] Memory required for data: 45402624
I0925 18:55:51.100873  4257 layer_factory.hpp:77] Creating layer conv25
I0925 18:55:51.100879  4257 net.cpp:100] Creating Layer conv25
I0925 18:55:51.100881  4257 net.cpp:434] conv25 <- deconv24
I0925 18:55:51.100885  4257 net.cpp:408] conv25 -> conv25
I0925 18:55:51.103840  4257 net.cpp:150] Setting up conv25
I0925 18:55:51.103849  4257 net.cpp:157] Top shape: 32 48 72 72 (7962624)
I0925 18:55:51.103857  4257 net.cpp:165] Memory required for data: 77253120
I0925 18:55:51.103863  4257 layer_factory.hpp:77] Creating layer slice25
I0925 18:55:51.103868  4257 net.cpp:100] Creating Layer slice25
I0925 18:55:51.103870  4257 net.cpp:434] slice25 <- conv25
I0925 18:55:51.103874  4257 net.cpp:408] slice25 -> conv25-a
I0925 18:55:51.103880  4257 net.cpp:408] slice25 -> conv25-b
I0925 18:55:51.103885  4257 net.cpp:408] slice25 -> conv25-c
I0925 18:55:51.103914  4257 net.cpp:150] Setting up slice25
I0925 18:55:51.103919  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.103921  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.103924  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.103925  4257 net.cpp:165] Memory required for data: 109103616
I0925 18:55:51.103927  4257 layer_factory.hpp:77] Creating layer maxout25
I0925 18:55:51.103934  4257 net.cpp:100] Creating Layer maxout25
I0925 18:55:51.103936  4257 net.cpp:434] maxout25 <- conv25-a
I0925 18:55:51.103940  4257 net.cpp:434] maxout25 <- conv25-b
I0925 18:55:51.103943  4257 net.cpp:434] maxout25 <- conv25-c
I0925 18:55:51.103946  4257 net.cpp:408] maxout25 -> maxout25
I0925 18:55:51.103970  4257 net.cpp:150] Setting up maxout25
I0925 18:55:51.103973  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.103976  4257 net.cpp:165] Memory required for data: 119720448
I0925 18:55:51.103977  4257 layer_factory.hpp:77] Creating layer bn25
I0925 18:55:51.103981  4257 net.cpp:100] Creating Layer bn25
I0925 18:55:51.103983  4257 net.cpp:434] bn25 <- maxout25
I0925 18:55:51.103986  4257 net.cpp:395] bn25 -> maxout25 (in-place)
I0925 18:55:51.104085  4257 net.cpp:150] Setting up bn25
I0925 18:55:51.104089  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.104092  4257 net.cpp:165] Memory required for data: 130337280
I0925 18:55:51.104099  4257 layer_factory.hpp:77] Creating layer relu25
I0925 18:55:51.104102  4257 net.cpp:100] Creating Layer relu25
I0925 18:55:51.104105  4257 net.cpp:434] relu25 <- maxout25
I0925 18:55:51.104107  4257 net.cpp:395] relu25 -> maxout25 (in-place)
I0925 18:55:51.104854  4257 net.cpp:150] Setting up relu25
I0925 18:55:51.104862  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.104864  4257 net.cpp:165] Memory required for data: 140954112
I0925 18:55:51.104866  4257 layer_factory.hpp:77] Creating layer conv26
I0925 18:55:51.104873  4257 net.cpp:100] Creating Layer conv26
I0925 18:55:51.104876  4257 net.cpp:434] conv26 <- maxout25
I0925 18:55:51.104879  4257 net.cpp:408] conv26 -> conv26
I0925 18:55:51.109721  4257 net.cpp:150] Setting up conv26
I0925 18:55:51.109730  4257 net.cpp:157] Top shape: 32 48 72 72 (7962624)
I0925 18:55:51.109732  4257 net.cpp:165] Memory required for data: 172804608
I0925 18:55:51.109737  4257 layer_factory.hpp:77] Creating layer slice26
I0925 18:55:51.109741  4257 net.cpp:100] Creating Layer slice26
I0925 18:55:51.109743  4257 net.cpp:434] slice26 <- conv26
I0925 18:55:51.109746  4257 net.cpp:408] slice26 -> conv26-a
I0925 18:55:51.109750  4257 net.cpp:408] slice26 -> conv26-b
I0925 18:55:51.109755  4257 net.cpp:408] slice26 -> conv26-c
I0925 18:55:51.109782  4257 net.cpp:150] Setting up slice26
I0925 18:55:51.109787  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.109789  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.109791  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.109793  4257 net.cpp:165] Memory required for data: 204655104
I0925 18:55:51.109796  4257 layer_factory.hpp:77] Creating layer maxout26
I0925 18:55:51.109799  4257 net.cpp:100] Creating Layer maxout26
I0925 18:55:51.109802  4257 net.cpp:434] maxout26 <- conv26-a
I0925 18:55:51.109804  4257 net.cpp:434] maxout26 <- conv26-b
I0925 18:55:51.109807  4257 net.cpp:434] maxout26 <- conv26-c
I0925 18:55:51.109812  4257 net.cpp:408] maxout26 -> maxout26
I0925 18:55:51.109829  4257 net.cpp:150] Setting up maxout26
I0925 18:55:51.109833  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.109841  4257 net.cpp:165] Memory required for data: 215271936
I0925 18:55:51.109843  4257 layer_factory.hpp:77] Creating layer bn26
I0925 18:55:51.109848  4257 net.cpp:100] Creating Layer bn26
I0925 18:55:51.109849  4257 net.cpp:434] bn26 <- maxout26
I0925 18:55:51.109853  4257 net.cpp:395] bn26 -> maxout26 (in-place)
I0925 18:55:51.109956  4257 net.cpp:150] Setting up bn26
I0925 18:55:51.109959  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.109961  4257 net.cpp:165] Memory required for data: 225888768
I0925 18:55:51.109966  4257 layer_factory.hpp:77] Creating layer relu26
I0925 18:55:51.109971  4257 net.cpp:100] Creating Layer relu26
I0925 18:55:51.109972  4257 net.cpp:434] relu26 <- maxout26
I0925 18:55:51.109975  4257 net.cpp:395] relu26 -> maxout26 (in-place)
I0925 18:55:51.111016  4257 net.cpp:150] Setting up relu26
I0925 18:55:51.111022  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.111024  4257 net.cpp:165] Memory required for data: 236505600
I0925 18:55:51.111027  4257 layer_factory.hpp:77] Creating layer conv27
I0925 18:55:51.111032  4257 net.cpp:100] Creating Layer conv27
I0925 18:55:51.111035  4257 net.cpp:434] conv27 <- maxout26
I0925 18:55:51.111038  4257 net.cpp:408] conv27 -> conv27
I0925 18:55:51.115607  4257 net.cpp:150] Setting up conv27
I0925 18:55:51.115615  4257 net.cpp:157] Top shape: 32 1 72 72 (165888)
I0925 18:55:51.115618  4257 net.cpp:165] Memory required for data: 237169152
I0925 18:55:51.115622  4257 layer_factory.hpp:77] Creating layer conv31
I0925 18:55:51.115628  4257 net.cpp:100] Creating Layer conv31
I0925 18:55:51.115631  4257 net.cpp:434] conv31 <- low3
I0925 18:55:51.115635  4257 net.cpp:408] conv31 -> conv31
I0925 18:55:51.119592  4257 net.cpp:150] Setting up conv31
I0925 18:55:51.119601  4257 net.cpp:157] Top shape: 32 16 24 24 (294912)
I0925 18:55:51.119604  4257 net.cpp:165] Memory required for data: 238348800
I0925 18:55:51.119607  4257 net.cpp:493] Sharing parameters 'conv_W1' owned by layer 'conv21', param index 0
I0925 18:55:51.119611  4257 net.cpp:493] Sharing parameters 'conv_b1' owned by layer 'conv21', param index 1
I0925 18:55:51.119612  4257 layer_factory.hpp:77] Creating layer relu31
I0925 18:55:51.119616  4257 net.cpp:100] Creating Layer relu31
I0925 18:55:51.119619  4257 net.cpp:434] relu31 <- conv31
I0925 18:55:51.119622  4257 net.cpp:395] relu31 -> conv31 (in-place)
I0925 18:55:51.120453  4257 net.cpp:150] Setting up relu31
I0925 18:55:51.120460  4257 net.cpp:157] Top shape: 32 16 24 24 (294912)
I0925 18:55:51.120462  4257 net.cpp:165] Memory required for data: 239528448
I0925 18:55:51.120465  4257 layer_factory.hpp:77] Creating layer conv32
I0925 18:55:51.120471  4257 net.cpp:100] Creating Layer conv32
I0925 18:55:51.120472  4257 net.cpp:434] conv32 <- conv31
I0925 18:55:51.120476  4257 net.cpp:408] conv32 -> conv32
I0925 18:55:51.124117  4257 net.cpp:150] Setting up conv32
I0925 18:55:51.124126  4257 net.cpp:157] Top shape: 32 16 24 24 (294912)
I0925 18:55:51.124128  4257 net.cpp:165] Memory required for data: 240708096
I0925 18:55:51.124131  4257 net.cpp:493] Sharing parameters 'conv_W2' owned by layer 'conv22', param index 0
I0925 18:55:51.124135  4257 net.cpp:493] Sharing parameters 'conv_b2' owned by layer 'conv22', param index 1
I0925 18:55:51.124136  4257 layer_factory.hpp:77] Creating layer bn32
I0925 18:55:51.124140  4257 net.cpp:100] Creating Layer bn32
I0925 18:55:51.124143  4257 net.cpp:434] bn32 <- conv32
I0925 18:55:51.124146  4257 net.cpp:395] bn32 -> conv32 (in-place)
I0925 18:55:51.124263  4257 net.cpp:150] Setting up bn32
I0925 18:55:51.124267  4257 net.cpp:157] Top shape: 32 16 24 24 (294912)
I0925 18:55:51.124269  4257 net.cpp:165] Memory required for data: 241887744
I0925 18:55:51.124276  4257 layer_factory.hpp:77] Creating layer relu32
I0925 18:55:51.124280  4257 net.cpp:100] Creating Layer relu32
I0925 18:55:51.124282  4257 net.cpp:434] relu32 <- conv32
I0925 18:55:51.124286  4257 net.cpp:395] relu32 -> conv32 (in-place)
I0925 18:55:51.125223  4257 net.cpp:150] Setting up relu32
I0925 18:55:51.125236  4257 net.cpp:157] Top shape: 32 16 24 24 (294912)
I0925 18:55:51.125239  4257 net.cpp:165] Memory required for data: 243067392
I0925 18:55:51.125241  4257 layer_factory.hpp:77] Creating layer conv33
I0925 18:55:51.125248  4257 net.cpp:100] Creating Layer conv33
I0925 18:55:51.125252  4257 net.cpp:434] conv33 <- conv32
I0925 18:55:51.125255  4257 net.cpp:408] conv33 -> conv33
I0925 18:55:51.128921  4257 net.cpp:150] Setting up conv33
I0925 18:55:51.128929  4257 net.cpp:157] Top shape: 32 16 24 24 (294912)
I0925 18:55:51.128931  4257 net.cpp:165] Memory required for data: 244247040
I0925 18:55:51.128934  4257 net.cpp:493] Sharing parameters 'conv_W3' owned by layer 'conv23', param index 0
I0925 18:55:51.128937  4257 net.cpp:493] Sharing parameters 'conv_b3' owned by layer 'conv23', param index 1
I0925 18:55:51.128939  4257 layer_factory.hpp:77] Creating layer bn33
I0925 18:55:51.128945  4257 net.cpp:100] Creating Layer bn33
I0925 18:55:51.128947  4257 net.cpp:434] bn33 <- conv33
I0925 18:55:51.128950  4257 net.cpp:395] bn33 -> conv33 (in-place)
I0925 18:55:51.129065  4257 net.cpp:150] Setting up bn33
I0925 18:55:51.129070  4257 net.cpp:157] Top shape: 32 16 24 24 (294912)
I0925 18:55:51.129071  4257 net.cpp:165] Memory required for data: 245426688
I0925 18:55:51.129076  4257 layer_factory.hpp:77] Creating layer relu3-13
I0925 18:55:51.129081  4257 net.cpp:100] Creating Layer relu3-13
I0925 18:55:51.129082  4257 net.cpp:434] relu3-13 <- conv33
I0925 18:55:51.129086  4257 net.cpp:395] relu3-13 -> conv33 (in-place)
I0925 18:55:51.130038  4257 net.cpp:150] Setting up relu3-13
I0925 18:55:51.130046  4257 net.cpp:157] Top shape: 32 16 24 24 (294912)
I0925 18:55:51.130048  4257 net.cpp:165] Memory required for data: 246606336
I0925 18:55:51.130050  4257 layer_factory.hpp:77] Creating layer deconv34
I0925 18:55:51.130055  4257 net.cpp:100] Creating Layer deconv34
I0925 18:55:51.130059  4257 net.cpp:434] deconv34 <- conv33
I0925 18:55:51.130061  4257 net.cpp:408] deconv34 -> deconv34
I0925 18:55:51.131806  4257 net.cpp:150] Setting up deconv34
I0925 18:55:51.131813  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.131814  4257 net.cpp:165] Memory required for data: 257223168
I0925 18:55:51.131819  4257 layer_factory.hpp:77] Creating layer relu34
I0925 18:55:51.131824  4257 net.cpp:100] Creating Layer relu34
I0925 18:55:51.131825  4257 net.cpp:434] relu34 <- deconv34
I0925 18:55:51.131829  4257 net.cpp:395] relu34 -> deconv34 (in-place)
I0925 18:55:51.131930  4257 net.cpp:150] Setting up relu34
I0925 18:55:51.131937  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.131938  4257 net.cpp:165] Memory required for data: 267840000
I0925 18:55:51.131940  4257 layer_factory.hpp:77] Creating layer conv35
I0925 18:55:51.131947  4257 net.cpp:100] Creating Layer conv35
I0925 18:55:51.131949  4257 net.cpp:434] conv35 <- deconv34
I0925 18:55:51.131953  4257 net.cpp:408] conv35 -> conv35
I0925 18:55:51.134940  4257 net.cpp:150] Setting up conv35
I0925 18:55:51.134949  4257 net.cpp:157] Top shape: 32 48 72 72 (7962624)
I0925 18:55:51.134951  4257 net.cpp:165] Memory required for data: 299690496
I0925 18:55:51.134954  4257 net.cpp:493] Sharing parameters 'conv_W5' owned by layer 'conv25', param index 0
I0925 18:55:51.134958  4257 net.cpp:493] Sharing parameters 'conv_b5' owned by layer 'conv25', param index 1
I0925 18:55:51.134959  4257 layer_factory.hpp:77] Creating layer slice35
I0925 18:55:51.134963  4257 net.cpp:100] Creating Layer slice35
I0925 18:55:51.134965  4257 net.cpp:434] slice35 <- conv35
I0925 18:55:51.134969  4257 net.cpp:408] slice35 -> conv35-a
I0925 18:55:51.134975  4257 net.cpp:408] slice35 -> conv35-b
I0925 18:55:51.134980  4257 net.cpp:408] slice35 -> conv35-c
I0925 18:55:51.135012  4257 net.cpp:150] Setting up slice35
I0925 18:55:51.135016  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.135020  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.135021  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.135023  4257 net.cpp:165] Memory required for data: 331540992
I0925 18:55:51.135031  4257 layer_factory.hpp:77] Creating layer maxout35
I0925 18:55:51.135035  4257 net.cpp:100] Creating Layer maxout35
I0925 18:55:51.135037  4257 net.cpp:434] maxout35 <- conv35-a
I0925 18:55:51.135040  4257 net.cpp:434] maxout35 <- conv35-b
I0925 18:55:51.135042  4257 net.cpp:434] maxout35 <- conv35-c
I0925 18:55:51.135047  4257 net.cpp:408] maxout35 -> maxout35
I0925 18:55:51.135071  4257 net.cpp:150] Setting up maxout35
I0925 18:55:51.135074  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.135076  4257 net.cpp:165] Memory required for data: 342157824
I0925 18:55:51.135078  4257 layer_factory.hpp:77] Creating layer bn35
I0925 18:55:51.135082  4257 net.cpp:100] Creating Layer bn35
I0925 18:55:51.135084  4257 net.cpp:434] bn35 <- maxout35
I0925 18:55:51.135087  4257 net.cpp:395] bn35 -> maxout35 (in-place)
I0925 18:55:51.135200  4257 net.cpp:150] Setting up bn35
I0925 18:55:51.135205  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.135206  4257 net.cpp:165] Memory required for data: 352774656
I0925 18:55:51.135210  4257 layer_factory.hpp:77] Creating layer relu35
I0925 18:55:51.135215  4257 net.cpp:100] Creating Layer relu35
I0925 18:55:51.135217  4257 net.cpp:434] relu35 <- maxout35
I0925 18:55:51.135221  4257 net.cpp:395] relu35 -> maxout35 (in-place)
I0925 18:55:51.136113  4257 net.cpp:150] Setting up relu35
I0925 18:55:51.136121  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.136123  4257 net.cpp:165] Memory required for data: 363391488
I0925 18:55:51.136126  4257 layer_factory.hpp:77] Creating layer conv36
I0925 18:55:51.136132  4257 net.cpp:100] Creating Layer conv36
I0925 18:55:51.136135  4257 net.cpp:434] conv36 <- maxout35
I0925 18:55:51.136139  4257 net.cpp:408] conv36 -> conv36
I0925 18:55:51.139750  4257 net.cpp:150] Setting up conv36
I0925 18:55:51.139758  4257 net.cpp:157] Top shape: 32 48 72 72 (7962624)
I0925 18:55:51.139761  4257 net.cpp:165] Memory required for data: 395241984
I0925 18:55:51.139765  4257 net.cpp:493] Sharing parameters 'conv_W6' owned by layer 'conv26', param index 0
I0925 18:55:51.139766  4257 net.cpp:493] Sharing parameters 'conv_b6' owned by layer 'conv26', param index 1
I0925 18:55:51.139768  4257 layer_factory.hpp:77] Creating layer slice36
I0925 18:55:51.139772  4257 net.cpp:100] Creating Layer slice36
I0925 18:55:51.139775  4257 net.cpp:434] slice36 <- conv36
I0925 18:55:51.139778  4257 net.cpp:408] slice36 -> conv36-a
I0925 18:55:51.139786  4257 net.cpp:408] slice36 -> conv36-b
I0925 18:55:51.139791  4257 net.cpp:408] slice36 -> conv36-c
I0925 18:55:51.139822  4257 net.cpp:150] Setting up slice36
I0925 18:55:51.139827  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.139829  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.139832  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.139833  4257 net.cpp:165] Memory required for data: 427092480
I0925 18:55:51.139835  4257 layer_factory.hpp:77] Creating layer maxout36
I0925 18:55:51.139839  4257 net.cpp:100] Creating Layer maxout36
I0925 18:55:51.139842  4257 net.cpp:434] maxout36 <- conv36-a
I0925 18:55:51.139844  4257 net.cpp:434] maxout36 <- conv36-b
I0925 18:55:51.139847  4257 net.cpp:434] maxout36 <- conv36-c
I0925 18:55:51.139850  4257 net.cpp:408] maxout36 -> maxout36
I0925 18:55:51.139873  4257 net.cpp:150] Setting up maxout36
I0925 18:55:51.139875  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.139878  4257 net.cpp:165] Memory required for data: 437709312
I0925 18:55:51.139879  4257 layer_factory.hpp:77] Creating layer bn36
I0925 18:55:51.139883  4257 net.cpp:100] Creating Layer bn36
I0925 18:55:51.139885  4257 net.cpp:434] bn36 <- maxout36
I0925 18:55:51.139889  4257 net.cpp:395] bn36 -> maxout36 (in-place)
I0925 18:55:51.140000  4257 net.cpp:150] Setting up bn36
I0925 18:55:51.140005  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.140007  4257 net.cpp:165] Memory required for data: 448326144
I0925 18:55:51.140012  4257 layer_factory.hpp:77] Creating layer relu36
I0925 18:55:51.140022  4257 net.cpp:100] Creating Layer relu36
I0925 18:55:51.140024  4257 net.cpp:434] relu36 <- maxout36
I0925 18:55:51.140027  4257 net.cpp:395] relu36 -> maxout36 (in-place)
I0925 18:55:51.140925  4257 net.cpp:150] Setting up relu36
I0925 18:55:51.140931  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.140933  4257 net.cpp:165] Memory required for data: 458942976
I0925 18:55:51.140936  4257 layer_factory.hpp:77] Creating layer conv37
I0925 18:55:51.140943  4257 net.cpp:100] Creating Layer conv37
I0925 18:55:51.140945  4257 net.cpp:434] conv37 <- maxout36
I0925 18:55:51.140949  4257 net.cpp:408] conv37 -> conv37
I0925 18:55:51.144546  4257 net.cpp:150] Setting up conv37
I0925 18:55:51.144556  4257 net.cpp:157] Top shape: 32 1 72 72 (165888)
I0925 18:55:51.144557  4257 net.cpp:165] Memory required for data: 459606528
I0925 18:55:51.144561  4257 net.cpp:493] Sharing parameters 'conv_W7' owned by layer 'conv27', param index 0
I0925 18:55:51.144563  4257 net.cpp:493] Sharing parameters 'conv_b7' owned by layer 'conv27', param index 1
I0925 18:55:51.144565  4257 layer_factory.hpp:77] Creating layer conv41
I0925 18:55:51.144572  4257 net.cpp:100] Creating Layer conv41
I0925 18:55:51.144574  4257 net.cpp:434] conv41 <- low4
I0925 18:55:51.144579  4257 net.cpp:408] conv41 -> conv41
I0925 18:55:51.148069  4257 net.cpp:150] Setting up conv41
I0925 18:55:51.148078  4257 net.cpp:157] Top shape: 32 16 18 18 (165888)
I0925 18:55:51.148080  4257 net.cpp:165] Memory required for data: 460270080
I0925 18:55:51.148083  4257 net.cpp:493] Sharing parameters 'conv_W1' owned by layer 'conv21', param index 0
I0925 18:55:51.148087  4257 net.cpp:493] Sharing parameters 'conv_b1' owned by layer 'conv21', param index 1
I0925 18:55:51.148088  4257 layer_factory.hpp:77] Creating layer relu41
I0925 18:55:51.148092  4257 net.cpp:100] Creating Layer relu41
I0925 18:55:51.148094  4257 net.cpp:434] relu41 <- conv41
I0925 18:55:51.148098  4257 net.cpp:395] relu41 -> conv41 (in-place)
I0925 18:55:51.149444  4257 net.cpp:150] Setting up relu41
I0925 18:55:51.149451  4257 net.cpp:157] Top shape: 32 16 18 18 (165888)
I0925 18:55:51.149453  4257 net.cpp:165] Memory required for data: 460933632
I0925 18:55:51.149456  4257 layer_factory.hpp:77] Creating layer conv42
I0925 18:55:51.149461  4257 net.cpp:100] Creating Layer conv42
I0925 18:55:51.149464  4257 net.cpp:434] conv42 <- conv41
I0925 18:55:51.149468  4257 net.cpp:408] conv42 -> conv42
I0925 18:55:51.151793  4257 net.cpp:150] Setting up conv42
I0925 18:55:51.151801  4257 net.cpp:157] Top shape: 32 16 18 18 (165888)
I0925 18:55:51.151803  4257 net.cpp:165] Memory required for data: 461597184
I0925 18:55:51.151806  4257 net.cpp:493] Sharing parameters 'conv_W2' owned by layer 'conv22', param index 0
I0925 18:55:51.151809  4257 net.cpp:493] Sharing parameters 'conv_b2' owned by layer 'conv22', param index 1
I0925 18:55:51.151811  4257 layer_factory.hpp:77] Creating layer bn42
I0925 18:55:51.151815  4257 net.cpp:100] Creating Layer bn42
I0925 18:55:51.151818  4257 net.cpp:434] bn42 <- conv42
I0925 18:55:51.151821  4257 net.cpp:395] bn42 -> conv42 (in-place)
I0925 18:55:51.151937  4257 net.cpp:150] Setting up bn42
I0925 18:55:51.151942  4257 net.cpp:157] Top shape: 32 16 18 18 (165888)
I0925 18:55:51.151944  4257 net.cpp:165] Memory required for data: 462260736
I0925 18:55:51.151948  4257 layer_factory.hpp:77] Creating layer relu42
I0925 18:55:51.151952  4257 net.cpp:100] Creating Layer relu42
I0925 18:55:51.151955  4257 net.cpp:434] relu42 <- conv42
I0925 18:55:51.151957  4257 net.cpp:395] relu42 -> conv42 (in-place)
I0925 18:55:51.152132  4257 net.cpp:150] Setting up relu42
I0925 18:55:51.152139  4257 net.cpp:157] Top shape: 32 16 18 18 (165888)
I0925 18:55:51.152142  4257 net.cpp:165] Memory required for data: 462924288
I0925 18:55:51.152143  4257 layer_factory.hpp:77] Creating layer conv43
I0925 18:55:51.152150  4257 net.cpp:100] Creating Layer conv43
I0925 18:55:51.152153  4257 net.cpp:434] conv43 <- conv42
I0925 18:55:51.152158  4257 net.cpp:408] conv43 -> conv43
I0925 18:55:51.152786  4257 net.cpp:150] Setting up conv43
I0925 18:55:51.152794  4257 net.cpp:157] Top shape: 32 16 18 18 (165888)
I0925 18:55:51.152796  4257 net.cpp:165] Memory required for data: 463587840
I0925 18:55:51.152799  4257 net.cpp:493] Sharing parameters 'conv_W3' owned by layer 'conv23', param index 0
I0925 18:55:51.152802  4257 net.cpp:493] Sharing parameters 'conv_b3' owned by layer 'conv23', param index 1
I0925 18:55:51.152804  4257 layer_factory.hpp:77] Creating layer bn43
I0925 18:55:51.152808  4257 net.cpp:100] Creating Layer bn43
I0925 18:55:51.152812  4257 net.cpp:434] bn43 <- conv43
I0925 18:55:51.152814  4257 net.cpp:395] bn43 -> conv43 (in-place)
I0925 18:55:51.152930  4257 net.cpp:150] Setting up bn43
I0925 18:55:51.152935  4257 net.cpp:157] Top shape: 32 16 18 18 (165888)
I0925 18:55:51.152936  4257 net.cpp:165] Memory required for data: 464251392
I0925 18:55:51.152940  4257 layer_factory.hpp:77] Creating layer relu4-13
I0925 18:55:51.152945  4257 net.cpp:100] Creating Layer relu4-13
I0925 18:55:51.152946  4257 net.cpp:434] relu4-13 <- conv43
I0925 18:55:51.152950  4257 net.cpp:395] relu4-13 -> conv43 (in-place)
I0925 18:55:51.153126  4257 net.cpp:150] Setting up relu4-13
I0925 18:55:51.153133  4257 net.cpp:157] Top shape: 32 16 18 18 (165888)
I0925 18:55:51.153136  4257 net.cpp:165] Memory required for data: 464914944
I0925 18:55:51.153137  4257 layer_factory.hpp:77] Creating layer deconv44
I0925 18:55:51.153142  4257 net.cpp:100] Creating Layer deconv44
I0925 18:55:51.153146  4257 net.cpp:434] deconv44 <- conv43
I0925 18:55:51.153149  4257 net.cpp:408] deconv44 -> deconv44
I0925 18:55:51.155114  4257 net.cpp:150] Setting up deconv44
I0925 18:55:51.155120  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.155122  4257 net.cpp:165] Memory required for data: 475531776
I0925 18:55:51.155130  4257 layer_factory.hpp:77] Creating layer relu44
I0925 18:55:51.155135  4257 net.cpp:100] Creating Layer relu44
I0925 18:55:51.155138  4257 net.cpp:434] relu44 <- deconv44
I0925 18:55:51.155140  4257 net.cpp:395] relu44 -> deconv44 (in-place)
I0925 18:55:51.155315  4257 net.cpp:150] Setting up relu44
I0925 18:55:51.155323  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.155325  4257 net.cpp:165] Memory required for data: 486148608
I0925 18:55:51.155328  4257 layer_factory.hpp:77] Creating layer conv45
I0925 18:55:51.155333  4257 net.cpp:100] Creating Layer conv45
I0925 18:55:51.155336  4257 net.cpp:434] conv45 <- deconv44
I0925 18:55:51.155340  4257 net.cpp:408] conv45 -> conv45
I0925 18:55:51.157778  4257 net.cpp:150] Setting up conv45
I0925 18:55:51.157786  4257 net.cpp:157] Top shape: 32 48 72 72 (7962624)
I0925 18:55:51.157788  4257 net.cpp:165] Memory required for data: 517999104
I0925 18:55:51.157791  4257 net.cpp:493] Sharing parameters 'conv_W5' owned by layer 'conv25', param index 0
I0925 18:55:51.157794  4257 net.cpp:493] Sharing parameters 'conv_b5' owned by layer 'conv25', param index 1
I0925 18:55:51.157796  4257 layer_factory.hpp:77] Creating layer slice45
I0925 18:55:51.157800  4257 net.cpp:100] Creating Layer slice45
I0925 18:55:51.157802  4257 net.cpp:434] slice45 <- conv45
I0925 18:55:51.157806  4257 net.cpp:408] slice45 -> conv45-a
I0925 18:55:51.157811  4257 net.cpp:408] slice45 -> conv45-b
I0925 18:55:51.157815  4257 net.cpp:408] slice45 -> conv45-c
I0925 18:55:51.157848  4257 net.cpp:150] Setting up slice45
I0925 18:55:51.157853  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.157855  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.157857  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.157860  4257 net.cpp:165] Memory required for data: 549849600
I0925 18:55:51.157861  4257 layer_factory.hpp:77] Creating layer maxout45
I0925 18:55:51.157865  4257 net.cpp:100] Creating Layer maxout45
I0925 18:55:51.157867  4257 net.cpp:434] maxout45 <- conv45-a
I0925 18:55:51.157869  4257 net.cpp:434] maxout45 <- conv45-b
I0925 18:55:51.157872  4257 net.cpp:434] maxout45 <- conv45-c
I0925 18:55:51.157882  4257 net.cpp:408] maxout45 -> maxout45
I0925 18:55:51.157905  4257 net.cpp:150] Setting up maxout45
I0925 18:55:51.157909  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.157912  4257 net.cpp:165] Memory required for data: 560466432
I0925 18:55:51.157913  4257 layer_factory.hpp:77] Creating layer bn45
I0925 18:55:51.157917  4257 net.cpp:100] Creating Layer bn45
I0925 18:55:51.157919  4257 net.cpp:434] bn45 <- maxout45
I0925 18:55:51.157922  4257 net.cpp:395] bn45 -> maxout45 (in-place)
I0925 18:55:51.158037  4257 net.cpp:150] Setting up bn45
I0925 18:55:51.158042  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.158043  4257 net.cpp:165] Memory required for data: 571083264
I0925 18:55:51.158048  4257 layer_factory.hpp:77] Creating layer relu45
I0925 18:55:51.158052  4257 net.cpp:100] Creating Layer relu45
I0925 18:55:51.158054  4257 net.cpp:434] relu45 <- maxout45
I0925 18:55:51.158057  4257 net.cpp:395] relu45 -> maxout45 (in-place)
I0925 18:55:51.158849  4257 net.cpp:150] Setting up relu45
I0925 18:55:51.158856  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.158859  4257 net.cpp:165] Memory required for data: 581700096
I0925 18:55:51.158860  4257 layer_factory.hpp:77] Creating layer conv46
I0925 18:55:51.158866  4257 net.cpp:100] Creating Layer conv46
I0925 18:55:51.158869  4257 net.cpp:434] conv46 <- maxout45
I0925 18:55:51.158874  4257 net.cpp:408] conv46 -> conv46
I0925 18:55:51.162490  4257 net.cpp:150] Setting up conv46
I0925 18:55:51.162500  4257 net.cpp:157] Top shape: 32 48 72 72 (7962624)
I0925 18:55:51.162503  4257 net.cpp:165] Memory required for data: 613550592
I0925 18:55:51.162505  4257 net.cpp:493] Sharing parameters 'conv_W6' owned by layer 'conv26', param index 0
I0925 18:55:51.162508  4257 net.cpp:493] Sharing parameters 'conv_b6' owned by layer 'conv26', param index 1
I0925 18:55:51.162509  4257 layer_factory.hpp:77] Creating layer slice46
I0925 18:55:51.162513  4257 net.cpp:100] Creating Layer slice46
I0925 18:55:51.162515  4257 net.cpp:434] slice46 <- conv46
I0925 18:55:51.162519  4257 net.cpp:408] slice46 -> conv46-a
I0925 18:55:51.162523  4257 net.cpp:408] slice46 -> conv46-b
I0925 18:55:51.162528  4257 net.cpp:408] slice46 -> conv46-c
I0925 18:55:51.162561  4257 net.cpp:150] Setting up slice46
I0925 18:55:51.162565  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.162567  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.162570  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.162571  4257 net.cpp:165] Memory required for data: 645401088
I0925 18:55:51.162573  4257 layer_factory.hpp:77] Creating layer maxout46
I0925 18:55:51.162580  4257 net.cpp:100] Creating Layer maxout46
I0925 18:55:51.162583  4257 net.cpp:434] maxout46 <- conv46-a
I0925 18:55:51.162587  4257 net.cpp:434] maxout46 <- conv46-b
I0925 18:55:51.162591  4257 net.cpp:434] maxout46 <- conv46-c
I0925 18:55:51.162595  4257 net.cpp:408] maxout46 -> maxout46
I0925 18:55:51.162616  4257 net.cpp:150] Setting up maxout46
I0925 18:55:51.162619  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.162621  4257 net.cpp:165] Memory required for data: 656017920
I0925 18:55:51.162624  4257 layer_factory.hpp:77] Creating layer bn46
I0925 18:55:51.162627  4257 net.cpp:100] Creating Layer bn46
I0925 18:55:51.162629  4257 net.cpp:434] bn46 <- maxout46
I0925 18:55:51.162633  4257 net.cpp:395] bn46 -> maxout46 (in-place)
I0925 18:55:51.162749  4257 net.cpp:150] Setting up bn46
I0925 18:55:51.162752  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.162755  4257 net.cpp:165] Memory required for data: 666634752
I0925 18:55:51.162760  4257 layer_factory.hpp:77] Creating layer relu46
I0925 18:55:51.162763  4257 net.cpp:100] Creating Layer relu46
I0925 18:55:51.162765  4257 net.cpp:434] relu46 <- maxout46
I0925 18:55:51.162768  4257 net.cpp:395] relu46 -> maxout46 (in-place)
I0925 18:55:51.163610  4257 net.cpp:150] Setting up relu46
I0925 18:55:51.163616  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.163624  4257 net.cpp:165] Memory required for data: 677251584
I0925 18:55:51.163625  4257 layer_factory.hpp:77] Creating layer conv47
I0925 18:55:51.163633  4257 net.cpp:100] Creating Layer conv47
I0925 18:55:51.163635  4257 net.cpp:434] conv47 <- maxout46
I0925 18:55:51.163640  4257 net.cpp:408] conv47 -> conv47
I0925 18:55:51.167179  4257 net.cpp:150] Setting up conv47
I0925 18:55:51.167189  4257 net.cpp:157] Top shape: 32 1 72 72 (165888)
I0925 18:55:51.167191  4257 net.cpp:165] Memory required for data: 677915136
I0925 18:55:51.167194  4257 net.cpp:493] Sharing parameters 'conv_W7' owned by layer 'conv27', param index 0
I0925 18:55:51.167197  4257 net.cpp:493] Sharing parameters 'conv_b7' owned by layer 'conv27', param index 1
I0925 18:55:51.167199  4257 layer_factory.hpp:77] Creating layer loss2
I0925 18:55:51.167206  4257 net.cpp:100] Creating Layer loss2
I0925 18:55:51.167209  4257 net.cpp:434] loss2 <- conv27
I0925 18:55:51.167212  4257 net.cpp:434] loss2 <- label_label_0_split_0
I0925 18:55:51.167217  4257 net.cpp:408] loss2 -> loss2
I0925 18:55:51.167246  4257 net.cpp:150] Setting up loss2
I0925 18:55:51.167251  4257 net.cpp:157] Top shape: (1)
I0925 18:55:51.167253  4257 net.cpp:160]     with loss weight 0.5
I0925 18:55:51.167265  4257 net.cpp:165] Memory required for data: 677915140
I0925 18:55:51.167268  4257 layer_factory.hpp:77] Creating layer loss3
I0925 18:55:51.167271  4257 net.cpp:100] Creating Layer loss3
I0925 18:55:51.167274  4257 net.cpp:434] loss3 <- conv37
I0925 18:55:51.167278  4257 net.cpp:434] loss3 <- label_label_0_split_1
I0925 18:55:51.167281  4257 net.cpp:408] loss3 -> loss3
I0925 18:55:51.167305  4257 net.cpp:150] Setting up loss3
I0925 18:55:51.167309  4257 net.cpp:157] Top shape: (1)
I0925 18:55:51.167311  4257 net.cpp:160]     with loss weight 0.3
I0925 18:55:51.167315  4257 net.cpp:165] Memory required for data: 677915144
I0925 18:55:51.167316  4257 layer_factory.hpp:77] Creating layer loss4
I0925 18:55:51.167320  4257 net.cpp:100] Creating Layer loss4
I0925 18:55:51.167322  4257 net.cpp:434] loss4 <- conv47
I0925 18:55:51.167325  4257 net.cpp:434] loss4 <- label_label_0_split_2
I0925 18:55:51.167328  4257 net.cpp:408] loss4 -> loss4
I0925 18:55:51.167352  4257 net.cpp:150] Setting up loss4
I0925 18:55:51.167356  4257 net.cpp:157] Top shape: (1)
I0925 18:55:51.167357  4257 net.cpp:160]     with loss weight 0.2
I0925 18:55:51.167361  4257 net.cpp:165] Memory required for data: 677915148
I0925 18:55:51.167362  4257 net.cpp:226] loss4 needs backward computation.
I0925 18:55:51.167364  4257 net.cpp:226] loss3 needs backward computation.
I0925 18:55:51.167366  4257 net.cpp:226] loss2 needs backward computation.
I0925 18:55:51.167368  4257 net.cpp:226] conv47 needs backward computation.
I0925 18:55:51.167371  4257 net.cpp:226] relu46 needs backward computation.
I0925 18:55:51.167372  4257 net.cpp:226] bn46 needs backward computation.
I0925 18:55:51.167374  4257 net.cpp:226] maxout46 needs backward computation.
I0925 18:55:51.167376  4257 net.cpp:226] slice46 needs backward computation.
I0925 18:55:51.167378  4257 net.cpp:226] conv46 needs backward computation.
I0925 18:55:51.167381  4257 net.cpp:226] relu45 needs backward computation.
I0925 18:55:51.167382  4257 net.cpp:226] bn45 needs backward computation.
I0925 18:55:51.167384  4257 net.cpp:226] maxout45 needs backward computation.
I0925 18:55:51.167387  4257 net.cpp:226] slice45 needs backward computation.
I0925 18:55:51.167388  4257 net.cpp:226] conv45 needs backward computation.
I0925 18:55:51.167390  4257 net.cpp:226] relu44 needs backward computation.
I0925 18:55:51.167392  4257 net.cpp:226] deconv44 needs backward computation.
I0925 18:55:51.167394  4257 net.cpp:226] relu4-13 needs backward computation.
I0925 18:55:51.167398  4257 net.cpp:226] bn43 needs backward computation.
I0925 18:55:51.167400  4257 net.cpp:226] conv43 needs backward computation.
I0925 18:55:51.167402  4257 net.cpp:226] relu42 needs backward computation.
I0925 18:55:51.167404  4257 net.cpp:226] bn42 needs backward computation.
I0925 18:55:51.167407  4257 net.cpp:226] conv42 needs backward computation.
I0925 18:55:51.167414  4257 net.cpp:226] relu41 needs backward computation.
I0925 18:55:51.167417  4257 net.cpp:226] conv41 needs backward computation.
I0925 18:55:51.167418  4257 net.cpp:226] conv37 needs backward computation.
I0925 18:55:51.167420  4257 net.cpp:226] relu36 needs backward computation.
I0925 18:55:51.167423  4257 net.cpp:226] bn36 needs backward computation.
I0925 18:55:51.167424  4257 net.cpp:226] maxout36 needs backward computation.
I0925 18:55:51.167426  4257 net.cpp:226] slice36 needs backward computation.
I0925 18:55:51.167428  4257 net.cpp:226] conv36 needs backward computation.
I0925 18:55:51.167430  4257 net.cpp:226] relu35 needs backward computation.
I0925 18:55:51.167433  4257 net.cpp:226] bn35 needs backward computation.
I0925 18:55:51.167434  4257 net.cpp:226] maxout35 needs backward computation.
I0925 18:55:51.167436  4257 net.cpp:226] slice35 needs backward computation.
I0925 18:55:51.167439  4257 net.cpp:226] conv35 needs backward computation.
I0925 18:55:51.167441  4257 net.cpp:226] relu34 needs backward computation.
I0925 18:55:51.167443  4257 net.cpp:226] deconv34 needs backward computation.
I0925 18:55:51.167445  4257 net.cpp:226] relu3-13 needs backward computation.
I0925 18:55:51.167448  4257 net.cpp:226] bn33 needs backward computation.
I0925 18:55:51.167449  4257 net.cpp:226] conv33 needs backward computation.
I0925 18:55:51.167451  4257 net.cpp:226] relu32 needs backward computation.
I0925 18:55:51.167454  4257 net.cpp:226] bn32 needs backward computation.
I0925 18:55:51.167456  4257 net.cpp:226] conv32 needs backward computation.
I0925 18:55:51.167459  4257 net.cpp:226] relu31 needs backward computation.
I0925 18:55:51.167460  4257 net.cpp:226] conv31 needs backward computation.
I0925 18:55:51.167464  4257 net.cpp:226] conv27 needs backward computation.
I0925 18:55:51.167465  4257 net.cpp:226] relu26 needs backward computation.
I0925 18:55:51.167469  4257 net.cpp:226] bn26 needs backward computation.
I0925 18:55:51.167470  4257 net.cpp:226] maxout26 needs backward computation.
I0925 18:55:51.167472  4257 net.cpp:226] slice26 needs backward computation.
I0925 18:55:51.167475  4257 net.cpp:226] conv26 needs backward computation.
I0925 18:55:51.167477  4257 net.cpp:226] relu25 needs backward computation.
I0925 18:55:51.167479  4257 net.cpp:226] bn25 needs backward computation.
I0925 18:55:51.167481  4257 net.cpp:226] maxout25 needs backward computation.
I0925 18:55:51.167484  4257 net.cpp:226] slice25 needs backward computation.
I0925 18:55:51.167486  4257 net.cpp:226] conv25 needs backward computation.
I0925 18:55:51.167489  4257 net.cpp:226] relu24 needs backward computation.
I0925 18:55:51.167490  4257 net.cpp:226] deconv24 needs backward computation.
I0925 18:55:51.167492  4257 net.cpp:226] relu2-13 needs backward computation.
I0925 18:55:51.167495  4257 net.cpp:226] bn23 needs backward computation.
I0925 18:55:51.167496  4257 net.cpp:226] conv23 needs backward computation.
I0925 18:55:51.167498  4257 net.cpp:226] relu22 needs backward computation.
I0925 18:55:51.167500  4257 net.cpp:226] bn22 needs backward computation.
I0925 18:55:51.167502  4257 net.cpp:226] conv22 needs backward computation.
I0925 18:55:51.167505  4257 net.cpp:226] relu21 needs backward computation.
I0925 18:55:51.167506  4257 net.cpp:226] conv21 needs backward computation.
I0925 18:55:51.167510  4257 net.cpp:228] label_label_0_split does not need backward computation.
I0925 18:55:51.167511  4257 net.cpp:228] label does not need backward computation.
I0925 18:55:51.167515  4257 net.cpp:228] low4 does not need backward computation.
I0925 18:55:51.167516  4257 net.cpp:228] low3 does not need backward computation.
I0925 18:55:51.167518  4257 net.cpp:228] low2 does not need backward computation.
I0925 18:55:51.167520  4257 net.cpp:270] This network produces output loss2
I0925 18:55:51.167522  4257 net.cpp:270] This network produces output loss3
I0925 18:55:51.167524  4257 net.cpp:270] This network produces output loss4
I0925 18:55:51.168385  4257 net.cpp:283] Network initialization done.
I0925 18:55:51.169339  4257 solver.cpp:181] Creating test net (#0) specified by net file: AESR/AESR_net.prototxt
I0925 18:55:51.169394  4257 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer low2
I0925 18:55:51.169397  4257 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer low3
I0925 18:55:51.169400  4257 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer low4
I0925 18:55:51.169401  4257 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer label
I0925 18:55:51.169631  4257 net.cpp:58] Initializing net from parameters: 
name: "AESR"
state {
  phase: TEST
}
layer {
  name: "low2"
  type: "HDF5Data"
  top: "low2"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "AESR/hdf5/ts_txt/low2.txt"
    batch_size: 32
  }
}
layer {
  name: "low3"
  type: "HDF5Data"
  top: "low3"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "AESR/hdf5/ts_txt/low3.txt"
    batch_size: 32
  }
}
layer {
  name: "low4"
  type: "HDF5Data"
  top: "low4"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "AESR/hdf5/ts_txt/low4.txt"
    batch_size: 32
  }
}
layer {
  name: "label"
  type: "HDF5Data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "AESR/hdf5/ts_txt/label.txt"
    batch_size: 32
  }
}
layer {
  name: "conv21"
  type: "Convolution"
  bottom: "low2"
  top: "conv21"
  param {
    name: "conv_W1"
    lr_mult: 0.3
  }
  param {
    name: "conv_b1"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "relu21"
  type: "ReLU"
  bottom: "conv21"
  top: "conv21"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv22"
  type: "Convolution"
  bottom: "conv21"
  top: "conv22"
  param {
    name: "conv_W2"
    lr_mult: 0.3
  }
  param {
    name: "conv_b2"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "bn22"
  type: "BatchNorm"
  bottom: "conv22"
  top: "conv22"
}
layer {
  name: "relu22"
  type: "ReLU"
  bottom: "conv22"
  top: "conv22"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv23"
  type: "Convolution"
  bottom: "conv22"
  top: "conv23"
  param {
    name: "conv_W3"
    lr_mult: 0.3
  }
  param {
    name: "conv_b3"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "bn23"
  type: "BatchNorm"
  bottom: "conv23"
  top: "conv23"
}
layer {
  name: "relu2-13"
  type: "ReLU"
  bottom: "conv23"
  top: "conv23"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "deconv24"
  type: "Deconvolution"
  bottom: "conv23"
  top: "deconv24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 6
    kernel_size: 14
    stride: 2
    weight_filler {
      type: "bilinear"
    }
    engine: CUDNN
  }
}
layer {
  name: "relu24"
  type: "ReLU"
  bottom: "deconv24"
  top: "deconv24"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv25"
  type: "Convolution"
  bottom: "deconv24"
  top: "conv25"
  param {
    name: "conv_W5"
    lr_mult: 0.3
  }
  param {
    name: "conv_b5"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "slice25"
  type: "Slice"
  bottom: "conv25"
  top: "conv25-a"
  top: "conv25-b"
  top: "conv25-c"
  slice_param {
    axis: 1
  }
}
layer {
  name: "maxout25"
  type: "Eltwise"
  bottom: "conv25-a"
  bottom: "conv25-b"
  bottom: "conv25-c"
  top: "maxout25"
  eltwise_param {
    operation: MAX
  }
}
layer {
  name: "bn25"
  type: "BatchNorm"
  bottom: "maxout25"
  top: "maxout25"
}
layer {
  name: "relu25"
  type: "ReLU"
  bottom: "maxout25"
  top: "maxout25"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv26"
  type: "Convolution"
  bottom: "maxout25"
  top: "conv26"
  param {
    name: "conv_W6"
    lr_mult: 0.3
  }
  param {
    name: "conv_b6"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "slice26"
  type: "Slice"
  bottom: "conv26"
  top: "conv26-a"
  top: "conv26-b"
  top: "conv26-c"
  slice_param {
    axis: 1
  }
}
layer {
  name: "maxout26"
  type: "Eltwise"
  bottom: "conv26-a"
  bottom: "conv26-b"
  bottom: "conv26-c"
  top: "maxout26"
  eltwise_param {
    operation: MAX
  }
}
layer {
  name: "bn26"
  type: "BatchNorm"
  bottom: "maxout26"
  top: "maxout26"
}
layer {
  name: "relu26"
  type: "ReLU"
  bottom: "maxout26"
  top: "maxout26"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv27"
  type: "Convolution"
  bottom: "maxout26"
  top: "conv27"
  param {
    name: "conv_W7"
    lr_mult: 0.3
  }
  param {
    name: "conv_b7"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 1
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "conv31"
  type: "Convolution"
  bottom: "low3"
  top: "conv31"
  param {
    name: "conv_W1"
    lr_mult: 0.3
  }
  param {
    name: "conv_b1"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "relu31"
  type: "ReLU"
  bottom: "conv31"
  top: "conv31"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv32"
  type: "Convolution"
  bottom: "conv31"
  top: "conv32"
  param {
    name: "conv_W2"
    lr_mult: 0.3
  }
  param {
    name: "conv_b2"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "bn32"
  type: "BatchNorm"
  bottom: "conv32"
  top: "conv32"
}
layer {
  name: "relu32"
  type: "ReLU"
  bottom: "conv32"
  top: "conv32"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv33"
  type: "Convolution"
  bottom: "conv32"
  top: "conv33"
  param {
    name: "conv_W3"
    lr_mult: 0.3
  }
  param {
    name: "conv_b3"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "bn33"
  type: "BatchNorm"
  bottom: "conv33"
  top: "conv33"
}
layer {
  name: "relu3-13"
  type: "ReLU"
  bottom: "conv33"
  top: "conv33"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "deconv34"
  type: "Deconvolution"
  bottom: "conv33"
  top: "deconv34"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 6
    kernel_size: 15
    stride: 3
    weight_filler {
      type: "bilinear"
    }
    engine: CUDNN
  }
}
layer {
  name: "relu34"
  type: "ReLU"
  bottom: "deconv34"
  top: "deconv34"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv35"
  type: "Convolution"
  bottom: "deconv34"
  top: "conv35"
  param {
    name: "conv_W5"
    lr_mult: 0.3
  }
  param {
    name: "conv_b5"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "slice35"
  type: "Slice"
  bottom: "conv35"
  top: "conv35-a"
  top: "conv35-b"
  top: "conv35-c"
  slice_param {
    axis: 1
  }
}
layer {
  name: "maxout35"
  type: "Eltwise"
  bottom: "conv35-a"
  bottom: "conv35-b"
  bottom: "conv35-c"
  top: "maxout35"
  eltwise_param {
    operation: MAX
  }
}
layer {
  name: "bn35"
  type: "BatchNorm"
  bottom: "maxout35"
  top: "maxout35"
}
layer {
  name: "relu35"
  type: "ReLU"
  bottom: "maxout35"
  top: "maxout35"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv36"
  type: "Convolution"
  bottom: "maxout35"
  top: "conv36"
  param {
    name: "conv_W6"
    lr_mult: 0.3
  }
  param {
    name: "conv_b6"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "slice36"
  type: "Slice"
  bottom: "conv36"
  top: "conv36-a"
  top: "conv36-b"
  top: "conv36-c"
  slice_param {
    axis: 1
  }
}
layer {
  name: "maxout36"
  type: "Eltwise"
  bottom: "conv36-a"
  bottom: "conv36-b"
  bottom: "conv36-c"
  top: "maxout36"
  eltwise_param {
    operation: MAX
  }
}
layer {
  name: "bn36"
  type: "BatchNorm"
  bottom: "maxout36"
  top: "maxout36"
}
layer {
  name: "relu36"
  type: "ReLU"
  bottom: "maxout36"
  top: "maxout36"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv37"
  type: "Convolution"
  bottom: "maxout36"
  top: "conv37"
  param {
    name: "conv_W7"
    lr_mult: 0.3
  }
  param {
    name: "conv_b7"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 1
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "conv41"
  type: "Convolution"
  bottom: "low4"
  top: "conv41"
  param {
    name: "conv_W1"
    lr_mult: 0.3
  }
  param {
    name: "conv_b1"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "relu41"
  type: "ReLU"
  bottom: "conv41"
  top: "conv41"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv42"
  type: "Convolution"
  bottom: "conv41"
  top: "conv42"
  param {
    name: "conv_W2"
    lr_mult: 0.3
  }
  param {
    name: "conv_b2"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "bn42"
  type: "BatchNorm"
  bottom: "conv42"
  top: "conv42"
}
layer {
  name: "relu42"
  type: "ReLU"
  bottom: "conv42"
  top: "conv42"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv43"
  type: "Convolution"
  bottom: "conv42"
  top: "conv43"
  param {
    name: "conv_W3"
    lr_mult: 0.3
  }
  param {
    name: "conv_b3"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "bn43"
  type: "BatchNorm"
  bottom: "conv43"
  top: "conv43"
}
layer {
  name: "relu4-13"
  type: "ReLU"
  bottom: "conv43"
  top: "conv43"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "deconv44"
  type: "Deconvolution"
  bottom: "conv43"
  top: "deconv44"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 6
    kernel_size: 16
    stride: 4
    weight_filler {
      type: "bilinear"
    }
    engine: CUDNN
  }
}
layer {
  name: "relu44"
  type: "ReLU"
  bottom: "deconv44"
  top: "deconv44"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv45"
  type: "Convolution"
  bottom: "deconv44"
  top: "conv45"
  param {
    name: "conv_W5"
    lr_mult: 0.3
  }
  param {
    name: "conv_b5"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "slice45"
  type: "Slice"
  bottom: "conv45"
  top: "conv45-a"
  top: "conv45-b"
  top: "conv45-c"
  slice_param {
    axis: 1
  }
}
layer {
  name: "maxout45"
  type: "Eltwise"
  bottom: "conv45-a"
  bottom: "conv45-b"
  bottom: "conv45-c"
  top: "maxout45"
  eltwise_param {
    operation: MAX
  }
}
layer {
  name: "bn45"
  type: "BatchNorm"
  bottom: "maxout45"
  top: "maxout45"
}
layer {
  name: "relu45"
  type: "ReLU"
  bottom: "maxout45"
  top: "maxout45"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv46"
  type: "Convolution"
  bottom: "maxout45"
  top: "conv46"
  param {
    name: "conv_W6"
    lr_mult: 0.3
  }
  param {
    name: "conv_b6"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "slice46"
  type: "Slice"
  bottom: "conv46"
  top: "conv46-a"
  top: "conv46-b"
  top: "conv46-c"
  slice_param {
    axis: 1
  }
}
layer {
  name: "maxout46"
  type: "Eltwise"
  bottom: "conv46-a"
  bottom: "conv46-b"
  bottom: "conv46-c"
  top: "maxout46"
  eltwise_param {
    operation: MAX
  }
}
layer {
  name: "bn46"
  type: "BatchNorm"
  bottom: "maxout46"
  top: "maxout46"
}
layer {
  name: "relu46"
  type: "ReLU"
  bottom: "maxout46"
  top: "maxout46"
  relu_param {
    negative_slope: 0.1
    engine: CUDNN
  }
}
layer {
  name: "conv47"
  type: "Convolution"
  bottom: "maxout46"
  top: "conv47"
  param {
    name: "conv_W7"
    lr_mult: 0.3
  }
  param {
    name: "conv_b7"
    lr_mult: 0.1
    decay_mult: 0
  }
  convolution_param {
    num_output: 1
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    engine: CUDNN
  }
}
layer {
  name: "loss2"
  type: "EuclideanLoss"
  bottom: "conv27"
  bottom: "label"
  top: "loss2"
  loss_weight: 0.5
}
layer {
  name: "loss3"
  type: "EuclideanLoss"
  bottom: "conv37"
  bottom: "label"
  top: "loss3"
  loss_weight: 0.3
}
layer {
  name: "loss4"
  type: "EuclideanLoss"
  bottom: "conv47"
  bottom: "label"
  top: "loss4"
  loss_weight: 0.2
}
I0925 18:55:51.169781  4257 layer_factory.hpp:77] Creating layer low2
I0925 18:55:51.169788  4257 net.cpp:100] Creating Layer low2
I0925 18:55:51.169791  4257 net.cpp:408] low2 -> low2
I0925 18:55:51.169796  4257 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: AESR/hdf5/ts_txt/low2.txt
I0925 18:55:51.169844  4257 hdf5_data_layer.cpp:93] Number of HDF5 files: 196
I0925 18:55:51.170225  4257 net.cpp:150] Setting up low2
I0925 18:55:51.170234  4257 net.cpp:157] Top shape: 32 1 36 36 (41472)
I0925 18:55:51.170238  4257 net.cpp:165] Memory required for data: 165888
I0925 18:55:51.170245  4257 layer_factory.hpp:77] Creating layer low3
I0925 18:55:51.170250  4257 net.cpp:100] Creating Layer low3
I0925 18:55:51.170253  4257 net.cpp:408] low3 -> low3
I0925 18:55:51.170258  4257 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: AESR/hdf5/ts_txt/low3.txt
I0925 18:55:51.170300  4257 hdf5_data_layer.cpp:93] Number of HDF5 files: 196
I0925 18:55:51.170740  4257 net.cpp:150] Setting up low3
I0925 18:55:51.170749  4257 net.cpp:157] Top shape: 32 1 24 24 (18432)
I0925 18:55:51.170753  4257 net.cpp:165] Memory required for data: 239616
I0925 18:55:51.170754  4257 layer_factory.hpp:77] Creating layer low4
I0925 18:55:51.170759  4257 net.cpp:100] Creating Layer low4
I0925 18:55:51.170761  4257 net.cpp:408] low4 -> low4
I0925 18:55:51.170768  4257 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: AESR/hdf5/ts_txt/low4.txt
I0925 18:55:51.170809  4257 hdf5_data_layer.cpp:93] Number of HDF5 files: 196
I0925 18:55:51.170999  4257 net.cpp:150] Setting up low4
I0925 18:55:51.171006  4257 net.cpp:157] Top shape: 32 1 18 18 (10368)
I0925 18:55:51.171008  4257 net.cpp:165] Memory required for data: 281088
I0925 18:55:51.171011  4257 layer_factory.hpp:77] Creating layer label
I0925 18:55:51.171015  4257 net.cpp:100] Creating Layer label
I0925 18:55:51.171017  4257 net.cpp:408] label -> label
I0925 18:55:51.171021  4257 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: AESR/hdf5/ts_txt/label.txt
I0925 18:55:51.171062  4257 hdf5_data_layer.cpp:93] Number of HDF5 files: 196
I0925 18:55:51.171646  4257 net.cpp:150] Setting up label
I0925 18:55:51.171655  4257 net.cpp:157] Top shape: 32 1 72 72 (165888)
I0925 18:55:51.171658  4257 net.cpp:165] Memory required for data: 944640
I0925 18:55:51.171660  4257 layer_factory.hpp:77] Creating layer label_label_0_split
I0925 18:55:51.171665  4257 net.cpp:100] Creating Layer label_label_0_split
I0925 18:55:51.171667  4257 net.cpp:434] label_label_0_split <- label
I0925 18:55:51.171672  4257 net.cpp:408] label_label_0_split -> label_label_0_split_0
I0925 18:55:51.171677  4257 net.cpp:408] label_label_0_split -> label_label_0_split_1
I0925 18:55:51.171682  4257 net.cpp:408] label_label_0_split -> label_label_0_split_2
I0925 18:55:51.171725  4257 net.cpp:150] Setting up label_label_0_split
I0925 18:55:51.171730  4257 net.cpp:157] Top shape: 32 1 72 72 (165888)
I0925 18:55:51.171733  4257 net.cpp:157] Top shape: 32 1 72 72 (165888)
I0925 18:55:51.171736  4257 net.cpp:157] Top shape: 32 1 72 72 (165888)
I0925 18:55:51.171738  4257 net.cpp:165] Memory required for data: 2935296
I0925 18:55:51.171741  4257 layer_factory.hpp:77] Creating layer conv21
I0925 18:55:51.171746  4257 net.cpp:100] Creating Layer conv21
I0925 18:55:51.171749  4257 net.cpp:434] conv21 <- low2
I0925 18:55:51.171753  4257 net.cpp:408] conv21 -> conv21
I0925 18:55:51.173725  4257 net.cpp:150] Setting up conv21
I0925 18:55:51.173735  4257 net.cpp:157] Top shape: 32 16 36 36 (663552)
I0925 18:55:51.173738  4257 net.cpp:165] Memory required for data: 5589504
I0925 18:55:51.173743  4257 layer_factory.hpp:77] Creating layer relu21
I0925 18:55:51.173748  4257 net.cpp:100] Creating Layer relu21
I0925 18:55:51.173751  4257 net.cpp:434] relu21 <- conv21
I0925 18:55:51.173754  4257 net.cpp:395] relu21 -> conv21 (in-place)
I0925 18:55:51.173861  4257 net.cpp:150] Setting up relu21
I0925 18:55:51.173866  4257 net.cpp:157] Top shape: 32 16 36 36 (663552)
I0925 18:55:51.173868  4257 net.cpp:165] Memory required for data: 8243712
I0925 18:55:51.173871  4257 layer_factory.hpp:77] Creating layer conv22
I0925 18:55:51.173877  4257 net.cpp:100] Creating Layer conv22
I0925 18:55:51.173879  4257 net.cpp:434] conv22 <- conv21
I0925 18:55:51.173883  4257 net.cpp:408] conv22 -> conv22
I0925 18:55:51.177431  4257 net.cpp:150] Setting up conv22
I0925 18:55:51.177440  4257 net.cpp:157] Top shape: 32 16 36 36 (663552)
I0925 18:55:51.177443  4257 net.cpp:165] Memory required for data: 10897920
I0925 18:55:51.177448  4257 layer_factory.hpp:77] Creating layer bn22
I0925 18:55:51.177453  4257 net.cpp:100] Creating Layer bn22
I0925 18:55:51.177464  4257 net.cpp:434] bn22 <- conv22
I0925 18:55:51.177466  4257 net.cpp:395] bn22 -> conv22 (in-place)
I0925 18:55:51.177588  4257 net.cpp:150] Setting up bn22
I0925 18:55:51.177593  4257 net.cpp:157] Top shape: 32 16 36 36 (663552)
I0925 18:55:51.177597  4257 net.cpp:165] Memory required for data: 13552128
I0925 18:55:51.177603  4257 layer_factory.hpp:77] Creating layer relu22
I0925 18:55:51.177606  4257 net.cpp:100] Creating Layer relu22
I0925 18:55:51.177608  4257 net.cpp:434] relu22 <- conv22
I0925 18:55:51.177611  4257 net.cpp:395] relu22 -> conv22 (in-place)
I0925 18:55:51.177925  4257 net.cpp:150] Setting up relu22
I0925 18:55:51.177933  4257 net.cpp:157] Top shape: 32 16 36 36 (663552)
I0925 18:55:51.177935  4257 net.cpp:165] Memory required for data: 16206336
I0925 18:55:51.177937  4257 layer_factory.hpp:77] Creating layer conv23
I0925 18:55:51.177943  4257 net.cpp:100] Creating Layer conv23
I0925 18:55:51.177945  4257 net.cpp:434] conv23 <- conv22
I0925 18:55:51.177949  4257 net.cpp:408] conv23 -> conv23
I0925 18:55:51.180035  4257 net.cpp:150] Setting up conv23
I0925 18:55:51.180044  4257 net.cpp:157] Top shape: 32 16 36 36 (663552)
I0925 18:55:51.180047  4257 net.cpp:165] Memory required for data: 18860544
I0925 18:55:51.180052  4257 layer_factory.hpp:77] Creating layer bn23
I0925 18:55:51.180057  4257 net.cpp:100] Creating Layer bn23
I0925 18:55:51.180058  4257 net.cpp:434] bn23 <- conv23
I0925 18:55:51.180061  4257 net.cpp:395] bn23 -> conv23 (in-place)
I0925 18:55:51.180189  4257 net.cpp:150] Setting up bn23
I0925 18:55:51.180193  4257 net.cpp:157] Top shape: 32 16 36 36 (663552)
I0925 18:55:51.180196  4257 net.cpp:165] Memory required for data: 21514752
I0925 18:55:51.180200  4257 layer_factory.hpp:77] Creating layer relu2-13
I0925 18:55:51.180204  4257 net.cpp:100] Creating Layer relu2-13
I0925 18:55:51.180207  4257 net.cpp:434] relu2-13 <- conv23
I0925 18:55:51.180209  4257 net.cpp:395] relu2-13 -> conv23 (in-place)
I0925 18:55:51.180397  4257 net.cpp:150] Setting up relu2-13
I0925 18:55:51.180404  4257 net.cpp:157] Top shape: 32 16 36 36 (663552)
I0925 18:55:51.180407  4257 net.cpp:165] Memory required for data: 24168960
I0925 18:55:51.180409  4257 layer_factory.hpp:77] Creating layer deconv24
I0925 18:55:51.180415  4257 net.cpp:100] Creating Layer deconv24
I0925 18:55:51.180418  4257 net.cpp:434] deconv24 <- conv23
I0925 18:55:51.180421  4257 net.cpp:408] deconv24 -> deconv24
I0925 18:55:51.182044  4257 net.cpp:150] Setting up deconv24
I0925 18:55:51.182049  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.182051  4257 net.cpp:165] Memory required for data: 34785792
I0925 18:55:51.182054  4257 layer_factory.hpp:77] Creating layer relu24
I0925 18:55:51.182059  4257 net.cpp:100] Creating Layer relu24
I0925 18:55:51.182061  4257 net.cpp:434] relu24 <- deconv24
I0925 18:55:51.182065  4257 net.cpp:395] relu24 -> deconv24 (in-place)
I0925 18:55:51.182174  4257 net.cpp:150] Setting up relu24
I0925 18:55:51.182180  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.182183  4257 net.cpp:165] Memory required for data: 45402624
I0925 18:55:51.182184  4257 layer_factory.hpp:77] Creating layer conv25
I0925 18:55:51.182190  4257 net.cpp:100] Creating Layer conv25
I0925 18:55:51.182193  4257 net.cpp:434] conv25 <- deconv24
I0925 18:55:51.182198  4257 net.cpp:408] conv25 -> conv25
I0925 18:55:51.185084  4257 net.cpp:150] Setting up conv25
I0925 18:55:51.185093  4257 net.cpp:157] Top shape: 32 48 72 72 (7962624)
I0925 18:55:51.185096  4257 net.cpp:165] Memory required for data: 77253120
I0925 18:55:51.185099  4257 layer_factory.hpp:77] Creating layer slice25
I0925 18:55:51.185106  4257 net.cpp:100] Creating Layer slice25
I0925 18:55:51.185107  4257 net.cpp:434] slice25 <- conv25
I0925 18:55:51.185111  4257 net.cpp:408] slice25 -> conv25-a
I0925 18:55:51.185117  4257 net.cpp:408] slice25 -> conv25-b
I0925 18:55:51.185122  4257 net.cpp:408] slice25 -> conv25-c
I0925 18:55:51.185156  4257 net.cpp:150] Setting up slice25
I0925 18:55:51.185161  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.185169  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.185173  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.185173  4257 net.cpp:165] Memory required for data: 109103616
I0925 18:55:51.185176  4257 layer_factory.hpp:77] Creating layer maxout25
I0925 18:55:51.185180  4257 net.cpp:100] Creating Layer maxout25
I0925 18:55:51.185184  4257 net.cpp:434] maxout25 <- conv25-a
I0925 18:55:51.185185  4257 net.cpp:434] maxout25 <- conv25-b
I0925 18:55:51.185189  4257 net.cpp:434] maxout25 <- conv25-c
I0925 18:55:51.185192  4257 net.cpp:408] maxout25 -> maxout25
I0925 18:55:51.185217  4257 net.cpp:150] Setting up maxout25
I0925 18:55:51.185221  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.185223  4257 net.cpp:165] Memory required for data: 119720448
I0925 18:55:51.185225  4257 layer_factory.hpp:77] Creating layer bn25
I0925 18:55:51.185230  4257 net.cpp:100] Creating Layer bn25
I0925 18:55:51.185231  4257 net.cpp:434] bn25 <- maxout25
I0925 18:55:51.185235  4257 net.cpp:395] bn25 -> maxout25 (in-place)
I0925 18:55:51.185358  4257 net.cpp:150] Setting up bn25
I0925 18:55:51.185361  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.185364  4257 net.cpp:165] Memory required for data: 130337280
I0925 18:55:51.185371  4257 layer_factory.hpp:77] Creating layer relu25
I0925 18:55:51.185374  4257 net.cpp:100] Creating Layer relu25
I0925 18:55:51.185377  4257 net.cpp:434] relu25 <- maxout25
I0925 18:55:51.185380  4257 net.cpp:395] relu25 -> maxout25 (in-place)
I0925 18:55:51.186156  4257 net.cpp:150] Setting up relu25
I0925 18:55:51.186164  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.186167  4257 net.cpp:165] Memory required for data: 140954112
I0925 18:55:51.186168  4257 layer_factory.hpp:77] Creating layer conv26
I0925 18:55:51.186174  4257 net.cpp:100] Creating Layer conv26
I0925 18:55:51.186177  4257 net.cpp:434] conv26 <- maxout25
I0925 18:55:51.186182  4257 net.cpp:408] conv26 -> conv26
I0925 18:55:51.189653  4257 net.cpp:150] Setting up conv26
I0925 18:55:51.189663  4257 net.cpp:157] Top shape: 32 48 72 72 (7962624)
I0925 18:55:51.189666  4257 net.cpp:165] Memory required for data: 172804608
I0925 18:55:51.189669  4257 layer_factory.hpp:77] Creating layer slice26
I0925 18:55:51.189673  4257 net.cpp:100] Creating Layer slice26
I0925 18:55:51.189676  4257 net.cpp:434] slice26 <- conv26
I0925 18:55:51.189679  4257 net.cpp:408] slice26 -> conv26-a
I0925 18:55:51.189685  4257 net.cpp:408] slice26 -> conv26-b
I0925 18:55:51.189690  4257 net.cpp:408] slice26 -> conv26-c
I0925 18:55:51.189723  4257 net.cpp:150] Setting up slice26
I0925 18:55:51.189728  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.189730  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.189733  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.189734  4257 net.cpp:165] Memory required for data: 204655104
I0925 18:55:51.189736  4257 layer_factory.hpp:77] Creating layer maxout26
I0925 18:55:51.189740  4257 net.cpp:100] Creating Layer maxout26
I0925 18:55:51.189743  4257 net.cpp:434] maxout26 <- conv26-a
I0925 18:55:51.189744  4257 net.cpp:434] maxout26 <- conv26-b
I0925 18:55:51.189748  4257 net.cpp:434] maxout26 <- conv26-c
I0925 18:55:51.189749  4257 net.cpp:408] maxout26 -> maxout26
I0925 18:55:51.189772  4257 net.cpp:150] Setting up maxout26
I0925 18:55:51.189776  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.189777  4257 net.cpp:165] Memory required for data: 215271936
I0925 18:55:51.189780  4257 layer_factory.hpp:77] Creating layer bn26
I0925 18:55:51.189784  4257 net.cpp:100] Creating Layer bn26
I0925 18:55:51.189785  4257 net.cpp:434] bn26 <- maxout26
I0925 18:55:51.189788  4257 net.cpp:395] bn26 -> maxout26 (in-place)
I0925 18:55:51.189913  4257 net.cpp:150] Setting up bn26
I0925 18:55:51.189918  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.189919  4257 net.cpp:165] Memory required for data: 225888768
I0925 18:55:51.189924  4257 layer_factory.hpp:77] Creating layer relu26
I0925 18:55:51.189934  4257 net.cpp:100] Creating Layer relu26
I0925 18:55:51.189936  4257 net.cpp:434] relu26 <- maxout26
I0925 18:55:51.189939  4257 net.cpp:395] relu26 -> maxout26 (in-place)
I0925 18:55:51.190754  4257 net.cpp:150] Setting up relu26
I0925 18:55:51.190760  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.190762  4257 net.cpp:165] Memory required for data: 236505600
I0925 18:55:51.190764  4257 layer_factory.hpp:77] Creating layer conv27
I0925 18:55:51.190770  4257 net.cpp:100] Creating Layer conv27
I0925 18:55:51.190773  4257 net.cpp:434] conv27 <- maxout26
I0925 18:55:51.190778  4257 net.cpp:408] conv27 -> conv27
I0925 18:55:51.194075  4257 net.cpp:150] Setting up conv27
I0925 18:55:51.194085  4257 net.cpp:157] Top shape: 32 1 72 72 (165888)
I0925 18:55:51.194087  4257 net.cpp:165] Memory required for data: 237169152
I0925 18:55:51.194092  4257 layer_factory.hpp:77] Creating layer conv31
I0925 18:55:51.194098  4257 net.cpp:100] Creating Layer conv31
I0925 18:55:51.194100  4257 net.cpp:434] conv31 <- low3
I0925 18:55:51.194105  4257 net.cpp:408] conv31 -> conv31
I0925 18:55:51.196930  4257 net.cpp:150] Setting up conv31
I0925 18:55:51.196939  4257 net.cpp:157] Top shape: 32 16 24 24 (294912)
I0925 18:55:51.196943  4257 net.cpp:165] Memory required for data: 238348800
I0925 18:55:51.196944  4257 net.cpp:493] Sharing parameters 'conv_W1' owned by layer 'conv21', param index 0
I0925 18:55:51.196948  4257 net.cpp:493] Sharing parameters 'conv_b1' owned by layer 'conv21', param index 1
I0925 18:55:51.196949  4257 layer_factory.hpp:77] Creating layer relu31
I0925 18:55:51.196954  4257 net.cpp:100] Creating Layer relu31
I0925 18:55:51.196955  4257 net.cpp:434] relu31 <- conv31
I0925 18:55:51.196959  4257 net.cpp:395] relu31 -> conv31 (in-place)
I0925 18:55:51.198004  4257 net.cpp:150] Setting up relu31
I0925 18:55:51.198010  4257 net.cpp:157] Top shape: 32 16 24 24 (294912)
I0925 18:55:51.198012  4257 net.cpp:165] Memory required for data: 239528448
I0925 18:55:51.198014  4257 layer_factory.hpp:77] Creating layer conv32
I0925 18:55:51.198020  4257 net.cpp:100] Creating Layer conv32
I0925 18:55:51.198024  4257 net.cpp:434] conv32 <- conv31
I0925 18:55:51.198027  4257 net.cpp:408] conv32 -> conv32
I0925 18:55:51.199141  4257 net.cpp:150] Setting up conv32
I0925 18:55:51.199149  4257 net.cpp:157] Top shape: 32 16 24 24 (294912)
I0925 18:55:51.199151  4257 net.cpp:165] Memory required for data: 240708096
I0925 18:55:51.199154  4257 net.cpp:493] Sharing parameters 'conv_W2' owned by layer 'conv22', param index 0
I0925 18:55:51.199157  4257 net.cpp:493] Sharing parameters 'conv_b2' owned by layer 'conv22', param index 1
I0925 18:55:51.199159  4257 layer_factory.hpp:77] Creating layer bn32
I0925 18:55:51.199164  4257 net.cpp:100] Creating Layer bn32
I0925 18:55:51.199167  4257 net.cpp:434] bn32 <- conv32
I0925 18:55:51.199169  4257 net.cpp:395] bn32 -> conv32 (in-place)
I0925 18:55:51.199300  4257 net.cpp:150] Setting up bn32
I0925 18:55:51.199306  4257 net.cpp:157] Top shape: 32 16 24 24 (294912)
I0925 18:55:51.199307  4257 net.cpp:165] Memory required for data: 241887744
I0925 18:55:51.199314  4257 layer_factory.hpp:77] Creating layer relu32
I0925 18:55:51.199318  4257 net.cpp:100] Creating Layer relu32
I0925 18:55:51.199321  4257 net.cpp:434] relu32 <- conv32
I0925 18:55:51.199323  4257 net.cpp:395] relu32 -> conv32 (in-place)
I0925 18:55:51.200201  4257 net.cpp:150] Setting up relu32
I0925 18:55:51.200209  4257 net.cpp:157] Top shape: 32 16 24 24 (294912)
I0925 18:55:51.200212  4257 net.cpp:165] Memory required for data: 243067392
I0925 18:55:51.200213  4257 layer_factory.hpp:77] Creating layer conv33
I0925 18:55:51.200220  4257 net.cpp:100] Creating Layer conv33
I0925 18:55:51.200222  4257 net.cpp:434] conv33 <- conv32
I0925 18:55:51.200227  4257 net.cpp:408] conv33 -> conv33
I0925 18:55:51.203685  4257 net.cpp:150] Setting up conv33
I0925 18:55:51.203693  4257 net.cpp:157] Top shape: 32 16 24 24 (294912)
I0925 18:55:51.203696  4257 net.cpp:165] Memory required for data: 244247040
I0925 18:55:51.203704  4257 net.cpp:493] Sharing parameters 'conv_W3' owned by layer 'conv23', param index 0
I0925 18:55:51.203707  4257 net.cpp:493] Sharing parameters 'conv_b3' owned by layer 'conv23', param index 1
I0925 18:55:51.203709  4257 layer_factory.hpp:77] Creating layer bn33
I0925 18:55:51.203716  4257 net.cpp:100] Creating Layer bn33
I0925 18:55:51.203718  4257 net.cpp:434] bn33 <- conv33
I0925 18:55:51.203722  4257 net.cpp:395] bn33 -> conv33 (in-place)
I0925 18:55:51.203852  4257 net.cpp:150] Setting up bn33
I0925 18:55:51.203857  4257 net.cpp:157] Top shape: 32 16 24 24 (294912)
I0925 18:55:51.203860  4257 net.cpp:165] Memory required for data: 245426688
I0925 18:55:51.203865  4257 layer_factory.hpp:77] Creating layer relu3-13
I0925 18:55:51.203868  4257 net.cpp:100] Creating Layer relu3-13
I0925 18:55:51.203871  4257 net.cpp:434] relu3-13 <- conv33
I0925 18:55:51.203873  4257 net.cpp:395] relu3-13 -> conv33 (in-place)
I0925 18:55:51.204798  4257 net.cpp:150] Setting up relu3-13
I0925 18:55:51.204807  4257 net.cpp:157] Top shape: 32 16 24 24 (294912)
I0925 18:55:51.204808  4257 net.cpp:165] Memory required for data: 246606336
I0925 18:55:51.204810  4257 layer_factory.hpp:77] Creating layer deconv34
I0925 18:55:51.204818  4257 net.cpp:100] Creating Layer deconv34
I0925 18:55:51.204820  4257 net.cpp:434] deconv34 <- conv33
I0925 18:55:51.204823  4257 net.cpp:408] deconv34 -> deconv34
I0925 18:55:51.206584  4257 net.cpp:150] Setting up deconv34
I0925 18:55:51.206590  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.206593  4257 net.cpp:165] Memory required for data: 257223168
I0925 18:55:51.206598  4257 layer_factory.hpp:77] Creating layer relu34
I0925 18:55:51.206601  4257 net.cpp:100] Creating Layer relu34
I0925 18:55:51.206604  4257 net.cpp:434] relu34 <- deconv34
I0925 18:55:51.206606  4257 net.cpp:395] relu34 -> deconv34 (in-place)
I0925 18:55:51.206714  4257 net.cpp:150] Setting up relu34
I0925 18:55:51.206720  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.206722  4257 net.cpp:165] Memory required for data: 267840000
I0925 18:55:51.206725  4257 layer_factory.hpp:77] Creating layer conv35
I0925 18:55:51.206732  4257 net.cpp:100] Creating Layer conv35
I0925 18:55:51.206733  4257 net.cpp:434] conv35 <- deconv34
I0925 18:55:51.206738  4257 net.cpp:408] conv35 -> conv35
I0925 18:55:51.209419  4257 net.cpp:150] Setting up conv35
I0925 18:55:51.209429  4257 net.cpp:157] Top shape: 32 48 72 72 (7962624)
I0925 18:55:51.209430  4257 net.cpp:165] Memory required for data: 299690496
I0925 18:55:51.209434  4257 net.cpp:493] Sharing parameters 'conv_W5' owned by layer 'conv25', param index 0
I0925 18:55:51.209436  4257 net.cpp:493] Sharing parameters 'conv_b5' owned by layer 'conv25', param index 1
I0925 18:55:51.209439  4257 layer_factory.hpp:77] Creating layer slice35
I0925 18:55:51.209442  4257 net.cpp:100] Creating Layer slice35
I0925 18:55:51.209445  4257 net.cpp:434] slice35 <- conv35
I0925 18:55:51.209448  4257 net.cpp:408] slice35 -> conv35-a
I0925 18:55:51.209452  4257 net.cpp:408] slice35 -> conv35-b
I0925 18:55:51.209457  4257 net.cpp:408] slice35 -> conv35-c
I0925 18:55:51.209494  4257 net.cpp:150] Setting up slice35
I0925 18:55:51.209499  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.209501  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.209503  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.209506  4257 net.cpp:165] Memory required for data: 331540992
I0925 18:55:51.209508  4257 layer_factory.hpp:77] Creating layer maxout35
I0925 18:55:51.209512  4257 net.cpp:100] Creating Layer maxout35
I0925 18:55:51.209514  4257 net.cpp:434] maxout35 <- conv35-a
I0925 18:55:51.209517  4257 net.cpp:434] maxout35 <- conv35-b
I0925 18:55:51.209519  4257 net.cpp:434] maxout35 <- conv35-c
I0925 18:55:51.209522  4257 net.cpp:408] maxout35 -> maxout35
I0925 18:55:51.209547  4257 net.cpp:150] Setting up maxout35
I0925 18:55:51.209552  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.209558  4257 net.cpp:165] Memory required for data: 342157824
I0925 18:55:51.209560  4257 layer_factory.hpp:77] Creating layer bn35
I0925 18:55:51.209563  4257 net.cpp:100] Creating Layer bn35
I0925 18:55:51.209565  4257 net.cpp:434] bn35 <- maxout35
I0925 18:55:51.209569  4257 net.cpp:395] bn35 -> maxout35 (in-place)
I0925 18:55:51.209699  4257 net.cpp:150] Setting up bn35
I0925 18:55:51.209704  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.209707  4257 net.cpp:165] Memory required for data: 352774656
I0925 18:55:51.209710  4257 layer_factory.hpp:77] Creating layer relu35
I0925 18:55:51.209714  4257 net.cpp:100] Creating Layer relu35
I0925 18:55:51.209717  4257 net.cpp:434] relu35 <- maxout35
I0925 18:55:51.209719  4257 net.cpp:395] relu35 -> maxout35 (in-place)
I0925 18:55:51.211138  4257 net.cpp:150] Setting up relu35
I0925 18:55:51.211145  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.211148  4257 net.cpp:165] Memory required for data: 363391488
I0925 18:55:51.211150  4257 layer_factory.hpp:77] Creating layer conv36
I0925 18:55:51.211158  4257 net.cpp:100] Creating Layer conv36
I0925 18:55:51.211160  4257 net.cpp:434] conv36 <- maxout35
I0925 18:55:51.211165  4257 net.cpp:408] conv36 -> conv36
I0925 18:55:51.214556  4257 net.cpp:150] Setting up conv36
I0925 18:55:51.214565  4257 net.cpp:157] Top shape: 32 48 72 72 (7962624)
I0925 18:55:51.214567  4257 net.cpp:165] Memory required for data: 395241984
I0925 18:55:51.214570  4257 net.cpp:493] Sharing parameters 'conv_W6' owned by layer 'conv26', param index 0
I0925 18:55:51.214572  4257 net.cpp:493] Sharing parameters 'conv_b6' owned by layer 'conv26', param index 1
I0925 18:55:51.214576  4257 layer_factory.hpp:77] Creating layer slice36
I0925 18:55:51.214578  4257 net.cpp:100] Creating Layer slice36
I0925 18:55:51.214581  4257 net.cpp:434] slice36 <- conv36
I0925 18:55:51.214586  4257 net.cpp:408] slice36 -> conv36-a
I0925 18:55:51.214591  4257 net.cpp:408] slice36 -> conv36-b
I0925 18:55:51.214596  4257 net.cpp:408] slice36 -> conv36-c
I0925 18:55:51.214633  4257 net.cpp:150] Setting up slice36
I0925 18:55:51.214637  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.214639  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.214643  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.214643  4257 net.cpp:165] Memory required for data: 427092480
I0925 18:55:51.214645  4257 layer_factory.hpp:77] Creating layer maxout36
I0925 18:55:51.214650  4257 net.cpp:100] Creating Layer maxout36
I0925 18:55:51.214653  4257 net.cpp:434] maxout36 <- conv36-a
I0925 18:55:51.214654  4257 net.cpp:434] maxout36 <- conv36-b
I0925 18:55:51.214658  4257 net.cpp:434] maxout36 <- conv36-c
I0925 18:55:51.214661  4257 net.cpp:408] maxout36 -> maxout36
I0925 18:55:51.214686  4257 net.cpp:150] Setting up maxout36
I0925 18:55:51.214690  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.214691  4257 net.cpp:165] Memory required for data: 437709312
I0925 18:55:51.214694  4257 layer_factory.hpp:77] Creating layer bn36
I0925 18:55:51.214696  4257 net.cpp:100] Creating Layer bn36
I0925 18:55:51.214699  4257 net.cpp:434] bn36 <- maxout36
I0925 18:55:51.214702  4257 net.cpp:395] bn36 -> maxout36 (in-place)
I0925 18:55:51.214830  4257 net.cpp:150] Setting up bn36
I0925 18:55:51.214834  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.214836  4257 net.cpp:165] Memory required for data: 448326144
I0925 18:55:51.214841  4257 layer_factory.hpp:77] Creating layer relu36
I0925 18:55:51.214844  4257 net.cpp:100] Creating Layer relu36
I0925 18:55:51.214848  4257 net.cpp:434] relu36 <- maxout36
I0925 18:55:51.214850  4257 net.cpp:395] relu36 -> maxout36 (in-place)
I0925 18:55:51.214977  4257 net.cpp:150] Setting up relu36
I0925 18:55:51.214982  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.214984  4257 net.cpp:165] Memory required for data: 458942976
I0925 18:55:51.214987  4257 layer_factory.hpp:77] Creating layer conv37
I0925 18:55:51.214993  4257 net.cpp:100] Creating Layer conv37
I0925 18:55:51.215000  4257 net.cpp:434] conv37 <- maxout36
I0925 18:55:51.215005  4257 net.cpp:408] conv37 -> conv37
I0925 18:55:51.217582  4257 net.cpp:150] Setting up conv37
I0925 18:55:51.217592  4257 net.cpp:157] Top shape: 32 1 72 72 (165888)
I0925 18:55:51.217593  4257 net.cpp:165] Memory required for data: 459606528
I0925 18:55:51.217597  4257 net.cpp:493] Sharing parameters 'conv_W7' owned by layer 'conv27', param index 0
I0925 18:55:51.217599  4257 net.cpp:493] Sharing parameters 'conv_b7' owned by layer 'conv27', param index 1
I0925 18:55:51.217602  4257 layer_factory.hpp:77] Creating layer conv41
I0925 18:55:51.217608  4257 net.cpp:100] Creating Layer conv41
I0925 18:55:51.217610  4257 net.cpp:434] conv41 <- low4
I0925 18:55:51.217615  4257 net.cpp:408] conv41 -> conv41
I0925 18:55:51.221349  4257 net.cpp:150] Setting up conv41
I0925 18:55:51.221359  4257 net.cpp:157] Top shape: 32 16 18 18 (165888)
I0925 18:55:51.221360  4257 net.cpp:165] Memory required for data: 460270080
I0925 18:55:51.221364  4257 net.cpp:493] Sharing parameters 'conv_W1' owned by layer 'conv21', param index 0
I0925 18:55:51.221366  4257 net.cpp:493] Sharing parameters 'conv_b1' owned by layer 'conv21', param index 1
I0925 18:55:51.221369  4257 layer_factory.hpp:77] Creating layer relu41
I0925 18:55:51.221372  4257 net.cpp:100] Creating Layer relu41
I0925 18:55:51.221374  4257 net.cpp:434] relu41 <- conv41
I0925 18:55:51.221379  4257 net.cpp:395] relu41 -> conv41 (in-place)
I0925 18:55:51.222401  4257 net.cpp:150] Setting up relu41
I0925 18:55:51.222407  4257 net.cpp:157] Top shape: 32 16 18 18 (165888)
I0925 18:55:51.222409  4257 net.cpp:165] Memory required for data: 460933632
I0925 18:55:51.222411  4257 layer_factory.hpp:77] Creating layer conv42
I0925 18:55:51.222417  4257 net.cpp:100] Creating Layer conv42
I0925 18:55:51.222420  4257 net.cpp:434] conv42 <- conv41
I0925 18:55:51.222424  4257 net.cpp:408] conv42 -> conv42
I0925 18:55:51.225927  4257 net.cpp:150] Setting up conv42
I0925 18:55:51.225936  4257 net.cpp:157] Top shape: 32 16 18 18 (165888)
I0925 18:55:51.225939  4257 net.cpp:165] Memory required for data: 461597184
I0925 18:55:51.225941  4257 net.cpp:493] Sharing parameters 'conv_W2' owned by layer 'conv22', param index 0
I0925 18:55:51.225944  4257 net.cpp:493] Sharing parameters 'conv_b2' owned by layer 'conv22', param index 1
I0925 18:55:51.225945  4257 layer_factory.hpp:77] Creating layer bn42
I0925 18:55:51.225950  4257 net.cpp:100] Creating Layer bn42
I0925 18:55:51.225952  4257 net.cpp:434] bn42 <- conv42
I0925 18:55:51.225956  4257 net.cpp:395] bn42 -> conv42 (in-place)
I0925 18:55:51.226091  4257 net.cpp:150] Setting up bn42
I0925 18:55:51.226096  4257 net.cpp:157] Top shape: 32 16 18 18 (165888)
I0925 18:55:51.226099  4257 net.cpp:165] Memory required for data: 462260736
I0925 18:55:51.226102  4257 layer_factory.hpp:77] Creating layer relu42
I0925 18:55:51.226106  4257 net.cpp:100] Creating Layer relu42
I0925 18:55:51.226109  4257 net.cpp:434] relu42 <- conv42
I0925 18:55:51.226111  4257 net.cpp:395] relu42 -> conv42 (in-place)
I0925 18:55:51.227234  4257 net.cpp:150] Setting up relu42
I0925 18:55:51.227242  4257 net.cpp:157] Top shape: 32 16 18 18 (165888)
I0925 18:55:51.227244  4257 net.cpp:165] Memory required for data: 462924288
I0925 18:55:51.227247  4257 layer_factory.hpp:77] Creating layer conv43
I0925 18:55:51.227253  4257 net.cpp:100] Creating Layer conv43
I0925 18:55:51.227257  4257 net.cpp:434] conv43 <- conv42
I0925 18:55:51.227260  4257 net.cpp:408] conv43 -> conv43
I0925 18:55:51.230769  4257 net.cpp:150] Setting up conv43
I0925 18:55:51.230778  4257 net.cpp:157] Top shape: 32 16 18 18 (165888)
I0925 18:55:51.230780  4257 net.cpp:165] Memory required for data: 463587840
I0925 18:55:51.230783  4257 net.cpp:493] Sharing parameters 'conv_W3' owned by layer 'conv23', param index 0
I0925 18:55:51.230787  4257 net.cpp:493] Sharing parameters 'conv_b3' owned by layer 'conv23', param index 1
I0925 18:55:51.230788  4257 layer_factory.hpp:77] Creating layer bn43
I0925 18:55:51.230793  4257 net.cpp:100] Creating Layer bn43
I0925 18:55:51.230801  4257 net.cpp:434] bn43 <- conv43
I0925 18:55:51.230805  4257 net.cpp:395] bn43 -> conv43 (in-place)
I0925 18:55:51.230939  4257 net.cpp:150] Setting up bn43
I0925 18:55:51.230944  4257 net.cpp:157] Top shape: 32 16 18 18 (165888)
I0925 18:55:51.230947  4257 net.cpp:165] Memory required for data: 464251392
I0925 18:55:51.230950  4257 layer_factory.hpp:77] Creating layer relu4-13
I0925 18:55:51.230954  4257 net.cpp:100] Creating Layer relu4-13
I0925 18:55:51.230957  4257 net.cpp:434] relu4-13 <- conv43
I0925 18:55:51.230959  4257 net.cpp:395] relu4-13 -> conv43 (in-place)
I0925 18:55:51.231952  4257 net.cpp:150] Setting up relu4-13
I0925 18:55:51.231961  4257 net.cpp:157] Top shape: 32 16 18 18 (165888)
I0925 18:55:51.231962  4257 net.cpp:165] Memory required for data: 464914944
I0925 18:55:51.231964  4257 layer_factory.hpp:77] Creating layer deconv44
I0925 18:55:51.231969  4257 net.cpp:100] Creating Layer deconv44
I0925 18:55:51.231972  4257 net.cpp:434] deconv44 <- conv43
I0925 18:55:51.231976  4257 net.cpp:408] deconv44 -> deconv44
I0925 18:55:51.233970  4257 net.cpp:150] Setting up deconv44
I0925 18:55:51.233976  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.233978  4257 net.cpp:165] Memory required for data: 475531776
I0925 18:55:51.233988  4257 layer_factory.hpp:77] Creating layer relu44
I0925 18:55:51.233991  4257 net.cpp:100] Creating Layer relu44
I0925 18:55:51.233994  4257 net.cpp:434] relu44 <- deconv44
I0925 18:55:51.233997  4257 net.cpp:395] relu44 -> deconv44 (in-place)
I0925 18:55:51.234107  4257 net.cpp:150] Setting up relu44
I0925 18:55:51.234113  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.234115  4257 net.cpp:165] Memory required for data: 486148608
I0925 18:55:51.234117  4257 layer_factory.hpp:77] Creating layer conv45
I0925 18:55:51.234124  4257 net.cpp:100] Creating Layer conv45
I0925 18:55:51.234127  4257 net.cpp:434] conv45 <- deconv44
I0925 18:55:51.234132  4257 net.cpp:408] conv45 -> conv45
I0925 18:55:51.237011  4257 net.cpp:150] Setting up conv45
I0925 18:55:51.237020  4257 net.cpp:157] Top shape: 32 48 72 72 (7962624)
I0925 18:55:51.237022  4257 net.cpp:165] Memory required for data: 517999104
I0925 18:55:51.237025  4257 net.cpp:493] Sharing parameters 'conv_W5' owned by layer 'conv25', param index 0
I0925 18:55:51.237028  4257 net.cpp:493] Sharing parameters 'conv_b5' owned by layer 'conv25', param index 1
I0925 18:55:51.237030  4257 layer_factory.hpp:77] Creating layer slice45
I0925 18:55:51.237035  4257 net.cpp:100] Creating Layer slice45
I0925 18:55:51.237037  4257 net.cpp:434] slice45 <- conv45
I0925 18:55:51.237040  4257 net.cpp:408] slice45 -> conv45-a
I0925 18:55:51.237046  4257 net.cpp:408] slice45 -> conv45-b
I0925 18:55:51.237051  4257 net.cpp:408] slice45 -> conv45-c
I0925 18:55:51.237088  4257 net.cpp:150] Setting up slice45
I0925 18:55:51.237093  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.237095  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.237097  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.237099  4257 net.cpp:165] Memory required for data: 549849600
I0925 18:55:51.237102  4257 layer_factory.hpp:77] Creating layer maxout45
I0925 18:55:51.237105  4257 net.cpp:100] Creating Layer maxout45
I0925 18:55:51.237107  4257 net.cpp:434] maxout45 <- conv45-a
I0925 18:55:51.237110  4257 net.cpp:434] maxout45 <- conv45-b
I0925 18:55:51.237112  4257 net.cpp:434] maxout45 <- conv45-c
I0925 18:55:51.237115  4257 net.cpp:408] maxout45 -> maxout45
I0925 18:55:51.237143  4257 net.cpp:150] Setting up maxout45
I0925 18:55:51.237146  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.237148  4257 net.cpp:165] Memory required for data: 560466432
I0925 18:55:51.237149  4257 layer_factory.hpp:77] Creating layer bn45
I0925 18:55:51.237152  4257 net.cpp:100] Creating Layer bn45
I0925 18:55:51.237155  4257 net.cpp:434] bn45 <- maxout45
I0925 18:55:51.237159  4257 net.cpp:395] bn45 -> maxout45 (in-place)
I0925 18:55:51.237290  4257 net.cpp:150] Setting up bn45
I0925 18:55:51.237300  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.237303  4257 net.cpp:165] Memory required for data: 571083264
I0925 18:55:51.237308  4257 layer_factory.hpp:77] Creating layer relu45
I0925 18:55:51.237311  4257 net.cpp:100] Creating Layer relu45
I0925 18:55:51.237313  4257 net.cpp:434] relu45 <- maxout45
I0925 18:55:51.237316  4257 net.cpp:395] relu45 -> maxout45 (in-place)
I0925 18:55:51.238116  4257 net.cpp:150] Setting up relu45
I0925 18:55:51.238122  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.238126  4257 net.cpp:165] Memory required for data: 581700096
I0925 18:55:51.238127  4257 layer_factory.hpp:77] Creating layer conv46
I0925 18:55:51.238134  4257 net.cpp:100] Creating Layer conv46
I0925 18:55:51.238137  4257 net.cpp:434] conv46 <- maxout45
I0925 18:55:51.238142  4257 net.cpp:408] conv46 -> conv46
I0925 18:55:51.241736  4257 net.cpp:150] Setting up conv46
I0925 18:55:51.241745  4257 net.cpp:157] Top shape: 32 48 72 72 (7962624)
I0925 18:55:51.241747  4257 net.cpp:165] Memory required for data: 613550592
I0925 18:55:51.241750  4257 net.cpp:493] Sharing parameters 'conv_W6' owned by layer 'conv26', param index 0
I0925 18:55:51.241753  4257 net.cpp:493] Sharing parameters 'conv_b6' owned by layer 'conv26', param index 1
I0925 18:55:51.241755  4257 layer_factory.hpp:77] Creating layer slice46
I0925 18:55:51.241760  4257 net.cpp:100] Creating Layer slice46
I0925 18:55:51.241762  4257 net.cpp:434] slice46 <- conv46
I0925 18:55:51.241765  4257 net.cpp:408] slice46 -> conv46-a
I0925 18:55:51.241770  4257 net.cpp:408] slice46 -> conv46-b
I0925 18:55:51.241775  4257 net.cpp:408] slice46 -> conv46-c
I0925 18:55:51.241812  4257 net.cpp:150] Setting up slice46
I0925 18:55:51.241816  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.241819  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.241822  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.241823  4257 net.cpp:165] Memory required for data: 645401088
I0925 18:55:51.241825  4257 layer_factory.hpp:77] Creating layer maxout46
I0925 18:55:51.241832  4257 net.cpp:100] Creating Layer maxout46
I0925 18:55:51.241834  4257 net.cpp:434] maxout46 <- conv46-a
I0925 18:55:51.241839  4257 net.cpp:434] maxout46 <- conv46-b
I0925 18:55:51.241842  4257 net.cpp:434] maxout46 <- conv46-c
I0925 18:55:51.241847  4257 net.cpp:408] maxout46 -> maxout46
I0925 18:55:51.241871  4257 net.cpp:150] Setting up maxout46
I0925 18:55:51.241875  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.241878  4257 net.cpp:165] Memory required for data: 656017920
I0925 18:55:51.241879  4257 layer_factory.hpp:77] Creating layer bn46
I0925 18:55:51.241883  4257 net.cpp:100] Creating Layer bn46
I0925 18:55:51.241885  4257 net.cpp:434] bn46 <- maxout46
I0925 18:55:51.241888  4257 net.cpp:395] bn46 -> maxout46 (in-place)
I0925 18:55:51.242024  4257 net.cpp:150] Setting up bn46
I0925 18:55:51.242029  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.242032  4257 net.cpp:165] Memory required for data: 666634752
I0925 18:55:51.242036  4257 layer_factory.hpp:77] Creating layer relu46
I0925 18:55:51.242040  4257 net.cpp:100] Creating Layer relu46
I0925 18:55:51.242043  4257 net.cpp:434] relu46 <- maxout46
I0925 18:55:51.242045  4257 net.cpp:395] relu46 -> maxout46 (in-place)
I0925 18:55:51.242853  4257 net.cpp:150] Setting up relu46
I0925 18:55:51.242859  4257 net.cpp:157] Top shape: 32 16 72 72 (2654208)
I0925 18:55:51.242861  4257 net.cpp:165] Memory required for data: 677251584
I0925 18:55:51.242863  4257 layer_factory.hpp:77] Creating layer conv47
I0925 18:55:51.242871  4257 net.cpp:100] Creating Layer conv47
I0925 18:55:51.242872  4257 net.cpp:434] conv47 <- maxout46
I0925 18:55:51.242877  4257 net.cpp:408] conv47 -> conv47
I0925 18:55:51.246414  4257 net.cpp:150] Setting up conv47
I0925 18:55:51.246423  4257 net.cpp:157] Top shape: 32 1 72 72 (165888)
I0925 18:55:51.246425  4257 net.cpp:165] Memory required for data: 677915136
I0925 18:55:51.246428  4257 net.cpp:493] Sharing parameters 'conv_W7' owned by layer 'conv27', param index 0
I0925 18:55:51.246438  4257 net.cpp:493] Sharing parameters 'conv_b7' owned by layer 'conv27', param index 1
I0925 18:55:51.246439  4257 layer_factory.hpp:77] Creating layer loss2
I0925 18:55:51.246443  4257 net.cpp:100] Creating Layer loss2
I0925 18:55:51.246445  4257 net.cpp:434] loss2 <- conv27
I0925 18:55:51.246449  4257 net.cpp:434] loss2 <- label_label_0_split_0
I0925 18:55:51.246454  4257 net.cpp:408] loss2 -> loss2
I0925 18:55:51.246484  4257 net.cpp:150] Setting up loss2
I0925 18:55:51.246490  4257 net.cpp:157] Top shape: (1)
I0925 18:55:51.246492  4257 net.cpp:160]     with loss weight 0.5
I0925 18:55:51.246500  4257 net.cpp:165] Memory required for data: 677915140
I0925 18:55:51.246502  4257 layer_factory.hpp:77] Creating layer loss3
I0925 18:55:51.246505  4257 net.cpp:100] Creating Layer loss3
I0925 18:55:51.246507  4257 net.cpp:434] loss3 <- conv37
I0925 18:55:51.246510  4257 net.cpp:434] loss3 <- label_label_0_split_1
I0925 18:55:51.246513  4257 net.cpp:408] loss3 -> loss3
I0925 18:55:51.246541  4257 net.cpp:150] Setting up loss3
I0925 18:55:51.246546  4257 net.cpp:157] Top shape: (1)
I0925 18:55:51.246546  4257 net.cpp:160]     with loss weight 0.3
I0925 18:55:51.246549  4257 net.cpp:165] Memory required for data: 677915144
I0925 18:55:51.246551  4257 layer_factory.hpp:77] Creating layer loss4
I0925 18:55:51.246554  4257 net.cpp:100] Creating Layer loss4
I0925 18:55:51.246556  4257 net.cpp:434] loss4 <- conv47
I0925 18:55:51.246559  4257 net.cpp:434] loss4 <- label_label_0_split_2
I0925 18:55:51.246563  4257 net.cpp:408] loss4 -> loss4
I0925 18:55:51.246590  4257 net.cpp:150] Setting up loss4
I0925 18:55:51.246594  4257 net.cpp:157] Top shape: (1)
I0925 18:55:51.246597  4257 net.cpp:160]     with loss weight 0.2
I0925 18:55:51.246598  4257 net.cpp:165] Memory required for data: 677915148
I0925 18:55:51.246600  4257 net.cpp:226] loss4 needs backward computation.
I0925 18:55:51.246603  4257 net.cpp:226] loss3 needs backward computation.
I0925 18:55:51.246605  4257 net.cpp:226] loss2 needs backward computation.
I0925 18:55:51.246608  4257 net.cpp:226] conv47 needs backward computation.
I0925 18:55:51.246609  4257 net.cpp:226] relu46 needs backward computation.
I0925 18:55:51.246611  4257 net.cpp:226] bn46 needs backward computation.
I0925 18:55:51.246613  4257 net.cpp:226] maxout46 needs backward computation.
I0925 18:55:51.246616  4257 net.cpp:226] slice46 needs backward computation.
I0925 18:55:51.246619  4257 net.cpp:226] conv46 needs backward computation.
I0925 18:55:51.246621  4257 net.cpp:226] relu45 needs backward computation.
I0925 18:55:51.246623  4257 net.cpp:226] bn45 needs backward computation.
I0925 18:55:51.246625  4257 net.cpp:226] maxout45 needs backward computation.
I0925 18:55:51.246628  4257 net.cpp:226] slice45 needs backward computation.
I0925 18:55:51.246630  4257 net.cpp:226] conv45 needs backward computation.
I0925 18:55:51.246632  4257 net.cpp:226] relu44 needs backward computation.
I0925 18:55:51.246634  4257 net.cpp:226] deconv44 needs backward computation.
I0925 18:55:51.246636  4257 net.cpp:226] relu4-13 needs backward computation.
I0925 18:55:51.246639  4257 net.cpp:226] bn43 needs backward computation.
I0925 18:55:51.246640  4257 net.cpp:226] conv43 needs backward computation.
I0925 18:55:51.246642  4257 net.cpp:226] relu42 needs backward computation.
I0925 18:55:51.246644  4257 net.cpp:226] bn42 needs backward computation.
I0925 18:55:51.246645  4257 net.cpp:226] conv42 needs backward computation.
I0925 18:55:51.246647  4257 net.cpp:226] relu41 needs backward computation.
I0925 18:55:51.246649  4257 net.cpp:226] conv41 needs backward computation.
I0925 18:55:51.246651  4257 net.cpp:226] conv37 needs backward computation.
I0925 18:55:51.246655  4257 net.cpp:226] relu36 needs backward computation.
I0925 18:55:51.246656  4257 net.cpp:226] bn36 needs backward computation.
I0925 18:55:51.246659  4257 net.cpp:226] maxout36 needs backward computation.
I0925 18:55:51.246661  4257 net.cpp:226] slice36 needs backward computation.
I0925 18:55:51.246668  4257 net.cpp:226] conv36 needs backward computation.
I0925 18:55:51.246670  4257 net.cpp:226] relu35 needs backward computation.
I0925 18:55:51.246672  4257 net.cpp:226] bn35 needs backward computation.
I0925 18:55:51.246675  4257 net.cpp:226] maxout35 needs backward computation.
I0925 18:55:51.246676  4257 net.cpp:226] slice35 needs backward computation.
I0925 18:55:51.246678  4257 net.cpp:226] conv35 needs backward computation.
I0925 18:55:51.246680  4257 net.cpp:226] relu34 needs backward computation.
I0925 18:55:51.246682  4257 net.cpp:226] deconv34 needs backward computation.
I0925 18:55:51.246685  4257 net.cpp:226] relu3-13 needs backward computation.
I0925 18:55:51.246686  4257 net.cpp:226] bn33 needs backward computation.
I0925 18:55:51.246688  4257 net.cpp:226] conv33 needs backward computation.
I0925 18:55:51.246690  4257 net.cpp:226] relu32 needs backward computation.
I0925 18:55:51.246692  4257 net.cpp:226] bn32 needs backward computation.
I0925 18:55:51.246695  4257 net.cpp:226] conv32 needs backward computation.
I0925 18:55:51.246696  4257 net.cpp:226] relu31 needs backward computation.
I0925 18:55:51.246698  4257 net.cpp:226] conv31 needs backward computation.
I0925 18:55:51.246701  4257 net.cpp:226] conv27 needs backward computation.
I0925 18:55:51.246702  4257 net.cpp:226] relu26 needs backward computation.
I0925 18:55:51.246704  4257 net.cpp:226] bn26 needs backward computation.
I0925 18:55:51.246707  4257 net.cpp:226] maxout26 needs backward computation.
I0925 18:55:51.246711  4257 net.cpp:226] slice26 needs backward computation.
I0925 18:55:51.246712  4257 net.cpp:226] conv26 needs backward computation.
I0925 18:55:51.246714  4257 net.cpp:226] relu25 needs backward computation.
I0925 18:55:51.246716  4257 net.cpp:226] bn25 needs backward computation.
I0925 18:55:51.246718  4257 net.cpp:226] maxout25 needs backward computation.
I0925 18:55:51.246721  4257 net.cpp:226] slice25 needs backward computation.
I0925 18:55:51.246723  4257 net.cpp:226] conv25 needs backward computation.
I0925 18:55:51.246726  4257 net.cpp:226] relu24 needs backward computation.
I0925 18:55:51.246727  4257 net.cpp:226] deconv24 needs backward computation.
I0925 18:55:51.246729  4257 net.cpp:226] relu2-13 needs backward computation.
I0925 18:55:51.246731  4257 net.cpp:226] bn23 needs backward computation.
I0925 18:55:51.246733  4257 net.cpp:226] conv23 needs backward computation.
I0925 18:55:51.246736  4257 net.cpp:226] relu22 needs backward computation.
I0925 18:55:51.246737  4257 net.cpp:226] bn22 needs backward computation.
I0925 18:55:51.246739  4257 net.cpp:226] conv22 needs backward computation.
I0925 18:55:51.246742  4257 net.cpp:226] relu21 needs backward computation.
I0925 18:55:51.246743  4257 net.cpp:226] conv21 needs backward computation.
I0925 18:55:51.246747  4257 net.cpp:228] label_label_0_split does not need backward computation.
I0925 18:55:51.246750  4257 net.cpp:228] label does not need backward computation.
I0925 18:55:51.246752  4257 net.cpp:228] low4 does not need backward computation.
I0925 18:55:51.246753  4257 net.cpp:228] low3 does not need backward computation.
I0925 18:55:51.246755  4257 net.cpp:228] low2 does not need backward computation.
I0925 18:55:51.246757  4257 net.cpp:270] This network produces output loss2
I0925 18:55:51.246759  4257 net.cpp:270] This network produces output loss3
I0925 18:55:51.246762  4257 net.cpp:270] This network produces output loss4
I0925 18:55:51.247628  4257 net.cpp:283] Network initialization done.
I0925 18:55:51.247823  4257 solver.cpp:60] Solver scaffolding done.
I0925 18:55:51.249147  4257 caffe.cpp:251] Starting Optimization
I0925 18:55:51.249152  4257 solver.cpp:279] Solving AESR
I0925 18:55:51.249155  4257 solver.cpp:280] Learning Rate Policy: step
I0925 18:55:51.515193  4257 solver.cpp:228] Iteration 0, loss = 1674.93
I0925 18:55:51.515213  4257 solver.cpp:244]     Train net output #0: loss2 = 1677.72 (* 0.5 = 838.862 loss)
I0925 18:55:51.515218  4257 solver.cpp:244]     Train net output #1: loss3 = 1745.6 (* 0.3 = 523.68 loss)
I0925 18:55:51.515233  4257 solver.cpp:244]     Train net output #2: loss4 = 1561.92 (* 0.2 = 312.384 loss)
I0925 18:55:51.515240  4257 sgd_solver.cpp:106] Iteration 0, lr = 1e-05
I0925 18:55:53.778831  4179 solver.cpp:228] Iteration 370, loss = 19.7666
I0925 18:55:53.778859  4179 solver.cpp:244]     Train net output #0: loss2 = 17.0272 (* 0.5 = 8.51359 loss)
I0925 18:55:53.778865  4179 solver.cpp:244]     Train net output #1: loss3 = 21.1019 (* 0.3 = 6.33056 loss)
I0925 18:55:53.778869  4179 solver.cpp:244]     Train net output #2: loss4 = 24.6122 (* 0.2 = 4.92243 loss)
I0925 18:55:53.778874  4179 sgd_solver.cpp:106] Iteration 370, lr = 1e-05
I0925 18:55:55.344367  4257 solver.cpp:228] Iteration 10, loss = 321.167
I0925 18:55:55.344393  4257 solver.cpp:244]     Train net output #0: loss2 = 275.649 (* 0.5 = 137.824 loss)
I0925 18:55:55.344398  4257 solver.cpp:244]     Train net output #1: loss3 = 351.618 (* 0.3 = 105.485 loss)
I0925 18:55:55.344403  4257 solver.cpp:244]     Train net output #2: loss4 = 389.286 (* 0.2 = 77.8572 loss)
I0925 18:55:55.344405  4257 sgd_solver.cpp:106] Iteration 10, lr = 1e-05
I0925 18:55:57.654767  4179 solver.cpp:228] Iteration 380, loss = 19.5405
I0925 18:55:57.654794  4179 solver.cpp:244]     Train net output #0: loss2 = 16.8289 (* 0.5 = 8.41447 loss)
I0925 18:55:57.654800  4179 solver.cpp:244]     Train net output #1: loss3 = 20.8784 (* 0.3 = 6.26353 loss)
I0925 18:55:57.654804  4179 solver.cpp:244]     Train net output #2: loss4 = 24.3126 (* 0.2 = 4.86253 loss)
I0925 18:55:57.654808  4179 sgd_solver.cpp:106] Iteration 380, lr = 1e-05
I0925 18:55:59.198072  4257 solver.cpp:228] Iteration 20, loss = 86.6751
I0925 18:55:59.198099  4257 solver.cpp:244]     Train net output #0: loss2 = 79.5126 (* 0.5 = 39.7563 loss)
I0925 18:55:59.198104  4257 solver.cpp:244]     Train net output #1: loss3 = 92.8117 (* 0.3 = 27.8435 loss)
I0925 18:55:59.198109  4257 solver.cpp:244]     Train net output #2: loss4 = 95.3762 (* 0.2 = 19.0752 loss)
I0925 18:55:59.198112  4257 sgd_solver.cpp:106] Iteration 20, lr = 1e-05
I0925 18:56:01.592432  4179 solver.cpp:228] Iteration 390, loss = 19.322
I0925 18:56:01.592468  4179 solver.cpp:244]     Train net output #0: loss2 = 16.6368 (* 0.5 = 8.31842 loss)
I0925 18:56:01.592473  4179 solver.cpp:244]     Train net output #1: loss3 = 20.6633 (* 0.3 = 6.19899 loss)
I0925 18:56:01.592478  4179 solver.cpp:244]     Train net output #2: loss4 = 24.0231 (* 0.2 = 4.80462 loss)
I0925 18:56:01.592483  4179 sgd_solver.cpp:106] Iteration 390, lr = 1e-05
I0925 18:56:03.014919  4257 solver.cpp:228] Iteration 30, loss = 62.8346
I0925 18:56:03.014948  4257 solver.cpp:244]     Train net output #0: loss2 = 53.7947 (* 0.5 = 26.8973 loss)
I0925 18:56:03.014955  4257 solver.cpp:244]     Train net output #1: loss3 = 68.1007 (* 0.3 = 20.4302 loss)
I0925 18:56:03.014960  4257 solver.cpp:244]     Train net output #2: loss4 = 77.5353 (* 0.2 = 15.5071 loss)
I0925 18:56:03.014964  4257 sgd_solver.cpp:106] Iteration 30, lr = 1e-05
I0925 18:56:05.518165  4179 solver.cpp:228] Iteration 400, loss = 19.1108
I0925 18:56:05.518196  4179 solver.cpp:244]     Train net output #0: loss2 = 16.4506 (* 0.5 = 8.22528 loss)
I0925 18:56:05.518201  4179 solver.cpp:244]     Train net output #1: loss3 = 20.4563 (* 0.3 = 6.13688 loss)
I0925 18:56:05.518206  4179 solver.cpp:244]     Train net output #2: loss4 = 23.7432 (* 0.2 = 4.74864 loss)
I0925 18:56:05.518210  4179 sgd_solver.cpp:106] Iteration 400, lr = 1e-05
I0925 18:56:06.871285  4257 solver.cpp:228] Iteration 40, loss = 43.5968
I0925 18:56:06.871312  4257 solver.cpp:244]     Train net output #0: loss2 = 37.1334 (* 0.5 = 18.5667 loss)
I0925 18:56:06.871318  4257 solver.cpp:244]     Train net output #1: loss3 = 46.8608 (* 0.3 = 14.0582 loss)
I0925 18:56:06.871322  4257 solver.cpp:244]     Train net output #2: loss4 = 54.8596 (* 0.2 = 10.9719 loss)
I0925 18:56:06.871326  4257 sgd_solver.cpp:106] Iteration 40, lr = 1e-05
I0925 18:56:09.387111  4179 solver.cpp:228] Iteration 410, loss = 18.9049
I0925 18:56:09.387161  4179 solver.cpp:244]     Train net output #0: loss2 = 16.2672 (* 0.5 = 8.1336 loss)
I0925 18:56:09.387171  4179 solver.cpp:244]     Train net output #1: loss3 = 20.2567 (* 0.3 = 6.07702 loss)
I0925 18:56:09.387176  4179 solver.cpp:244]     Train net output #2: loss4 = 23.4716 (* 0.2 = 4.69431 loss)
I0925 18:56:09.387183  4179 sgd_solver.cpp:106] Iteration 410, lr = 1e-05
I0925 18:56:10.729208  4257 solver.cpp:228] Iteration 50, loss = 38.472
I0925 18:56:10.729245  4257 solver.cpp:244]     Train net output #0: loss2 = 33.7124 (* 0.5 = 16.8562 loss)
I0925 18:56:10.729254  4257 solver.cpp:244]     Train net output #1: loss3 = 40.7999 (* 0.3 = 12.24 loss)
I0925 18:56:10.729261  4257 solver.cpp:244]     Train net output #2: loss4 = 46.879 (* 0.2 = 9.3758 loss)
I0925 18:56:10.729267  4257 sgd_solver.cpp:106] Iteration 50, lr = 1e-05
I0925 18:56:13.237140  4179 solver.cpp:228] Iteration 420, loss = 18.7043
I0925 18:56:13.237167  4179 solver.cpp:244]     Train net output #0: loss2 = 16.0865 (* 0.5 = 8.04323 loss)
I0925 18:56:13.237174  4179 solver.cpp:244]     Train net output #1: loss3 = 20.0646 (* 0.3 = 6.01938 loss)
I0925 18:56:13.237179  4179 solver.cpp:244]     Train net output #2: loss4 = 23.2082 (* 0.2 = 4.64164 loss)
I0925 18:56:13.237195  4179 sgd_solver.cpp:106] Iteration 420, lr = 1e-05
I0925 18:56:14.540442  4257 solver.cpp:228] Iteration 60, loss = 37.0192
I0925 18:56:14.540473  4257 solver.cpp:244]     Train net output #0: loss2 = 32.6305 (* 0.5 = 16.3152 loss)
I0925 18:56:14.540479  4257 solver.cpp:244]     Train net output #1: loss3 = 39.0364 (* 0.3 = 11.7109 loss)
I0925 18:56:14.540483  4257 solver.cpp:244]     Train net output #2: loss4 = 44.9651 (* 0.2 = 8.99302 loss)
I0925 18:56:14.540488  4257 sgd_solver.cpp:106] Iteration 60, lr = 1e-05
I0925 18:56:17.165732  4179 solver.cpp:228] Iteration 430, loss = 18.508
I0925 18:56:17.165823  4179 solver.cpp:244]     Train net output #0: loss2 = 15.9073 (* 0.5 = 7.95366 loss)
I0925 18:56:17.165830  4179 solver.cpp:244]     Train net output #1: loss3 = 19.8792 (* 0.3 = 5.96376 loss)
I0925 18:56:17.165834  4179 solver.cpp:244]     Train net output #2: loss4 = 22.9527 (* 0.2 = 4.59054 loss)
I0925 18:56:17.165838  4179 sgd_solver.cpp:106] Iteration 430, lr = 1e-05
I0925 18:56:18.289022  4257 solver.cpp:228] Iteration 70, loss = 34.0316
I0925 18:56:18.289052  4257 solver.cpp:244]     Train net output #0: loss2 = 30.0185 (* 0.5 = 15.0093 loss)
I0925 18:56:18.289058  4257 solver.cpp:244]     Train net output #1: loss3 = 35.8715 (* 0.3 = 10.7614 loss)
I0925 18:56:18.289063  4257 solver.cpp:244]     Train net output #2: loss4 = 41.3044 (* 0.2 = 8.26088 loss)
I0925 18:56:18.289068  4257 sgd_solver.cpp:106] Iteration 70, lr = 1e-05
I0925 18:56:21.159801  4179 solver.cpp:228] Iteration 440, loss = 18.3157
I0925 18:56:21.159832  4179 solver.cpp:244]     Train net output #0: loss2 = 15.7307 (* 0.5 = 7.86535 loss)
I0925 18:56:21.159838  4179 solver.cpp:244]     Train net output #1: loss3 = 19.6995 (* 0.3 = 5.90986 loss)
I0925 18:56:21.159843  4179 solver.cpp:244]     Train net output #2: loss4 = 22.7027 (* 0.2 = 4.54053 loss)
I0925 18:56:21.159848  4179 sgd_solver.cpp:106] Iteration 440, lr = 1e-05
I0925 18:56:22.132463  4257 solver.cpp:228] Iteration 80, loss = 32.115
I0925 18:56:22.132525  4257 solver.cpp:244]     Train net output #0: loss2 = 28.1483 (* 0.5 = 14.0742 loss)
I0925 18:56:22.132532  4257 solver.cpp:244]     Train net output #1: loss3 = 33.8473 (* 0.3 = 10.1542 loss)
I0925 18:56:22.132536  4257 solver.cpp:244]     Train net output #2: loss4 = 39.4334 (* 0.2 = 7.88667 loss)
I0925 18:56:22.132542  4257 sgd_solver.cpp:106] Iteration 80, lr = 1e-05
I0925 18:56:25.034095  4179 solver.cpp:228] Iteration 450, loss = 18.1249
I0925 18:56:25.034124  4179 solver.cpp:244]     Train net output #0: loss2 = 15.5551 (* 0.5 = 7.77753 loss)
I0925 18:56:25.034131  4179 solver.cpp:244]     Train net output #1: loss3 = 19.5221 (* 0.3 = 5.85662 loss)
I0925 18:56:25.034137  4179 solver.cpp:244]     Train net output #2: loss4 = 22.4539 (* 0.2 = 4.49079 loss)
I0925 18:56:25.034140  4179 sgd_solver.cpp:106] Iteration 450, lr = 1e-05
I0925 18:56:25.998895  4257 solver.cpp:228] Iteration 90, loss = 31.1012
I0925 18:56:25.998924  4257 solver.cpp:244]     Train net output #0: loss2 = 27.1398 (* 0.5 = 13.5699 loss)
I0925 18:56:25.998929  4257 solver.cpp:244]     Train net output #1: loss3 = 32.7976 (* 0.3 = 9.83927 loss)
I0925 18:56:25.998934  4257 solver.cpp:244]     Train net output #2: loss4 = 38.4601 (* 0.2 = 7.69202 loss)
I0925 18:56:25.998939  4257 sgd_solver.cpp:106] Iteration 90, lr = 1e-05
I0925 18:56:28.891121  4179 solver.cpp:228] Iteration 460, loss = 17.9349
I0925 18:56:28.891155  4179 solver.cpp:244]     Train net output #0: loss2 = 15.3778 (* 0.5 = 7.68891 loss)
I0925 18:56:28.891161  4179 solver.cpp:244]     Train net output #1: loss3 = 19.3466 (* 0.3 = 5.80397 loss)
I0925 18:56:28.891165  4179 solver.cpp:244]     Train net output #2: loss4 = 22.2101 (* 0.2 = 4.44202 loss)
I0925 18:56:28.891171  4179 sgd_solver.cpp:106] Iteration 460, lr = 1e-05
I0925 18:56:29.821665  4257 solver.cpp:228] Iteration 100, loss = 30.092
I0925 18:56:29.821694  4257 solver.cpp:244]     Train net output #0: loss2 = 26.2188 (* 0.5 = 13.1094 loss)
I0925 18:56:29.821701  4257 solver.cpp:244]     Train net output #1: loss3 = 31.7633 (* 0.3 = 9.52898 loss)
I0925 18:56:29.821705  4257 solver.cpp:244]     Train net output #2: loss4 = 37.2678 (* 0.2 = 7.45356 loss)
I0925 18:56:29.821709  4257 sgd_solver.cpp:106] Iteration 100, lr = 1e-05
I0925 18:56:32.860424  4179 solver.cpp:228] Iteration 470, loss = 17.7478
I0925 18:56:32.860452  4179 solver.cpp:244]     Train net output #0: loss2 = 15.201 (* 0.5 = 7.60052 loss)
I0925 18:56:32.860458  4179 solver.cpp:244]     Train net output #1: loss3 = 19.1743 (* 0.3 = 5.7523 loss)
I0925 18:56:32.860463  4179 solver.cpp:244]     Train net output #2: loss4 = 21.9747 (* 0.2 = 4.39494 loss)
I0925 18:56:32.860467  4179 sgd_solver.cpp:106] Iteration 470, lr = 1e-05
I0925 18:56:33.568083  4257 solver.cpp:228] Iteration 110, loss = 29.3873
I0925 18:56:33.568109  4257 solver.cpp:244]     Train net output #0: loss2 = 25.5677 (* 0.5 = 12.7838 loss)
I0925 18:56:33.568114  4257 solver.cpp:244]     Train net output #1: loss3 = 31.0201 (* 0.3 = 9.30603 loss)
I0925 18:56:33.568119  4257 solver.cpp:244]     Train net output #2: loss4 = 36.4873 (* 0.2 = 7.29747 loss)
I0925 18:56:33.568122  4257 sgd_solver.cpp:106] Iteration 110, lr = 1e-05
I0925 18:56:36.788002  4179 solver.cpp:228] Iteration 480, loss = 17.5617
I0925 18:56:36.788033  4179 solver.cpp:244]     Train net output #0: loss2 = 15.0234 (* 0.5 = 7.51169 loss)
I0925 18:56:36.788039  4179 solver.cpp:244]     Train net output #1: loss3 = 19.0034 (* 0.3 = 5.70103 loss)
I0925 18:56:36.788044  4179 solver.cpp:244]     Train net output #2: loss4 = 21.7451 (* 0.2 = 4.34901 loss)
I0925 18:56:36.788049  4179 sgd_solver.cpp:106] Iteration 480, lr = 1e-05
I0925 18:56:37.408912  4257 solver.cpp:228] Iteration 120, loss = 28.6875
I0925 18:56:37.408943  4257 solver.cpp:244]     Train net output #0: loss2 = 24.9353 (* 0.5 = 12.4676 loss)
I0925 18:56:37.408949  4257 solver.cpp:244]     Train net output #1: loss3 = 30.2782 (* 0.3 = 9.08347 loss)
I0925 18:56:37.408953  4257 solver.cpp:244]     Train net output #2: loss4 = 35.6817 (* 0.2 = 7.13635 loss)
I0925 18:56:37.408958  4257 sgd_solver.cpp:106] Iteration 120, lr = 1e-05
I0925 18:56:40.688297  4179 solver.cpp:228] Iteration 490, loss = 17.3774
I0925 18:56:40.688326  4179 solver.cpp:244]     Train net output #0: loss2 = 14.8455 (* 0.5 = 7.42276 loss)
I0925 18:56:40.688331  4179 solver.cpp:244]     Train net output #1: loss3 = 18.8347 (* 0.3 = 5.65041 loss)
I0925 18:56:40.688335  4179 solver.cpp:244]     Train net output #2: loss4 = 21.5212 (* 0.2 = 4.30425 loss)
I0925 18:56:40.688339  4179 sgd_solver.cpp:106] Iteration 490, lr = 1e-05
I0925 18:56:41.272050  4257 solver.cpp:228] Iteration 130, loss = 28.0602
I0925 18:56:41.272080  4257 solver.cpp:244]     Train net output #0: loss2 = 24.3774 (* 0.5 = 12.1887 loss)
I0925 18:56:41.272089  4257 solver.cpp:244]     Train net output #1: loss3 = 29.6201 (* 0.3 = 8.88602 loss)
I0925 18:56:41.272096  4257 solver.cpp:244]     Train net output #2: loss4 = 34.9275 (* 0.2 = 6.9855 loss)
I0925 18:56:41.272120  4257 sgd_solver.cpp:106] Iteration 130, lr = 1e-05
I0925 18:56:44.560706  4179 solver.cpp:228] Iteration 500, loss = 17.1976
I0925 18:56:44.560736  4179 solver.cpp:244]     Train net output #0: loss2 = 14.6713 (* 0.5 = 7.33564 loss)
I0925 18:56:44.560742  4179 solver.cpp:244]     Train net output #1: loss3 = 18.6701 (* 0.3 = 5.60102 loss)
I0925 18:56:44.560747  4179 solver.cpp:244]     Train net output #2: loss4 = 21.3049 (* 0.2 = 4.26097 loss)
I0925 18:56:44.560752  4179 sgd_solver.cpp:106] Iteration 500, lr = 1e-05
I0925 18:56:45.134270  4257 solver.cpp:228] Iteration 140, loss = 27.533
I0925 18:56:45.134299  4257 solver.cpp:244]     Train net output #0: loss2 = 23.906 (* 0.5 = 11.953 loss)
I0925 18:56:45.134306  4257 solver.cpp:244]     Train net output #1: loss3 = 29.0702 (* 0.3 = 8.72107 loss)
I0925 18:56:45.134313  4257 solver.cpp:244]     Train net output #2: loss4 = 34.2948 (* 0.2 = 6.85896 loss)
I0925 18:56:45.134322  4257 sgd_solver.cpp:106] Iteration 140, lr = 1e-05
I0925 18:56:48.473526  4179 solver.cpp:228] Iteration 510, loss = 17.0209
I0925 18:56:48.473618  4179 solver.cpp:244]     Train net output #0: loss2 = 14.501 (* 0.5 = 7.25049 loss)
I0925 18:56:48.473628  4179 solver.cpp:244]     Train net output #1: loss3 = 18.507 (* 0.3 = 5.5521 loss)
I0925 18:56:48.473631  4179 solver.cpp:244]     Train net output #2: loss4 = 21.0917 (* 0.2 = 4.21833 loss)
I0925 18:56:48.473636  4179 sgd_solver.cpp:106] Iteration 510, lr = 1e-05
I0925 18:56:48.890874  4257 solver.cpp:228] Iteration 150, loss = 26.9972
I0925 18:56:48.890903  4257 solver.cpp:244]     Train net output #0: loss2 = 23.4244 (* 0.5 = 11.7122 loss)
I0925 18:56:48.890909  4257 solver.cpp:244]     Train net output #1: loss3 = 28.5158 (* 0.3 = 8.55475 loss)
I0925 18:56:48.890914  4257 solver.cpp:244]     Train net output #2: loss4 = 33.6513 (* 0.2 = 6.73026 loss)
I0925 18:56:48.890918  4257 sgd_solver.cpp:106] Iteration 150, lr = 1e-05
*** Aborted at 1474801011 (unix time) try "date -d @1474801011" if you are using GNU date ***
PC: @     0x7ffe0ffc29ac (unknown)
*** SIGTERM (@0x3e800000fcb) received by PID 4179 (TID 0x7f9e281f2a40) from PID 4043; stack trace: ***
    @     0x7f9e26162d40 (unknown)
    @     0x7ffe0ffc29ac (unknown)
    @     0x7f9e2623492d (unknown)
    @     0x7f9e0840c59e (unknown)
    @     0x7f9e07dc251b (unknown)
    @     0x7f9e07d9fca3 (unknown)
    @     0x7f9e07d979e1 (unknown)
    @     0x7f9e07d98736 (unknown)
    @     0x7f9e07d06322 (unknown)
    @     0x7f9e07d0647a (unknown)
    @     0x7f9e07ce9f45 (unknown)
    @     0x7f9e27397482 (unknown)
    @     0x7f9e27379db1 (unknown)
    @     0x7f9e2739d9b8 (unknown)
    @     0x7f9e278d96de caffe::caffe_gpu_memcpy()
    @     0x7f9e27767d70 caffe::SyncedMemory::mutable_cpu_data()
    @     0x7f9e277466f2 caffe::Blob<>::mutable_cpu_data()
    @     0x7f9e278e45ad caffe::BatchNormLayer<>::Forward_gpu()
    @     0x7f9e277b4385 caffe::Net<>::ForwardFromTo()
    @     0x7f9e277b46f7 caffe::Net<>::Forward()
    @     0x7f9e2777f997 caffe::Solver<>::Step()
    @     0x7f9e27780259 caffe::Solver<>::Solve()
    @           0x40873b train()
    @           0x405b3c main
    @     0x7f9e2614dec5 (unknown)
    @           0x4063ab (unknown)
    @                0x0 (unknown)
Terminated
I0925 18:56:52.110383  4257 solver.cpp:228] Iteration 160, loss = 26.4972
I0925 18:56:52.110414  4257 solver.cpp:244]     Train net output #0: loss2 = 22.9756 (* 0.5 = 11.4878 loss)
I0925 18:56:52.110420  4257 solver.cpp:244]     Train net output #1: loss3 = 27.9981 (* 0.3 = 8.39944 loss)
I0925 18:56:52.110425  4257 solver.cpp:244]     Train net output #2: loss4 = 33.0501 (* 0.2 = 6.61003 loss)
I0925 18:56:52.110430  4257 sgd_solver.cpp:106] Iteration 160, lr = 1e-05
I0925 18:56:53.924021  4257 solver.cpp:228] Iteration 170, loss = 26.0353
I0925 18:56:53.924101  4257 solver.cpp:244]     Train net output #0: loss2 = 22.562 (* 0.5 = 11.281 loss)
I0925 18:56:53.924108  4257 solver.cpp:244]     Train net output #1: loss3 = 27.5194 (* 0.3 = 8.25582 loss)
I0925 18:56:53.924114  4257 solver.cpp:244]     Train net output #2: loss4 = 32.4925 (* 0.2 = 6.4985 loss)
I0925 18:56:53.924123  4257 sgd_solver.cpp:106] Iteration 170, lr = 1e-05
I0925 18:56:55.736830  4257 solver.cpp:228] Iteration 180, loss = 25.5921
I0925 18:56:55.736860  4257 solver.cpp:244]     Train net output #0: loss2 = 22.1667 (* 0.5 = 11.0833 loss)
I0925 18:56:55.736865  4257 solver.cpp:244]     Train net output #1: loss3 = 27.0602 (* 0.3 = 8.11806 loss)
I0925 18:56:55.736870  4257 solver.cpp:244]     Train net output #2: loss4 = 31.9534 (* 0.2 = 6.39067 loss)
I0925 18:56:55.736873  4257 sgd_solver.cpp:106] Iteration 180, lr = 1e-05
*** Aborted at 1474801016 (unix time) try "date -d @1474801016" if you are using GNU date ***
PC: @     0x7ffd23b2c9ac (unknown)
*** SIGTERM (@0x3e800000fcb) received by PID 4257 (TID 0x7f105a456a40) from PID 4043; stack trace: ***
    @     0x7f10583c6d40 (unknown)
    @     0x7ffd23b2c9ac (unknown)
    @     0x7f105849892d (unknown)
    @     0x7f103a67059e (unknown)
    @     0x7f103a02651b (unknown)
    @     0x7f103a003ca3 (unknown)
    @     0x7f1039ffb9e1 (unknown)
    @     0x7f1039ffc736 (unknown)
    @     0x7f1039f6a322 (unknown)
    @     0x7f1039f6a47a (unknown)
    @     0x7f1039f4df45 (unknown)
    @     0x7f10595fb482 (unknown)
    @     0x7f10595dddb1 (unknown)
    @     0x7f10596019b8 (unknown)
    @     0x7f1059b3d6de caffe::caffe_gpu_memcpy()
    @     0x7f10599cbd70 caffe::SyncedMemory::mutable_cpu_data()
    @     0x7f10599aa6f2 caffe::Blob<>::mutable_cpu_data()
    @     0x7f1059b485ad caffe::BatchNormLayer<>::Forward_gpu()
    @     0x7f1059a18385 caffe::Net<>::ForwardFromTo()
    @     0x7f1059a186f7 caffe::Net<>::Forward()
    @     0x7f10599e3997 caffe::Solver<>::Step()
    @     0x7f10599e4259 caffe::Solver<>::Solve()
    @           0x40873b train()
    @           0x405b3c main
    @     0x7f10583b1ec5 (unknown)
    @           0x4063ab (unknown)
    @                0x0 (unknown)
Terminated
